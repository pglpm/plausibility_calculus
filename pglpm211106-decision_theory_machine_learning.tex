\pdfoutput=1
%% Author: PGL  Porta Mana
%% Created: 2015-05-01T20:53:34+0200
%% Last-Updated: 2021-12-16T14:46:53+0100
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newif\ifarxiv
\arxivfalse
\ifarxiv\pdfmapfile{+classico.map}\fi
\newif\ifafour
\afourfalse% true = A4, false = A5
\newif\iftypodisclaim % typographical disclaim on the side
\typodisclaimtrue
\newcommand*{\memfontfamily}{zplx}
\newcommand*{\memfontpack}{newpxtext}
\documentclass[\ifafour a4paper,12pt,\else a5paper,10pt,\fi%extrafontsizes,%
onecolumn,oneside,article,%french,italian,german,swedish,latin,
british%
]{memoir}
\newcommand*{\firstdraft}{6 November 2021}
\newcommand*{\firstpublished}{\firstdraft}
\newcommand*{\updated}{\ifarxiv***\else\today\fi}
\newcommand*{\propertitle}{The foundations of machine learning\\on
  probability theory and decision theory%\\{\large ***}%
}% title uses LARGE; set Large for smaller
\newcommand*{\pdftitle}{\propertitle}
\newcommand*{\headtitle}{Machine learning, probability theory, decision theory}
\newcommand*{\pdfauthor}{P.G.L.  Porta Mana, A. S. Lundervold}
\newcommand*{\headauthor}{Luca \amp\ Alexander}
\newcommand*{\reporthead}{\ifarxiv\else Open Science Framework \href{https://doi.org/10.31219/osf.io/***}{\textsc{doi}:10.31219/osf.io/***}\fi}% Report number

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Calls to packages (uncomment as needed)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\usepackage{pifont}

%\usepackage{fontawesome}

\usepackage[T1]{fontenc} 
\input{glyphtounicode} \pdfgentounicode=1

\usepackage[utf8]{inputenx}

%\usepackage{newunicodechar}
% \newunicodechar{Ĕ}{\u{E}}
% \newunicodechar{ĕ}{\u{e}}
% \newunicodechar{Ĭ}{\u{I}}
% \newunicodechar{ĭ}{\u{\i}}
% \newunicodechar{Ŏ}{\u{O}}
% \newunicodechar{ŏ}{\u{o}}
% \newunicodechar{Ŭ}{\u{U}}
% \newunicodechar{ŭ}{\u{u}}
% \newunicodechar{Ā}{\=A}
% \newunicodechar{ā}{\=a}
% \newunicodechar{Ē}{\=E}
% \newunicodechar{ē}{\=e}
% \newunicodechar{Ī}{\=I}
% \newunicodechar{ī}{\={\i}}
% \newunicodechar{Ō}{\=O}
% \newunicodechar{ō}{\=o}
% \newunicodechar{Ū}{\=U}
% \newunicodechar{ū}{\=u}
% \newunicodechar{Ȳ}{\=Y}
% \newunicodechar{ȳ}{\=y}

\newcommand*{\bmmax}{0} % reduce number of bold fonts, before font packages
\newcommand*{\hmmax}{0} % reduce number of heavy fonts, before font packages

\usepackage{textcomp}

%\usepackage[normalem]{ulem}% package for underlining
% \makeatletter
% \def\ssout{\bgroup \ULdepth=-.35ex%\UL@setULdepth
%  \markoverwith{\lower\ULdepth\hbox
%    {\kern-.03em\vbox{\hrule width.2em\kern1.2\p@\hrule}\kern-.03em}}%
%  \ULon}
% \makeatother

\usepackage{amsmath}

\usepackage{mathtools}
%\addtolength{\jot}{\jot} % increase spacing in multiline formulae
\setlength{\multlinegap}{0pt}

\usepackage{empheq}% automatically calls amsmath and mathtools
\newcommand*{\widefbox}[1]{\fbox{\hspace{1em}#1\hspace{1em}}}

%%%% empheq above seems more versatile than these:
%\usepackage{fancybox}
%\usepackage{framed}

% \usepackage[misc]{ifsym} % for dice
% \newcommand*{\diceone}{{\scriptsize\Cube{1}}}

\usepackage{amssymb}

\usepackage{amsxtra}

\usepackage[main=british]{babel}\selectlanguage{british}
%\newcommand*{\langnohyph}{\foreignlanguage{nohyphenation}}
\newcommand{\langnohyph}[1]{\begin{hyphenrules}{nohyphenation}#1\end{hyphenrules}}

\usepackage[autostyle=false,autopunct=false,english=british]{csquotes}
\setquotestyle{american}
\newcommand*{\defquote}[1]{`\,#1\,'}

% \makeatletter
% \renewenvironment{quotation}%
%                {\list{}{\listparindent 1.5em%
%                         \itemindent    \listparindent
%                         \rightmargin=1em   \leftmargin=1em
%                         \parsep        \z@ \@plus\p@}%
%                 \item[]\footnotesize}%
%                 {\endlist}
% \makeatother                


\usepackage{amsthm}
%% from https://tex.stackexchange.com/a/404680/97039
\makeatletter
\def\@endtheorem{\endtrivlist}
\makeatother

\newcommand*{\QED}{\textsc{q.e.d.}}
\renewcommand*{\qedsymbol}{\QED}
\theoremstyle{remark}
\newtheorem{note}{Note}
\newtheorem*{remark}{Note}
\newtheoremstyle{innote}{\parsep}{\parsep}{\footnotesize}{}{}{}{0pt}{}
\theoremstyle{innote}
\newtheorem*{innote}{}

\usepackage[shortlabels,inline]{enumitem}
\SetEnumitemKey{para}{itemindent=\parindent,leftmargin=0pt,listparindent=\parindent,parsep=0pt,itemsep=\topsep}
% \begin{asparaenum} = \begin{enumerate}[para]
% \begin{inparaenum} = \begin{enumerate*}
\setlist{itemsep=0pt,topsep=\parsep}
\setlist[enumerate,2]{label=\alph*.}
\setlist[enumerate]{label=\arabic*.,leftmargin=1.5\parindent}
\setlist[itemize]{leftmargin=1.5\parindent}
\setlist[description]{leftmargin=1.5\parindent}
% old alternative:
% \setlist[enumerate,2]{label=\alph*.}
% \setlist[enumerate]{leftmargin=\parindent}
% \setlist[itemize]{leftmargin=\parindent}
% \setlist[description]{leftmargin=\parindent}

\usepackage[babel,theoremfont,largesc]{newpxtext}

\usepackage[bigdelims,nosymbolsc%,smallerops % probably arXiv doesn't have it
]{newpxmath}
%\useosf
%\linespread{1.083}%
%\linespread{1.05}% widely used
\linespread{1.1}% best for text with maths
%% smaller operators for old version of newpxmath
\makeatletter
\def\re@DeclareMathSymbol#1#2#3#4{%
    \let#1=\undefined
    \DeclareMathSymbol{#1}{#2}{#3}{#4}}
%\re@DeclareMathSymbol{\bigsqcupop}{\mathop}{largesymbols}{"46}
%\re@DeclareMathSymbol{\bigodotop}{\mathop}{largesymbols}{"4A}
\re@DeclareMathSymbol{\bigoplusop}{\mathop}{largesymbols}{"4C}
\re@DeclareMathSymbol{\bigotimesop}{\mathop}{largesymbols}{"4E}
\re@DeclareMathSymbol{\sumop}{\mathop}{largesymbols}{"50}
\re@DeclareMathSymbol{\prodop}{\mathop}{largesymbols}{"51}
\re@DeclareMathSymbol{\bigcupop}{\mathop}{largesymbols}{"53}
\re@DeclareMathSymbol{\bigcapop}{\mathop}{largesymbols}{"54}
%\re@DeclareMathSymbol{\biguplusop}{\mathop}{largesymbols}{"55}
\re@DeclareMathSymbol{\bigwedgeop}{\mathop}{largesymbols}{"56}
\re@DeclareMathSymbol{\bigveeop}{\mathop}{largesymbols}{"57}
%\re@DeclareMathSymbol{\bigcupdotop}{\mathop}{largesymbols}{"DF}
%\re@DeclareMathSymbol{\bigcapplusop}{\mathop}{largesymbolsPXA}{"00}
%\re@DeclareMathSymbol{\bigsqcupplusop}{\mathop}{largesymbolsPXA}{"02}
%\re@DeclareMathSymbol{\bigsqcapplusop}{\mathop}{largesymbolsPXA}{"04}
%\re@DeclareMathSymbol{\bigsqcapop}{\mathop}{largesymbolsPXA}{"06}
\re@DeclareMathSymbol{\bigtimesop}{\mathop}{largesymbolsPXA}{"10}
%\re@DeclareMathSymbol{\coprodop}{\mathop}{largesymbols}{"60}
%\re@DeclareMathSymbol{\varprod}{\mathop}{largesymbolsPXA}{16}
\makeatother
%%
%% With euler font cursive for Greek letters - the [1] means 100% scaling
\DeclareFontFamily{U}{egreek}{\skewchar\font'177}%
\DeclareFontShape{U}{egreek}{m}{n}{<-6>s*[1]eurm5 <6-8>s*[1]eurm7 <8->s*[1]eurm10}{}%
\DeclareFontShape{U}{egreek}{m}{it}{<->s*[1]eurmo10}{}%
\DeclareFontShape{U}{egreek}{b}{n}{<-6>s*[1]eurb5 <6-8>s*[1]eurb7 <8->s*[1]eurb10}{}%
\DeclareFontShape{U}{egreek}{b}{it}{<->s*[1]eurbo10}{}%
\DeclareSymbolFont{egreeki}{U}{egreek}{m}{it}%
\SetSymbolFont{egreeki}{bold}{U}{egreek}{b}{it}% from the amsfonts package
\DeclareSymbolFont{egreekr}{U}{egreek}{m}{n}%
\SetSymbolFont{egreekr}{bold}{U}{egreek}{b}{n}% from the amsfonts package
% Take also \sum, \prod, \coprod symbols from Euler fonts
\DeclareFontFamily{U}{egreekx}{\skewchar\font'177}
\DeclareFontShape{U}{egreekx}{m}{n}{%
       <-7.5>s*[0.9]euex7%
    <7.5-8.5>s*[0.9]euex8%
    <8.5-9.5>s*[0.9]euex9%
    <9.5->s*[0.9]euex10%
}{}
\DeclareSymbolFont{egreekx}{U}{egreekx}{m}{n}
\DeclareMathSymbol{\sumop}{\mathop}{egreekx}{"50}
\DeclareMathSymbol{\prodop}{\mathop}{egreekx}{"51}
\DeclareMathSymbol{\coprodop}{\mathop}{egreekx}{"60}
\makeatletter
\def\sum{\DOTSI\sumop\slimits@}
\def\prod{\DOTSI\prodop\slimits@}
\def\coprod{\DOTSI\coprodop\slimits@}
\makeatother
\input{definegreek.tex}% Greek letters not usually given in LaTeX.

%\usepackage%[scaled=0.9]%
%{classico}%  Optima as sans-serif font
\renewcommand\sfdefault{uop}
\DeclareMathAlphabet{\mathsf}  {T1}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsf}{bold}{T1}{\sfdefault}{b}{sl}
%\newcommand*{\mathte}[1]{\textbf{\textit{\textsf{#1}}}}
% Upright sans-serif math alphabet
% \DeclareMathAlphabet{\mathsu}  {T1}{\sfdefault}{m}{n}
% \SetMathAlphabet{\mathsu}{bold}{T1}{\sfdefault}{b}{n}

% DejaVu Mono as typewriter text
\usepackage[scaled=0.84]{DejaVuSansMono}

\usepackage{mathdots}

\usepackage[usenames]{xcolor}
% Tol (2012) colour-blind-, print-, screen-friendly colours, alternative scheme; Munsell terminology
\definecolor{mypurpleblue}{RGB}{68,119,170}
\definecolor{myblue}{RGB}{102,204,238}
\definecolor{mygreen}{RGB}{34,136,51}
\definecolor{myyellow}{RGB}{204,187,68}
\definecolor{myred}{RGB}{238,102,119}
\definecolor{myredpurple}{RGB}{170,51,119}
\definecolor{mygrey}{RGB}{187,187,187}
% Tol (2012) colour-blind-, print-, screen-friendly colours; Munsell terminology
% \definecolor{lbpurple}{RGB}{51,34,136}
% \definecolor{lblue}{RGB}{136,204,238}
% \definecolor{lbgreen}{RGB}{68,170,153}
% \definecolor{lgreen}{RGB}{17,119,51}
% \definecolor{lgyellow}{RGB}{153,153,51}
% \definecolor{lyellow}{RGB}{221,204,119}
% \definecolor{lred}{RGB}{204,102,119}
% \definecolor{lpred}{RGB}{136,34,85}
% \definecolor{lrpurple}{RGB}{170,68,153}
\definecolor{lgrey}{RGB}{221,221,221}
%\newcommand*\mycolourbox[1]{%
%\colorbox{mygrey}{\hspace{1em}#1\hspace{1em}}}
\colorlet{shadecolor}{lgrey}

\usepackage{bm}

\usepackage{microtype}

\usepackage[backend=biber,mcite,%subentry,
citestyle=authoryear-comp,bibstyle=pglpm-authoryear,autopunct=false,sorting=ny,sortcites=false,natbib=false,maxcitenames=2,maxbibnames=8,minbibnames=8,giveninits=true,uniquename=false,uniquelist=false,maxalphanames=1,block=space,hyperref=true,defernumbers=false,useprefix=true,sortupper=false,language=british,parentracker=false]{biblatex}
\DeclareSortingTemplate{ny}{\sort{\field{sortname}\field{author}\field{editor}}\sort{\field{year}}}
\iffalse\makeatletter%%% replace parenthesis with brackets
\newrobustcmd*{\parentexttrack}[1]{%
  \begingroup
  \blx@blxinit
  \blx@setsfcodes
  \blx@bibopenparen#1\blx@bibcloseparen
  \endgroup}
\AtEveryCite{%
  \let\parentext=\parentexttrack%
  \let\bibopenparen=\bibopenbracket%
  \let\bibcloseparen=\bibclosebracket}
\makeatother\fi
\DefineBibliographyExtras{british}{\def\finalandcomma{\addcomma}}
\renewcommand*{\finalnamedelim}{\addspace\amp\space}
% \renewcommand*{\finalnamedelim}{\addcomma\space}
\renewcommand*{\textcitedelim}{\addcomma\space}
% \setcounter{biburlnumpenalty}{1}
% \setcounter{biburlucpenalty}{0}
% \setcounter{biburllcpenalty}{1}
\DeclareDelimFormat{multicitedelim}{\addsemicolon\addspace\space}
\DeclareDelimFormat{compcitedelim}{\addsemicolon\addspace\space}
\DeclareDelimFormat{postnotedelim}{\addspace}
\ifarxiv\else\addbibresource{portamanabib.bib}\fi
\renewcommand{\bibfont}{\footnotesize}
%\appto{\citesetup}{\footnotesize}% smaller font for citations
\defbibheading{bibliography}[\bibname]{\section*{#1}\addcontentsline{toc}{section}{#1}%\markboth{#1}{#1}
}
\newcommand*{\citep}{\footcites}
\newcommand*{\citey}{\footcites}%{\parencites*}
\newcommand*{\ibid}{\unspace\addtocounter{footnote}{-1}\footnotemark{}}
%\renewcommand*{\cite}{\parencite}
%\renewcommand*{\cites}{\parencites}
\providecommand{\href}[2]{#2}
\providecommand{\eprint}[2]{\texttt{\href{#1}{#2}}}
\newcommand*{\amp}{\&}
% \newcommand*{\citein}[2][]{\textnormal{\textcite[#1]{#2}}%\addtocategory{extras}{#2}
% }
\newcommand*{\citein}[2][]{\textnormal{\textcite[#1]{#2}}%\addtocategory{extras}{#2}
}
\newcommand*{\citebi}[2][]{\textcite[#1]{#2}%\addtocategory{extras}{#2}
}
\newcommand*{\subtitleproc}[1]{}
\newcommand*{\chapb}{ch.}
%
\DeclareUrlCommand\doiurl{\urlstyle{rm}}
\newcommand*{\arxiveprint}[1]{%
\texttt{arXiv:\urlalt{https://arxiv.org/abs/#1}{\doiurl{#1}}}%
}
\newcommand*{\mparceprint}[1]{%
\texttt{mp\_arc:\urlalt{http://www.ma.utexas.edu/mp_arc-bin/mpa?yn=#1}{\doiurl{#1}}}%
}
\newcommand*{\haleprint}[1]{%
\texttt{HAL:\urlalt{https://hal.archives-ouvertes.fr/#1}{\doiurrl{#1}}}%
}
\newcommand*{\philscieprint}[1]{%
\texttt{PhilSci:\urlalt{http://philsci-archive.pitt.edu/archive/#1}{\doiurl{#1}}}%
}
\newcommand*{\doi}[1]{%
\href{https://doi.org/#1}{\textsc{doi}:\allowbreak\texttt{\doiurl{#1}}}%
}
\newcommand*{\biorxiveprint}[1]{%
bioRxiv \doi{10.1101/#1}%
}
\newcommand*{\osfeprint}[1]{%
Open Science Framework \doi{10.31219/osf.io/#1}%
}

\usepackage{graphicx}

%\usepackage{wrapfig}

%\usepackage{tikz-cd}

\PassOptionsToPackage{hyphens}{url}\usepackage[hypertexnames=false,pdfencoding=unicode,psdextra]{hyperref}

\usepackage[depth=4]{bookmark}
\hypersetup{colorlinks=true,bookmarksnumbered,pdfborder={0 0 0.25},citebordercolor={0.2667 0.4667 0.6667},citecolor=mypurpleblue,linkbordercolor={0.6667 0.2 0.4667},linkcolor=myredpurple,urlbordercolor={0.1333 0.5333 0.2},urlcolor=mygreen,breaklinks=true,pdftitle={\pdftitle},pdfauthor={\pdfauthor}}
% \usepackage[vertfit=local]{breakurl}% only for arXiv
\providecommand*{\urlalt}{\href}

\usepackage[british]{datetime2}
\DTMnewdatestyle{mydate}%
{% definitions
\renewcommand*{\DTMdisplaydate}[4]{%
\number##3\ \DTMenglishmonthname{##2} ##1}%
\renewcommand*{\DTMDisplaydate}{\DTMdisplaydate}%
}
\DTMsetdatestyle{mydate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Layout. I do not know on which kind of paper the reader will print the
%%% paper on (A4? letter? one-sided? double-sided?). So I choose A5, which
%%% provides a good layout for reading on screen and save paper if printed
%%% two pages per sheet. Average length line is 66 characters and page
%%% numbers are centred.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ifafour\setstocksize{297mm}{210mm}%{*}% A4
\else\setstocksize{210mm}{5.5in}%{*}% 210x139.7
\fi
\settrimmedsize{\stockheight}{\stockwidth}{*}
\setlxvchars[\normalfont] %313.3632pt for a 66-characters line
\setxlvchars[\normalfont]
% \setlength{\trimtop}{0pt}
% \setlength{\trimedge}{\stockwidth}
% \addtolength{\trimedge}{-\paperwidth}
%\settrims{0pt}{0pt}
% The length of the normalsize alphabet is 133.05988pt - 10 pt = 26.1408pc
% The length of the normalsize alphabet is 159.6719pt - 12pt = 30.3586pc
% Bringhurst gives 32pc as boundary optimal with 69 ch per line
% The length of the normalsize alphabet is 191.60612pt - 14pt = 35.8634pc
\ifafour\settypeblocksize{*}{32pc}{1.618} % A4
%\setulmargins{*}{*}{1.667}%gives 5/3 margins % 2 or 1.667
\else\settypeblocksize{*}{26pc}{1.618}% nearer to a 66-line newpx and preserves GR
\fi
\setulmargins{*}{*}{1}%gives equal margins
\setlrmargins{*}{*}{*}
\setheadfoot{\onelineskip}{2.5\onelineskip}
\setheaderspaces{*}{2\onelineskip}{*}
\setmarginnotes{2ex}{10mm}{0pt}
\checkandfixthelayout[nearest]
%%% End layout
%% this fixes missing white spaces
%\pdfmapline{+dummy-space <dummy-space.pfb}
%\pdfinterwordspaceon% seems to add a white margin to Sumatrapdf

%%% Sectioning
\newcommand*{\asudedication}[1]{%
{\par\centering\textit{#1}\par}}
\newenvironment{acknowledgements}{\section*{Thanks}\addcontentsline{toc}{section}{Thanks}}{\par}
\makeatletter\renewcommand{\appendix}{\par
  \bigskip{\centering
   \interlinepenalty \@M
   \normalfont
   \printchaptertitle{\sffamily\appendixpagename}\par}
  \setcounter{section}{0}%
  \gdef\@chapapp{\appendixname}%
  \gdef\thesection{\@Alph\c@section}%
  \anappendixtrue}\makeatother
\counterwithout{section}{chapter}
\setsecnumformat{\upshape\csname the#1\endcsname\quad}
\setsecheadstyle{\large\bfseries\sffamily%
\centering}
\setsubsecheadstyle{\bfseries\sffamily%
\raggedright}
%\setbeforesecskip{-1.5ex plus 1ex minus .2ex}% plus 1ex minus .2ex}
%\setaftersecskip{1.3ex plus .2ex }% plus 1ex minus .2ex}
%\setsubsubsecheadstyle{\bfseries\sffamily\slshape\raggedright}
%\setbeforesubsecskip{1.25ex plus 1ex minus .2ex }% plus 1ex minus .2ex}
%\setaftersubsecskip{-1em}%{-0.5ex plus .2ex}% plus 1ex minus .2ex}
\setsubsecindent{0pt}%0ex plus 1ex minus .2ex}
\setparaheadstyle{\bfseries\sffamily%
\raggedright}
\setcounter{secnumdepth}{2}
\setlength{\headwidth}{\textwidth}
\newcommand{\addchap}[1]{\chapter*[#1]{#1}\addcontentsline{toc}{chapter}{#1}}
\newcommand{\addsec}[1]{\section*{#1}\addcontentsline{toc}{section}{#1}}
\newcommand{\addsubsec}[1]{\subsection*{#1}\addcontentsline{toc}{subsection}{#1}}
\newcommand{\addpara}[1]{\paragraph*{#1.}\addcontentsline{toc}{subsubsection}{#1}}
\newcommand{\addparap}[1]{\paragraph*{#1}\addcontentsline{toc}{subsubsection}{#1}}

%%% Headers, footers, pagestyle
\copypagestyle{manaart}{plain}
\makeheadrule{manaart}{\headwidth}{0.5\normalrulethickness}
\makeoddhead{manaart}{%
{\footnotesize%\sffamily%
\scshape\headauthor}}{}{{\footnotesize\sffamily%
\headtitle}}
\makeoddfoot{manaart}{}{\thepage}{}
\newcommand*\autanet{\includegraphics[height=\heightof{M}]{autanet.pdf}}
\definecolor{mygray}{gray}{0.333}
\iftypodisclaim%
\ifafour\newcommand\addprintnote{\begin{picture}(0,0)%
\put(245,149){\makebox(0,0){\rotatebox{90}{\tiny\color{mygray}\textsf{This
            document is designed for screen reading and
            two-up printing on A4 or Letter paper}}}}%
\end{picture}}% A4
\else\newcommand\addprintnote{\begin{picture}(0,0)%
\put(176,112){\makebox(0,0){\rotatebox{90}{\tiny\color{mygray}\textsf{This
            document is designed for screen reading and
            two-up printing on A4 or Letter paper}}}}%
\end{picture}}\fi%afourtrue
\makeoddfoot{plain}{}{\makebox[0pt]{\thepage}\addprintnote}{}
\else
\makeoddfoot{plain}{}{\makebox[0pt]{\thepage}}{}
\fi%typodisclaimtrue
\makeoddhead{plain}{\scriptsize\reporthead}{}{}
% \copypagestyle{manainitial}{plain}
% \makeheadrule{manainitial}{\headwidth}{0.5\normalrulethickness}
% \makeoddhead{manainitial}{%
% \footnotesize\sffamily%
% \scshape\headauthor}{}{\footnotesize\sffamily%
% \headtitle}
% \makeoddfoot{manaart}{}{\thepage}{}

\pagestyle{manaart}

\setlength{\droptitle}{-3.9\onelineskip}
\pretitle{\begin{center}\LARGE\sffamily%
\bfseries}
\posttitle{\bigskip\end{center}}

\makeatletter\newcommand*{\atf}{\includegraphics[totalheight=\heightof{@}]{atblack.png}}\makeatother
\providecommand{\affiliation}[1]{\textsl{\textsf{\footnotesize #1}}}
\providecommand{\epost}[1]{\texttt{\footnotesize\textless#1\textgreater}}
\providecommand{\email}[2]{\href{mailto:#1ZZ@#2 ((remove ZZ))}{#1\protect\atf#2}}
%\providecommand{\email}[2]{\href{mailto:#1@#2}{#1@#2}}

\preauthor{\vspace{-0.5\baselineskip}\begin{center}
\normalsize\sffamily%
\lineskip  0.5em}
\postauthor{\par\end{center}}
\predate{\DTMsetdatestyle{mydate}\begin{center}\footnotesize}
\postdate{\end{center}\vspace{-\medskipamount}}

\setfloatadjustment{figure}{\footnotesize}
\captiondelim{\quad}
\captionnamefont{\footnotesize\sffamily%
}
\captiontitlefont{\footnotesize}
%\firmlists*
\midsloppy
% handling orphan/widow lines, memman.pdf
% \clubpenalty=10000
% \widowpenalty=10000
% \raggedbottom
% Downes, memman.pdf
\clubpenalty=9996
\widowpenalty=9999
\brokenpenalty=4991
\predisplaypenalty=10000
\postdisplaypenalty=1549
\displaywidowpenalty=1602
\raggedbottom

\paragraphfootnotes
\setlength{\footmarkwidth}{2ex}
% \threecolumnfootnotes
%\setlength{\footmarksep}{0em}
\footmarkstyle{\textsuperscript{%\color{myred}
\scriptsize\bfseries#1}~}
%\footmarkstyle{\textsuperscript{\color{myred}\scriptsize\bfseries#1}~}
%\footmarkstyle{\textsuperscript{[#1]}~}

\selectlanguage{british}\frenchspacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Paper's details
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\propertitle}
\author{%
\hspace*{\stretch{1}}%
%% uncomment if additional authors present
% \parbox{0.5\linewidth}%\makebox[0pt][c]%
% {\protect\centering ***\\%
% \footnotesize\epost{\email{***}{***}}}%
% \hspace*{\stretch{1}}%
\parbox{0.25\linewidth}%\makebox[0pt][c]%
{\protect\centering Luca \href{https://orcid.org/0000-0002-6070-0784}{\protect\includegraphics[scale=0.16]{orcid_32x32.png}}\\\footnotesize%
%Western Norway University of Applied Sciences%
\epost{\email{pgl}{portamana.org}}}%
% Mohn Medical Imaging and Visualization Centre, Dept of Computer science, Electrical Engineering and Mathematical Sciences, Western Norway University of Applied Sciences, Bergen, Norway
%% uncomment if additional authors present
\hspace*{\stretch{0.5}}%
\parbox{0.25\linewidth}%\makebox[0pt][c]%
{\protect\centering Alexander\\%
\footnotesize\epost{\email{***}{***}}}%
\hspace*{\stretch{1}}\mbox{}%
\\\tiny(or any permutation thereof)}

%\date{Draft of \today\ (first drafted \firstdraft)}
\date{\firstpublished; updated \updated}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Macros @@@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Common ones - uncomment as needed
%\providecommand{\nequiv}{\not\equiv}
%\providecommand{\coloneqq}{\mathrel{\mathop:}=}
%\providecommand{\eqqcolon}{=\mathrel{\mathop:}}
%\providecommand{\varprod}{\prod}
\newcommand*{\de}{\partialup}%partial diff
\newcommand*{\pu}{\piup}%constant pi
\newcommand*{\delt}{\deltaup}%Kronecker, Dirac
%\newcommand*{\eps}{\varepsilonup}%Levi-Civita, Heaviside
%\newcommand*{\riem}{\zetaup}%Riemann zeta
%\providecommand{\degree}{\textdegree}% degree
%\newcommand*{\celsius}{\textcelsius}% degree Celsius
%\newcommand*{\micro}{\textmu}% degree Celsius
\newcommand*{\I}{\mathrm{i}}%imaginary unit
\newcommand*{\e}{\mathrm{e}}%Neper
\newcommand*{\di}{\mathrm{d}}%differential
%\newcommand*{\Di}{\mathrm{D}}%capital differential
%\newcommand*{\planckc}{\hslash}
%\newcommand*{\avogn}{N_{\textrm{A}}}
%\newcommand*{\NN}{\bm{\mathrm{N}}}
%\newcommand*{\ZZ}{\bm{\mathrm{Z}}}
%\newcommand*{\QQ}{\bm{\mathrm{Q}}}
\newcommand*{\RR}{\bm{\mathrm{R}}}
%\newcommand*{\CC}{\bm{\mathrm{C}}}
%\newcommand*{\nabl}{\bm{\nabla}}%nabla
%\DeclareMathOperator{\lb}{lb}%base 2 log
%\DeclareMathOperator{\tr}{tr}%trace
%\DeclareMathOperator{\card}{card}%cardinality
%\DeclareMathOperator{\im}{Im}%im part
%\DeclareMathOperator{\re}{Re}%re part
%\DeclareMathOperator{\sgn}{sgn}%signum
%\DeclareMathOperator{\ent}{ent}%integer less or equal to
%\DeclareMathOperator{\Ord}{O}%same order as
%\DeclareMathOperator{\ord}{o}%lower order than
%\newcommand*{\incr}{\triangle}%finite increment
\newcommand*{\defd}{\coloneqq}
\newcommand*{\defs}{\eqqcolon}
%\newcommand*{\Land}{\bigwedge}
%\newcommand*{\Lor}{\bigvee}
%\newcommand*{\lland}{\DOTSB\;\land\;}
%\newcommand*{\llor}{\DOTSB\;\lor\;}
\newcommand*{\limplies}{\mathbin{\Rightarrow}}%implies
%\newcommand*{\suchthat}{\mid}%{\mathpunct{|}}%such that (eg in sets)
%\newcommand*{\with}{\colon}%with (list of indices)
%\newcommand*{\mul}{\times}%multiplication
%\newcommand*{\inn}{\cdot}%inner product
\newcommand*{\dotv}{\mathord{\,\cdot\,}}%variable place
%\newcommand*{\comp}{\circ}%composition of functions
%\newcommand*{\con}{\mathbin{:}}%scal prod of tensors
%\newcommand*{\equi}{\sim}%equivalent to 
\renewcommand*{\asymp}{\simeq}%equivalent to 
%\newcommand*{\corr}{\mathrel{\hat{=}}}%corresponds to
%\providecommand{\varparallel}{\ensuremath{\mathbin{/\mkern-7mu/}}}%parallel (tentative symbol)
\renewcommand*{\le}{\leqslant}%less or equal
\renewcommand*{\ge}{\geqslant}%greater or equal
%\DeclarePairedDelimiter\clcl{[}{]}
%\DeclarePairedDelimiter\clop{[}{[}
%\DeclarePairedDelimiter\opcl{]}{]}
%\DeclarePairedDelimiter\opop{]}{[}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
%\DeclarePairedDelimiter\norm{\lVert}{\rVert}
\DeclarePairedDelimiter\set{\{}{\}} %}
%\DeclareMathOperator{\pr}{P}%probability
\newcommand*{\p}{\mathrm{p}}%probability
\renewcommand*{\P}{\mathrm{P}}%probability
%\newcommand*{\E}{\mathrm{E}}
%% The "\:" space is chosen to correctly separate inner binary and external rels
\renewcommand*{\|}[1][]{\nonscript\:#1\vert\nonscript\:\mathopen{}}
%\DeclarePairedDelimiterX{\cp}[2]{(}{)}{#1\nonscript\:\delimsize\vert\nonscript\:\mathopen{}#2}
%\DeclarePairedDelimiterX{\ct}[2]{[}{]}{#1\nonscript\;\delimsize\vert\nonscript\:\mathopen{}#2}
%\DeclarePairedDelimiterX{\cs}[2]{\{}{\}}{#1\nonscript\:\delimsize\vert\nonscript\:\mathopen{}#2}
%\newcommand*{\+}{\lor}
%\renewcommand{\*}{\land}
%% symbol = for equality statements within probabilities
%% from https://tex.stackexchange.com/a/484142/97039
% \newcommand*{\eq}{\mathrel{\!=\!}}
% \let\texteq\=
% \renewcommand*{\=}{\TextOrMath\texteq\eq}
% \newcommand*{\eq}[1][=]{\mathrel{\!#1\!}}
\newcommand*{\mo}[1][=]{\mathord{\,#1\,}}
%%
\newcommand*{\sect}{\S}% Sect.~
\newcommand*{\sects}{\S\S}% Sect.~
\newcommand*{\chap}{ch.}%
\newcommand*{\chaps}{chs}%
\newcommand*{\bref}{ref.}%
\newcommand*{\brefs}{refs}%
%\newcommand*{\fn}{fn}%
\newcommand*{\eqn}{eq.}%
\newcommand*{\eqns}{eqs}%
\newcommand*{\fig}{fig.}%
\newcommand*{\figs}{figs}%
\newcommand*{\vs}{{vs}}
\newcommand*{\eg}{{e.g.}}
\newcommand*{\etc}{{etc.}}
\newcommand*{\ie}{{i.e.}}
%\newcommand*{\ca}{{c.}}
\newcommand*{\foll}{{ff.}}
%\newcommand*{\viz}{{viz}}
\newcommand*{\cf}{{cf.}}
%\newcommand*{\Cf}{{Cf.}}
%\newcommand*{\vd}{{v.}}
\newcommand*{\etal}{{et al.}}
%\newcommand*{\etsim}{{et sim.}}
%\newcommand*{\ibid}{{ibid.}}
%\newcommand*{\sic}{{sic}}
%\newcommand*{\id}{\mathte{I}}%id matrix
%\newcommand*{\nbd}{\nobreakdash}%
%\newcommand*{\bd}{\hspace{0pt}}%
%\def\hy{-\penalty0\hskip0pt\relax}
%\newcommand*{\labelbis}[1]{\tag*{(\ref{#1})$_\text{r}$}}
%\newcommand*{\mathbox}[2][.8]{\parbox[t]{#1\columnwidth}{#2}}
%\newcommand*{\zerob}[1]{\makebox[0pt][l]{#1}}
\newcommand*{\tprod}{\mathop{\textstyle\prod}\nolimits}
\newcommand*{\tsum}{\mathop{\textstyle\sum}\nolimits}
%\newcommand*{\tint}{\begingroup\textstyle\int\endgroup\nolimits}
%\newcommand*{\tland}{\mathop{\textstyle\bigwedge}\nolimits}
%\newcommand*{\tlor}{\mathop{\textstyle\bigvee}\nolimits}
%\newcommand*{\sprod}{\mathop{\textstyle\prod}}
%\newcommand*{\ssum}{\mathop{\textstyle\sum}}
%\newcommand*{\sint}{\begingroup\textstyle\int\endgroup}
%\newcommand*{\sland}{\mathop{\textstyle\bigwedge}}
%\newcommand*{\slor}{\mathop{\textstyle\bigvee}}
%\newcommand*{\T}{^\transp}%transpose
%%\newcommand*{\QEM}%{\textnormal{$\Box$}}%{\ding{167}}
%\newcommand*{\qem}{\leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
%\quad\hbox{\QEM}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Custom macros for this file @@@
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\definecolor{notecolour}{RGB}{68,170,153}
%\newcommand*{\puzzle}{\maltese}
\newcommand*{\puzzle}{{\fontencoding{U}\fontfamily{fontawesometwo}\selectfont\symbol{225}}}
\newcommand*{\wrench}{{\fontencoding{U}\fontfamily{fontawesomethree}\selectfont\symbol{114}}}
\newcommand*{\pencil}{{\fontencoding{U}\fontfamily{fontawesometwo}\selectfont\symbol{210}}}
\newcommand{\mynote}[1]{ {\color{notecolour}#1}}

\newcommand*{\widebar}[1]{{\mkern1.5mu\skew{2}\overline{\mkern-1.5mu#1\mkern-1.5mu}\mkern 1.5mu}}

% \newcommand{\explanation}[4][t]{%\setlength{\tabcolsep}{-1ex}
% %\smash{
% \begin{tabular}[#1]{c}#2\\[0.5\jot]\rule{1pt}{#3}\\#4\end{tabular}}%}
% \newcommand*{\ptext}[1]{\text{\small #1}}
\DeclareMathOperator*{\argsup}{arg\,sup}
\newcommand*{\dob}{degree of belief}
\newcommand*{\dobs}{degrees of belief}
\newcommand*{\ml}{machine-learning}
\newcommand*{\xx}[1]{x_{#1}}
\newcommand*{\yy}[1]{y_{#1}}
\newcommand*{\bx}{\bm{x}}
\newcommand*{\by}{\bm{y}}
\newcommand*{\bz}{\bm{xy}}
\newcommand*{\xxx}[1]{\tilde{x}_{#1}}
\newcommand*{\yyy}[1]{\tilde{y}_{#1}}
\newcommand*{\bxx}{\tilde{\bm{x}}}
\newcommand*{\byy}{\tilde{\bm{y}}}
\newcommand*{\bzz}{\tilde{\bm{x}}\tilde{\bm{y}}}
\newcommand*{\bzzi}{\tilde{\bm{x}}'\tilde{\bm{y}}'}
\newcommand*{\ctheta}{\theta^{*}}
%%% Custom macros end @@@

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Beginning of document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\firmlists
\begin{document}
\captiondelim{\quad}\captionnamefont{\footnotesize}\captiontitlefont{\footnotesize}
\selectlanguage{british}\frenchspacing
\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Abstract
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\abstractrunin
\abslabeldelim{}
\renewcommand*{\abstractname}{}
\setlength{\absleftindent}{0pt}
\setlength{\absrightindent}{0pt}
\setlength{\abstitleskip}{-\absparindent}
\begin{abstract}\labelsep 0pt%
  \noindent %***
% \\\noindent\emph{\footnotesize Note: Dear Reader
%     \amp\ Peer, this manuscript is being peer-reviewed by you. Thank you.}
% \par%\\[\jot]
% \noindent
% {\footnotesize PACS: ***}\qquad%
% {\footnotesize MSC: ***}%
%\qquad{\footnotesize Keywords: ***}
\end{abstract}
\selectlanguage{british}\frenchspacing

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Epigraph
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \asudedication{\small ***}
% \vspace{\bigskipamount}
% \setlength{\epigraphwidth}{.7\columnwidth}
% %\epigraphposition{flushright}
% \epigraphtextposition{flushright}
% %\epigraphsourceposition{flushright}
% \epigraphfontsize{\footnotesize}
% \setlength{\epigraphrule}{0pt}
% %\setlength{\beforeepigraphskip}{0pt}
% %\setlength{\afterepigraphskip}{0pt}
% \epigraph{\emph{text}}{source}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% BEGINNING OF MAIN TEXT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Inferential vs decision algorithms}
\label{sec:inf_vs_dec}

A predictive, non-probabilistic \ml\ algorithm is typically designed to be
used multiple times to output a quantity $y$, which we call
\enquote*{predictand}, given some input quantity $x$, called the
\enquote*{predictor}. At bottom, such an algorithm is the implementation of
a function $x \mapsto y$. (We do not make any assumptions regarding $x$ and
$y$: either could be discrete, continuous, or belong to some complicated
multidimensional manifold; thus the \ml\ algorithm could be doing
classification or regression.)

The internal parameters of the algorithm are usually explored at the
training phase and finally kept fixed at values to be used thereafter.

At each use, the algorithm is making both a forecast and a decision under
the hood. A forecast because it must consider probable predictand values
related to the predictor. A decision because it chooses as its output only
one among such values.


In training and selecting such an algorithm we are also making a forecast
and a decision. A forecast because we consider several possible algorithms,
architectures, and internal-parameter values, and we must evaluate which of
them will most probably yield optimal outputs in their forthcoming use. A
decision because we must finally choose one such algorithm (which can be a
combination of different kinds of algorithms, but such combination is
itself an algorithm), with definite internal-parameter values, to be
shipped and employed by the final user.

The processes of training and selecting a \ml\ algorithm are thus a
forecast \amp\ decision problem. These processes should therefore follow
the rules of probability theory and decision theory. If they did not, they
would be marred by intrinsic logical inconsistencies or have a
mathematically guaranteed suboptimal long-run performance
\citep{prattetal1995_r1996,berger1980_r1985,raiffaetal1961_r2000,bernardoetal1994_r2000}[esp.\
\chaps~13--14]{jaynes1994_r2003}{degroot1970_r2004}[for early works
see][]{wald1950_r1964,savage1954_r1972,neumannetal1944_r1955,bernoulli1738}[for
introductions and summaries:][]{good1952,prattetal1964,north1968}[and the
brilliant][]{raiffa1968_r1970}[it is known that human beings often do not
follow rational decision theory (nor logic for that matter); this is why
logic, probability theory, decision theory are \emph{normative}, not
descriptive, theories; see \eg][]{tversky1975,tverskyetal1981}. We shall
interchangeably speak of forecast or \enquote*{inference}, meaning the
assessment of a probability distribution for some quantity or scenario of
interest, \emph{without commitment} to any specific value of such quantity.


The purpose of the present note is to make a step-by-step derivation of a
general \ml\ training and selection process, according to probability
theory and decision theory, and to interpret some common \ml\ algorithms
and practices from this point of view.

% ***current methods must be at least an approximation of decision-theoretic derivation


% forecast how
% several possible algorithms, and several possible internal-parameters
% values for each, will perform in the forthcoming application. A decision
% because we finally choose one such algorithm, with a definite set of
% internal-parameter values, for actual use.


The foundations of \ml\ algorithms on probability theory have been explored
at the very least since the 1980s
\citep{tishbyetal1989,levinetal1990,mackay1992,mackay1992b,mackay1992c,mackay1992d}[esp.
Part~V]{mackay1995_r2005}{neal1996}: these algorithms can generally be seen
as probability calculations based on exchangeability assumptions
\citep[\chap~4]{bernardoetal1994_r2000}. The output of a trained \ml\
algorithm, however, is often a specific value taken at face value; that is,
treated as \enquote{the truth}\citep[\cf][\sect~3]{mackay1992b}. From this
point of view the algorithm is making a \emph{decision}: choosing a
specific value to be used in the problem at hand. Moreover, once the
algorithm has been trained it is often used for future decisions without
any further training; that is, its internal parameters (the weights of a
neural net, for example) remain fixed at some specific value. This also
represents a choice from our part.

When we not only assess the probabilities for the values of a quantity, but
also choose a specific value or other course of action based on such
assessment, we enter the domain of decision theory
\citep{savage1954_r1972,raiffaetal1961_r2000,berger1980_r1985}[\chap~2]{bernardoetal1994_r2000}{prattetal1995_r1996}[\chaps~13--14]{jaynes1994_r2003}[for
a charming introduction see][]{raiffa1968_r1970}. We shall consider this
theory as normative and use its principles to approach the problem of
training and choosing the internal parameters of a \ml\ algorithm that
performs regression or classification, that is, that yields an output which
should ideally be equal to a true value $y$, called the predictand, given
an input $x$, called the predictor. Predictor and predictand quantities can
be real-valued, categorical, or belong to some general manifold. A brief
summary of decision theory is given in the next section.

\section{A simplified overview of decision theory}
\label{sec:dec_theory_overview}

\mynote{\wrench\ to be written}

\section{Training, parameter choice, and algorithm choice as a combined
  decision problem}
\label{sec:training_as_decision}

Let us now examine our problem from a decision-theoretic perspective.

\subsection{Decisions}
\label{sec:decisions}

A \ml\ algorithm with internal parameters $\theta$ typically yields an
output that is a function $t(x \| \theta)$ of the input $x$ and of the
(fixed) parameter $\theta$. For example, for a neural net $t$ is a
composition of nonlinear functions of $x$, and $\theta$ is a set of
connection weights; in the case of a linear-regression algorithm, $t$ is a
linear function of $x$ and $\theta$ its coefficients.

Our goal is to choose one among several \ml\ algorithms, and specific
internal-parameter values for that algorithm.

This nested choice can actually be combined into a single choice. Label the
candidates algorithms with 1, 2, \etc, and denote their parameter spaces by
$\varTheta_{1}$, $\varTheta_{2}$, \etc. The choice of algorithm and
internal parameter can then be seen as the choice of a parameter value
$\theta$ in the union space $\varTheta_{1} \cup \varTheta_{2} \cup\dotsb$,
denoted $\varTheta$. We shall denote the output produced by the \ml\
algorithm \amp\ parameter $\theta$ operating on the input $x$ simply as
$\theta(x)$, getting rid of the symbol \enquote{$t$}. Later we shall
explore how the separation into two different kinds of choices, algorithm
and parameters separately is made.

Our possible choices or decisions therefore consist of the possible values
$\theta \in \varTheta$.

We can alternatively see our set of choices as the set of possible
sequences of future outputs in response to future predictor values.
Since a specific output sequence is determined by a specific value of
$\theta$, the two points of view are equivalent. In
\sect~\ref{sec:utilities} this equivalence will be apparent in the
mathematical expression for the utility.

\subsection{Scenarios}
\label{sec:scenarios}

Besides the space of choices we must specify the space of possible
scenarios, of which only one will turn out to be true. Our scenarios
consist of all possible sequences of predictor-predictand pairs
$\bigl((\xx{1}, \yy{1}), (\xx{2}, \yy{2}), \dotsc \bigr)$ that our
algorithm will encounter in its lifetime: $(\xx{n})$ will be the known
inputs fed to the algorithm, and $(\yy{n})$ the unknown values that the
algorithm will try to predict. Let us assume that this sequence is finite
although very large.
% We use superscripts as indices (not as powers) without ambiguity

For typographical convenience any pair $(\xx{n}, \yy{n})$ is briefly
denoted $\xx{n}\yy{n}$; this juxtaposition does not represent any
mathematical operation. Denote $\bx \defd (\xx{1}, \xx{2}, \dotsc)$,
analogously for $\by$, and
$\bz \defd (\xx{1}\yy{1}, \xx{2}\yy{2}, \dotsc)$. If the quantity $x$
takes values in the manifold $X$ and $y$ in $Y$, our possible scenarios
live in the space $\prod_{n}(X\times Y)$.

Besides the sequence $(\xx{n}\yy{n})$ we also have a sequence
$(\xxx{m}\yyy{m})$ of predictors $(\xxx{m})$ and corresponding
\emph{known} predictands $(\yyy{m})$: our training data. One may adopt
the point of view that our set of scenarios should consist of all possible
sequences $(\xx{n}\yy{n}, \xxx{m}\yyy{m})$ (the subsequence
$(\xxx{m}\yyy{m})$ being common to all of them), on the grounds that
one wants the choice of algorithm and parameters to be optimal not only for
future predictions, but also for past ones. In the following steps we shall
also consider this alternative point of view. Let us denote
$\bxx \defd (\xxx{1}, \xxx{2}, \dotsc)$, analogously for $\byy$, and
$\bzz \defd (\xxx{1}\yyy{1}, \xxx{2}\yyy{2}, \dotsc)$.

\mynote{\puzzle\ It's maybe less confusing to proceed here and in the next
  sections without considering the possibility of including training data
  in the scenarios. Then in a later section the results are adapted to this
  assumptions. Will try this change later.}


\subsection{Utilities}
\label{sec:utilities}

For each combination of decision (algorithm \amp\ internal parameter)
$\theta$ and scenario $\bz$ we must now specify the utility
$U(\theta \| \bz)$.

We make the realistic assumptions that this utility is the sum of utilities
$u(\theta \| \xx{n}\yy{n})$ for each single application $n$ of the
algorithm to the sequence of data $\bz$, and that such individual utilities
have identical functional forms:
\begin{equation}
  \label{eq:total_utility}
  U(\theta \| \bz) = \sum_{n} u(\theta \| \xx{n}\yy{n}) \ .
\end{equation}
A more general approach, where the functional form of the utility changes
with each instance (even if $\xx{n}$ and $\yy{n}$ assume the same pair of
values), is also possible and may be more appropriate in particular
situations.

In each single instance what we are actually choosing is an output value
$\theta(x)$, determined by the input $x$ and by the algorithm and its
parameter $\theta$. The single-instance unknown is the true value $y$. So
the single-instance utility $u(\theta \| \xx{n}\yy{n})$ can actually be
rewritten as
\begin{equation}
  \label{eq:utility_singleinstance}
  u[\yy{n} \| \theta(\xx{n})] \ ,
\end{equation}
so that
\begin{equation}
  \label{eq:total_utility_final}
  U(\theta \| \bz) = \sum_{n} u[\yy{n} \| \theta(\xx{n})] \ .
\end{equation}
This equation expresses the fact, remarked in \sect~\ref{sec:decisions},
that the choice of parameter $\theta$ is equivalent to a choice \emph{en
  masse} of future outputs $(\yy{n})$, since the latter are determined by
the former.

If we also want to include the training data in the set of possible
scenarios, as discussed in \sect~\ref{sec:scenarios}, then the total
utility is
\begin{equation}
  \label{eq:total_utility_final_withtraining}
  U(\theta \| \bz\bzz) = \sum_{n} u[\yy{n} \| \theta(\xx{n})]
 +  \sum_{m} u[\yyy{m} \| \theta(\xxx{m})] \ .
\end{equation}

The functional form of the single-instance utility $u(\dotv\|\dotv)$
depends on the specific problem -- it is in fact no less problem-specific
than the choice of \ml\ algorithm -- so we do not make any more specific
assumptions about it.

\subsection{Probabilities for the scenarios and exchangeability}
\label{sec:scenario_probabilities}

Lastly we need to assess the distribution of probability over the possible
scenarios $\bz$. This probability distribution is conditional on some
hypotheses, assumptions, or background knowledge $H$, and on the sequence
$(\xxx{m}\yyy{m})$ of known predictors and predictands discussed in
\sect~\ref{sec:scenarios}. It can be written in two equivalent ways:
\begin{equation}
  \label{eq:prob_distr_conditional}
  \p(\bz \| \bzz, H)\,\di\bz
  \equiv
  \p(\by\| \bx, \bzz, H)\ \p(\bx \| \bzz, H)\ \di\bz \ .
\end{equation}

Two alternative assumptions can be made about this distribution.
\begin{enumerate}[label=(\Roman*),para]
\item\label{item:full_exchangeability} \emph{Joint exchangeability.} The
  prior distribution is jointly exchangeable in predictors and predictands.
  That is, the probability is the same for any sequence obtained from
  $\bz\bzz$ by simultaneously exchanging predictor-predictand pairs between
  different instances in the sequence, even across future and training
  subsequences.
\item\label{item:conditional_exchangeability} \emph{Conditional
    exchangeability.}\citep[\sect~4.6.2]{bernardoetal1994_r2000}[\sect~3]{diaconis1988}[\sect~3,
  Appendix~2]{lindleyetal1981} The prior distribution is conditionally
  exchangeable in the predictands given the predictors, but not in the
  predictors across future and training subsequences. That is, the
  probability is the same for any sequence obtained from $\bz\bzz$ by
  exchanging predictand values between different instances in the sequence
  \emph{that have the same predictor values}; however, the probability is
  generally not the same if we exchange predictor values, especially if
  across future data and training data.
\end{enumerate}

These two assumptions can also be understood in terms of
\enquote{populations}\citep[see the extremely insightful discussion
in][]{lindleyetal1981} and their frequency distributions.
\ref{item:full_exchangeability} says that future and training
predictor-predictand pairs all come from the same population. In other
words, the \emph{joint} frequency distribution observed in the training
data should be similar to the joint frequency distribution of future data
our \ml\ algorithm will be applied to.
\ref{item:conditional_exchangeability} says that future and training
predictands come from the same subpopulations conditional on the same
predictor values. The predictor values in future and training data,
however, come from potentially different populations. In other words, every
frequency distribution, observed in the training data, of the predictand
\emph{conditional} on each predictor value should be similar to every
frequency distribution of future predictands, \emph{conditional} on the
same predictor vaule; the (marginal) frequency distribution of predictor
values in the training data, however, may differ from that of predictor
values in future data. This difference is related to the distinction
between \enquote{generative} and \enquote{discriminative} approaches.

Assumption~\ref{item:full_exchangeability} applies to cases where our
training predictor-predictand pairs come from the same source (or, again,
\enquote{population} if you like) as the future pairs.
Assumption~\ref{item:conditional_exchangeability} applies to cases where
our training predictors and future predictors come from different sources,
possibly because of constraints in their choice -- for example, the
algorithm will be applied to predictor values expensive to realize
artificially, and the training is based on predictor values cheaper to
realize artificially.

It is important to note that joint exchangeability
\ref{item:full_exchangeability} implies conditional
exchangeability~\ref{item:conditional_exchangeability}, but not vice versa.
So the conditional exchangeability of \enquote{predictand${}\|{}$predictor}
is assumed in any case. It is indeed a necessary assumptions for our
regression problem to make sense at all.

We shall use a notation that allows us to consider
assumptions~\ref{item:full_exchangeability} and
\ref{item:conditional_exchangeability} at the same time.

\begin{subequations} \label{eq:exchangeable_conditional}
  \begin{gather}
    \label{eq:marginalize_conditional}
    \p(\by \| \bx, \bzz, H) =
    \int \Bigl[\prod_{n} F(\yy{n}\|\xx{n})\Bigr] \ \p(F \| \bzz, H)\ \di F
    \\\shortintertext{with}
    \label{eq:update_conditional}
    \p(F \| \bzz, H) =
    \frac{
      \bigl[\prod_{m} F(\yyy{m}\|\xxx{m}) \bigr]\ \p(F \| H)
    }{
      \int \bigl[\prod_{m} F(\yyy{m}\|\xxx{m}) \bigr]\ \p(F \| H)\ \di F
    } \ .
  \end{gather}
\end{subequations}








This distribution is typically assumed to be exchangeable in the whole
sequence of data (known and unknown) and therefore by de~Finetti's theorem
\citep{definetti1930,definetti1937,hewittetal1955}[\chap~4]{bernardoetal1994_r2000}[for
an insightful summary see]{dawid2013} and Bayes's theorem its density must
have the form
\begin{subequations} \label{eq:exchangeable_prob}
  \begin{gather}
    \label{eq:marginalize_F}
    \p(\bz \| \bzz, H) =
    \int \Bigl[\prod_{n} F(\xx{n}\yy{n})\Bigr] \ \p(F \| \bzz, H)\ \di F
    \\\shortintertext{with}
    \label{eq:update_F}
    \p(F \| \bzz, H) =
    \frac{
      \bigl[\prod_{m} F(\xxx{m}\yyy{m}) \bigr]\ \p(F \| H)
    }{
      \int \bigl[\prod_{m} F(\xxx{m}\yyy{m}) \bigr]\ \p(F \| H)\ \di F
    } \ .
  \end{gather}
\end{subequations}
These expressions can be intuitively interpreted as follows
\citep[\cf][]{lindleyetal1981}. The known and unknown sequences of data
together constitute a \enquote{population} where the different values in
$X$ and $Y$ appear with joint frequency density $F(xy)\,\di xy$. If we knew
such density, then our probability assessment for any new pair of values
would simply be $F(xy)$ owing to symmetry reasons. But since we do not know
the density $F$, we must marginalize over all possible such densities, each
given a probability, as in \eqn~\eqref{eq:marginalize_F}. The prior
probability density at frequency $F$ is $\p(F \| H)\,\di F$, which is
updated to $\p(F \| \bzz, H)$, \eqn~\eqref{eq:update_F}, when the training
data $\bzz$ are known.

If the training data are considered part of the scenarios, then our
probability distribution is
\begin{equation}
  \label{eq:prob_distr_conditional_withtraining}
  \p(\bz \| \bzz, H)\ \delt(\bzzi-\bzz)\ \di\bz\,\di\bzzi
\end{equation}
since the training data are known and their probability is one; the term
$\p(\bz \| \bzz, H)$ is still given by \eqns~\eqref{eq:exchangeable_prob}.




\subsection{Expected utilities and final choice}
\label{sec:expect_utilities}

According to decision theory every action $\theta$ has an associated
expected utility
\begin{equation}
  \label{eq:exp_utility_theta}
  E(\theta \| \bzz, H) 
\defd \iint U(\theta \| \bz) \ \p(\bz \| \bzz, H)\ \di\by\,\di\bx
\end{equation}
which, using \eqns~\eqref{eq:total_utility_final} and
\eqref{eq:exchangeable_prob}, becomes
\begin{subequations}    \label{eq:exp_utility_replace}
  \begin{gather}
\begin{multlined}[b][0.85\linewidth]
    E(\theta \| \bzz, H) =
      \frac{1}{Z(\bzz)}\iiiint \sum_{n} u[\yy{n} \| \theta(\xx{n})]\times{}\\ 
      \shoveright{\Bigl[\prod_{m} F(\yy{m}\|\xx{m})\ G(\xx{m})\Bigr]\
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\times{}}\\
      \p(F \| H)\
      \p(G \| \bzz, H)\ 
      \di\by\,\di\bx\,\di F\,\di G
    \end{multlined}
    \\\shortintertext{with}
    Z(\bzz) \defd
    \int \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\ \p(F \| H)\ \di F \ .
  \end{gather}
\end{subequations}
This expression can be simplified exchanging integrals and the sum in $n$,
and then integrating over the pairs $\di\yy{m}\,\di\xx{m}$ for which
$m \ne n$; such integrals give unity since $G$ and each $F$ are normalized.
We obtain
\begin{equation}
  \label{eq:exp_utility_simple}
  \begin{split}
    E(\theta \| \bzz, H) 
    &=
    \!\begin{multlined}[t][0.65\linewidth]
      \frac{1}{Z(\bzz)}\sum_{n} \iiiint u[\yy{n} \| \theta(\xx{n})] \
      F(\xx{n}\|\yy{n})\ G(\xx{n}) \times{}\\
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\ 
      \p(F \| H)\ \p(G \| \bzz, H)\
      \di\yy{n}\,\di\xx{n}\,\di F\,\di G
\end{multlined}
\\[3\jot]&\propto
    \!\begin{multlined}[t][0.65\linewidth]
      \iiint u[y \| \theta(x)] \
      F(y\|x)\ 
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\times{}\\
      \p(F \| H)\ \p(x \| \bzz, H)\
      \di y\,\di x\,\di F
       \ .
\end{multlined}
  \end{split}
\end{equation}
In the last expression we have renamed the dummy integration variables
$\xx{n}\yy{n}$ to $xy$, and performed a formal integration over $\di G$.
The terms of the sum in $n$ are therefore all equal, and the utility is a
multiple of any such term. We also omit the $\theta$-independent factor
$Z(\bzz)$. Thus the final expected utility of $\theta$, besides a constant
factor, is
\begin{multline}
  \label{eq:utility_final}
  E(\theta \| \bzz, H) 
= \iiint u[y \| \theta(x)] \
      F(y\|x)\ 
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\
      \p(F \| H)\times{}\\
      \p(x \| \bzz, H)\
      \di y\,\di x\,\di F\ .
\end{multline}

\bigskip

The formal solution to our decision problem is finally this: choose the
algorithm and internal parameters $\ctheta$ given by
\begin{empheq}[box=\widefbox]{equation}
  \label{eq:argsup_choice}
  \begin{multlined}[][0.8\linewidth]
  \ctheta \defd \argsup_{\theta} \iiint u[y \| \theta(x)] \times{}\\
      F(y\|x)\ 
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\ 
      \p(F \| H)\times{}\\
      \p(x \| \bzz\ H)\
      \di y\,\di x\,\di F
\ .
\end{multlined}
\end{empheq}

In the next section we analyse and discuss this formula, and study possible
approximations to it.

\section{Observations on the decision-theoretic solution}
\label{sec:observations_solution}

Formula~\eqref{eq:argsup_choice} presents three noteworthy points:
\begin{enumerate}[label=\textbf{(\Alph*)}, wide]
\item\label{item:nested_optim} The optimization can be separated into an
  optimization of internal parameters for each algorithm $i$, and then an
  optimization among algorithms, because we can first take
  $\ctheta_{i} \defd \argsup_{\theta \in \varTheta_{i}}$ for each $i$
  and then $\ctheta \defd \argsup_{\theta \in \set{\ctheta_{i}}}$.
  
\item\label{item:utility_vs_inference} There is a utility part
  $u[y \| \theta(x)]$, and a clearly distinguished inferential part
  $\p(\bz\|\bzz,H)$ rewritten in terms involving the conditional
  distributions $F$ and the probability distribution for $x$. The variable
  $\theta$, which runs over the candidate \ml\ algorithms and their
  internal-parameter values, appears only in the utility part, not in the
  inferential part. The latter is the same for all candidate algorithms.
  This fact has several important implications.

  First, it is inconsistent to use different algorithms, depending on the
  value of $\theta$, to compute the inferential part $\p(\bz\|\bzz,H)$. For
  example, it would be inconsistent to use a deep network $H_{\text{dn}}$
  to compute $\p(\bz\|\bzz,H_{\text{dn}})$, multiplying this probability by
  the deep network's utility $u[y \| \theta_{\text{dn}}(x)]$; and then use
  a probabilistic random forest $H_{\text{rf}}$ to compute
  $\p(\bz\|\bzz,H_{\text{rf}})$, multiplying this probability by the random
  forest's utility $u[y \| \theta_{\text{rf}}(x)]$; and so on. Only one
  algorithm should be used to compute $\p(\bz\|\bzz,H)$; this could be
  either an average over all candidate algorithms (with appropriate
  weights, as given by the probability calculus; see \cite[\sect~28.1
  p.~347]{mackay1995_r2005}), or the most probable among them (which would
  be equivalent to a maximum a-posteriori approximation).

  This fact may appear to conflict with analyses \citep[for
  example][\sect~5]{mackay1992}[\sect~2.2]{mackay1992b}[\sect~1.3]{bishop2006}[\chap~12]{barber2007_r2020}[\sect~1.4.8]{murphy2012}
  focused on an inferential-only interpretation. That kind of analysis
  involves a comparison among different models, based on the probabilities
  that they give to the data. However, such comparison is not meant as
  \emph{choice}\citep[\enquote{This paper concerns inference alone and no
    loss functions or utilities are
    involved}][footnote~1]{mackay1992}[\enquote{When we discuss model
    comparison, this should not be construed as implying model
    \emph{choice}}][\sect~28.1 p.~347]{mackay1995_r2005}, so there is no
  real conflict.


  Second, a probabilistic variant of a candidate algorithm might be most
  appropriate for the inferential part (for example because it is a
  non-parametric algorithm), and yet the final optimization might select a
  different candidate algorithm. \mynote{\wrench\ This must be explained
    much better.}
  
\item\label{item:px_needed} The optimization crucially depends on the
  distribution of probability over the future predictors: $\p(x\|\bzz,H)$.
  This fact makes sense. One algorithm might give correct predictions for a
  very wide range $\mathcal{W}$ of predictor values $x$, and poor
  predictions in the complementary, very narrow range $\mathcal{N}$;
  another algorithm might give poor predictions in $\mathcal{N}$ and
  correct predictions in $\mathcal{W}$. If future predictor values are much
  more probable to fall in $\mathcal{N}$ than $\mathcal{W}$,
    $\p(x \mo[\in] \mathcal{N}) \gg \p(x \mo[\in] \mathcal{R})$, then the
  second algorithm will yield a higher utility in the long run.

  The optimal choice of algorithm and internal parameters therefore
  requires an inference of probable future predictor values. Current
  practice in machine learning often neglects such inference. Indeed, the
  importance of such inference should be contrasted with the common routine
  of balancing the amount of training data among predictor domains.
  Balancing could actually be counter-productive.
\end{enumerate}


\section{Approximations and interpretations}
\label{sec:approx_interpr}

\subsection{Many-data approximation}
\label{sec:manydata_approx}

If we have many training data, with frequencies $\phi$, the predictive
conditional probabilities will be roughly equal to these frequencies:
\begin{multline}
  \begin{multlined}[][0.8\linewidth]
  \argsup_{\theta} \iiint u[y \| \theta(x)] \ 
      F(y\|x)\ 
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\ 
      \p(F \| H)\times{}\\
      \p(x \| \bzz, H)\
      \di y\,\di x\,\di F
    \end{multlined}
    \\
{}\approx \argsup_{\theta} \iint u[y \| \theta(x)] \ 
      \phi(y\|x)\ 
      \p(x \| \bzz, H)\
      \di y\,\di x
    \\
{}\approx \argsup_{\theta} \sum_{m} u[\yyy{m} \| \theta(\xxx{m})] 
\end{multline}

According to this interpretation \emph{the loss function used in machine learning
does not represent the logarithm of our uncertainty or of the distribution
of noise}: it represents the utility.


\subsection{Single algorithm and approximate inference}
\label{sec:single_alg_approx}

\mynote{\wrench\ Work in progress}

\begin{multline}
  \begin{multlined}[][0.8\linewidth]
  \argsup_{\theta} \iiint u[y \| \theta(x)] \ 
      F(y\|x)\ 
      \Bigl[\prod_{m} F(\yyy{m}\|\xxx{m})\Bigr]\ 
      \p(F \| H)\times{}\\
      \p(x \| \bzz, H)\
      \di y\,\di x\,\di F
    \end{multlined}
    \\
  \begin{multlined}[][0.8\linewidth]
{}= \argsup_{\theta} \iiint u[y \| \theta(x)] \ 
      f(y\|x, w)\ 
      \Bigl[\prod_{m} f(\yyy{m}\|\xxx{m}, w)\Bigr]\ 
      \p(w \| H)\times{}\\
      \p(x \| \bzz, H)\
      \di y\,\di x\,\di w
\end{multlined}
    \\
  \begin{multlined}[][0.8\linewidth]
{}\approx \argsup_{\theta} \iiint u[y \| \theta(x)] \ 
      f(y\|x, w^{*})\times{}\\
      \p(x \| \bzz, H)\
      \di y\,\di x\,\di w
\ .
\end{multlined}
\end{multline}

\section{Discussion}
\label{sec:discussion}


\mynote{\wrench\ To be written.

  Utility becomes unimportant when the inference is almost deterministic.
In modern \ml\ applications in particular fields such as medicine this
assumption may not be valid, owing either to the intrinsic, noisy
complexity of the phenomena involved, or to the scarcity of training data.}


% \[ \color{mypurpleblue}\bm{a} \color{myredpurple}\mathbin{\bm{\land}}\color{mypurpleblue} \bm{b} \]


%%%% examples use empheq
%   \begin{empheq}[left={\mathllap{\begin{aligned}    \de\yF_{\yc}/\de\yp&=0\text{:} \\
%         \de\yF_{\yc}/\de\ym&=0\text{:}\\ \de\yF_{\yc}/\de\yl&=0\text{:}\end{aligned}}\qquad}\empheqlbrace]{align}
%     \label{eq:con_p}
% %    \de\yF_{\yc}/\de\yp &\equiv
%     -\ln\yp + \ln\yq + \yl\yM + \ym\yu &=0,\\
%     \label{eq:con_u}
% %    \de\yF_{\yc}/\de\ym &\equiv
%     \yu\yp-1 &=0,\\
%     \label{eq:con_l}
%     %\de\yF_{\yc}/\de\yl &\equiv
%     \yM\yp-\yc &=0.
%   \end{empheq}
%%%%
% \begin{empheq}[box=\widefbox]{equation}
%   \label{eq:maxent_question}
%   \p\bigl[\yE{N+1}{k} \bigcond \tsum\yo\yf{N}\in\yA, \yM\bigr] = \mathord{?}
% \end{empheq}



% \[
%   \begin{tikzcd}
%       M_{n,n}(\CC) \arrow{r}{R'_{a}(\Hat{U})} & M_{n,n}(\CC)
%     \\
%     L(\mathcal{H}) \arrow{r}{\Hat{U}} \arrow[swap]{d}{R_*}\arrow[swap]{u}{R'_*} & L(\mathcal{H}) \arrow{d}{R_*}\arrow{u}{R'_*} \\
%       M_{n,n}(\CC) \arrow{r}{R_{a}(\Hat{U})} & M_{n,n}(\CC)
%   \end{tikzcd}
% \]

% \[
%   \begin{tikzcd}
%       \CC^n \arrow{r}{R'_*(A)} & \CC^n
%     \\
%     \mathcal{H} \arrow{r}{A} \arrow[swap]{d}{R}\arrow[swap]{u}{R'} & \mathcal{H} \arrow{d}{R}\arrow{u}{R'} \\
%       \CC^n \arrow{r}{R_*(A)} & \CC^n
%   \end{tikzcd}
% \]


% \[
%   \begin{tikzcd}
%     \mathcal{H} \arrow{r}{A} \arrow[swap]{d}{R} & \mathcal{H} \arrow{d}{R} \\
%       \CC^n \arrow{r}{R_*(A)} & \CC^n
%   \end{tikzcd}
% \]

%%\setlength{\intextsep}{0ex}% with wrapfigure
%%\setlength{\columnsep}{0ex}% with wrapfigure
%\begin{figure}[p!]% with figure
%\begin{wrapfigure}{r}{0.4\linewidth} % with wrapfigure
%  \centering\includegraphics[trim={12ex 0 18ex 0},clip,width=\linewidth]{maxent_saddle.png}\\
%\caption{caption}\label{fig:comparison_a5}
%\end{figure}% exp_family_maxent.nb


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Acknowledgements
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\iffalse
\begin{acknowledgements}
  \ldots to Mari \amp\ Miri for continuous encouragement and affection, and
  to Buster Keaton and Saitama for filling life with awe and inspiration.
  To the developers and maintainers of \LaTeX, Emacs, AUC\TeX, Open Science
  Framework, R, Python, Inkscape, Sci-Hub for making a free and impartial
  scientific exchange possible.
  % Our work was supported by the Trond Mohn Research Foundation, grant number BFS2018TMT07
%\rotatebox{15}{P}\rotatebox{5}{I}\rotatebox{-10}{P}\rotatebox{10}{\reflectbox{P}}\rotatebox{-5}{O}.
%\sourceatright{\autanet}
\mbox{}\hfill\autanet
\end{acknowledgements}
\fi

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Appendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%\clearpage
\bigskip
% %\renewcommand*{\appendixpagename}{Appendix}
% %\renewcommand*{\appendixname}{Appendix}
% %\appendixpage
% \appendix

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\renewcommand*{\finalnamedelim}{\addcomma\space}
\defbibnote{prenote}{{\footnotesize (\enquote{de $X$} is listed under D,
    \enquote{van $X$} under V, and so on, regardless of national
    conventions.)\par}}
% \defbibnote{postnote}{\par\medskip\noindent{\footnotesize% Note:
%     \arxivp \mparcp \philscip \biorxivp}}

\printbibliography[prenote=prenote%,postnote=postnote
]

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Cut text (won't be compiled)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


%%% Local Variables: 
%%% mode: LaTeX
%%% TeX-PDF-mode: t
%%% TeX-master: t
%%% End: 
