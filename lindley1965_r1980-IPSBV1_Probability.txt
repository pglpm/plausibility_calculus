INTRODHCTION TO 
PROBABILITY' AND 
STATISTICS 
FROM A BAYESIAN VIEWPOINT 
PART 1 
PROBABILITY 
BY 
D. V. LINDLEY 
Head of the Department of Statistic 
University College London 
CAMBRIDGE UNIVERSITY PRESS 
CAMBRIDGE 
LONDO'N NEW YORK NEW ROCHELLE 
MELBOURNE SYDNEY 
Published by the Press Syndicate of the University of Cambridge 
The Pitt Building, Trumpington Street, Cambridge CB2 1RP 
32 East 57th Street, New York, NY 10022, USA 
296 Beaconsfield Parade, Middle Park, Melbourne 3206, Australia 
� Cambridge University Press 1965 
ISBN 0 521 05562 8 hard covers 
ISBN 0 521 29867 9 paperback 
First published 1965 
Reprinted 1969 1976 
First paperback edition 1980 
Printed in Great Britain at the 
University Press, Cambridge 
M.P. MESHENBERG 
in gratitude 
vii 
CONTENTS 
Preface 
Probability 
Introduction 
1.1 The concept of a frequency limit 
1.2 The axioms of probability 
1.3 Independence 
1.4 Bayes's theorem 
1.5 Genetical applications 
1.6 Degrees of belief  
Exercises 
2 Probability distributions: one variable 
2.1 The discrete case 
2.2 The continuous case 
2.3 The Poisson process 
2.4 Features of distributions 
2.5 The simple random walk 
2.6 Generating functions 
Exercises 
3 Probability distributions: several variables 
3.1 The discrete case 
3.2 The continuous case 
3.3 Linear functions of random variables 
page ix 
1 
3 
6 
14 
19 
25 
29 
42 
49 
57 
63 
74 
82 
91 
97 
107 
117 
126 
VIII 
4 
CONTENTS 
3.4 Approximate means and variances 
3.5 Exact methods 
3.6 Limit theorems 
Exercises 
page 
Stochastic processes 
4.1 Immigration-emigration process 
4.2 Simple queueing process 
4.3 Queueing process with Poisson input and general 
service distribution 
4.4 Renewal theory 
4.5 Markov chains 
4.6 Markov chains (continued) 
Exercises 
Bibliography 
Subject Index 
134 
139 
150 
160 
174 
187 
193 
203 
215 
227 
235 
249 
253 
Index of Notations 258 
PREFACE 
The content of the two parts of this book is the minimum that, 
in my view, any mathematician ought to know about random 
phenomena probability and statistics. The first part deals with 
probability, the deductive aspect of randomness. The second 
part is devoted to statistics, the inferential side of our subject. 
The book is intended for students of mathematics at a univer- 
sity. The mathematical prerequisite is a sound knowledge of 
calculus, plus familiarity with the algebra of vectors and 
matrices. The temptation to assume a knowledge of measure 
theory and general integration has been resisted and, for 
example, the concept of a Borel field is not used. The treatment 
would have been better had these ideas been used, but. against 
this, the number of students able to study random phenomena 
by means of the book would have been substantially reduced. 
In any case the intent is only to provide an introduction to the 
subject, and at that level the measure theory concepts do not 
appreciably assist the understanding. A statistical specialist 
should, of course, continue his study further; but only, in my 
view, at a postgraduate level with the prerequisite of an honours 
degree in pure mathematics, when he will necessarily know the 
appropriate measure theory. 
A similar approach has been adopted in the level of the proofs 
offered. Where a rigorous proof is available at this level, I have 
tried to give it. Otherwise the proof has been omitted (for 
example, the convergence theorem for characteristic functions) 
or a proof that omits certain points of refinement has been 
given, with a clear indication of the presence of gaps (for 
example, the limiting properties of maximum likelihood). Pro- 
bability and statistics are branches of applied mathematics--in 
the proper sense of that term, and not in the narrow meaning 
that is common, where it means only applications to physics. 
This being so, some slight indulgence in the nature of the rigour 
is perhaps permissible. The applied nature of the subject means 
x PREFACE 
that the student using this book needs to supplement it with 
some experience of practical data handling. No attempt has 
been made to provide such experience in the present book, be- 
cause it would have made the book too large, and in any case 
other books that do provide it are readily available. The student 
should be trained in the use of various computers and be given 
exercises in the handling of data. In this way he will obtain the 
necessary understanding of the practical stimuli that have led 
to the mathematics, and the use of the mathematical results in 
understanding the numerical data. These two aspects of the 
subject, the mathematical and the practical, are complementary, 
and both are necessary for a full understanding of our subject. 
The fact that only one aspect is fully discussed here ought not to 
lead to neglect of the other. 
The book is divided into eight chapters, and each chapter into 
six sections. Equations and theorems are numbered i n the 
decimal notation: thus equation 3.5.1 refers to equation 1 of 
section 5 of chapter 3. Within � 3.5 it would be referred to simply 
as equation (1). Each section begins with a formal list of de- 
finitions, with statements and proofs of theorems. This is fol- 
lowed by discussion of these, examples and other illustrative 
material. In the discussion an attempt has been made to go 
beyond the usual limits of a formal treatise and to place the 
ideas in their proper contexts; and to emphasize ideas that are 
of wide use, as distinct from those of only immediate value. At 
the end of each chapter there is a large set of exercises, some of 
which are easy, but many of which are difficult. Most of these 
have been taken from examinations papers, and I am grateful 
for permission from the Universities of London, Cambridge, 
Aberdeen, Wales, Manchester and Leicester to use the questions 
in this way. (In order to fit into the Bayesian framework some 
minor alterations of language have had to be made in these 
questions. But otherwise they have been left as originally set.) 
The first part of the book, the first four chapters, is devoted 
to probability. The axioms of probability are stated in chapter 1 
and elementary deductions made from them. In chapters 2 
and 3 these results are applied to the study of random variables 
in one and higher dimensions respectively. Chapter 4 provides 
PREFACE xi 
an introduction to the study of stochastic processes, including 
queueing theory, renewal theory and Markov chains. 
The axiomatic structure used here is not the usual one asso- 
ciated with the name of Kolmogorov. Instead one based on the 
ideas of Renyi has been used. The essential difference between 
the two approaches is that Renyi's is stated in terms of condi- 
tional probabilities, whereas Kolmogorov's is in terms of 
absolute probabilities, and conditional probabilities are defined 
in terms of them. Our treatment always refers to the probability 
of ,4, given B, and not simply to the probability of A. In my 
experience students benefit from having to think of probability 
as a function of two arguments, A and B, right from the be- 
ginning. The conditioning event, B, is then not easily forgotten 
and misunderstandings are avoided. These ideas are particu- 
larly important in Bayesian inference where one's views are 
influenced by the changes in the conditioning event. 
Another novelty in chapter 1 is the extensive discussion of 
probability as a degree of belief in section 6. The reason for this 
is that the treatment of statistics in the second part of'the book 
is based on this form of probability. An attempt, at a modest 
mathematical level, has been made to justify the axiomatic 
structure for beliefs: in the hope that this will help to convince 
students of the reasonableness of the idea that beliefs can be 
measured numerically. The content of the first three chapters is 
a prerequisite for the second part on statistics. The study of 
stochastic processes in chapter 4 is not used in the latter part. 
I am extremely grateful to J. W. Pratt, H. V. Roberts, M. 
Stone, D. J. Bartholomew; and particularly to D. R. Cox and 
A.M. Walker who made valuable comments on an early version 
of the manuscript; and to D. A. East who gave substantially of 
his time at various stages and generously helped with the proof- 
reading. Mrs M. V. Bloor and Miss C. A. Davies made life 
easier by their efficient and accurate typing. I am most grateful 
to the University Press for the excellence of their printing. 
D.V.L. 
Aberystwyth 
April 1964 
PROBABILITY 
Introduction 
The object of this book is to provide an introduction to the study 
of random phenomena. Most phenomena studied in science are 
not looked at from a random viewpoint but from a deterministic 
one, and may often be put into the simple form of cause and effect: 
if A then B. When randomness is present A may sometimes 
cause B, but sometimes C. Nevertheless, random phenomena, 
like deterministic ones, are capable of mathematical description; 
and in this book we show how this can be done using probability 
ideas. There are two aspects to the study. In the first half of the 
book, chapters 1-4, we deal with several simple random pheno- 
mena combining together to produce a more complicated 
random situation: the argument is purely deductive. In the 
second half, chapters 5-8, inductive problems are considered. 
If AE always causes BE, and no two of the BE are the same, then it 
is a simple inductive process to infer that if BE is observed then 
AE must have been the cause. But if At can sometimes cause Be 
and sometimes B, then the cause of B may be either A or A 
and the induction is not so complete. Nevertheless, again using 
probability ideas, inductive statements can be made precise. We 
shall often use the term 'statistics' to cover this latter study and 
reserve the term 'probability' for the purely deductive part. 
Examples of deterministic statements of cause and effect are: 
if, under specified conditions, an electric current is passed 
through water, hydrogen and oxygen will be emitted; if the tem- 
perature of water is lowered sufficiently it will freeze; if a penny 
is released from the hand it will fall to the floor, and it can be 
calculated how fast it will fall. In contrast there are several situa- 
tions in which it does not seem possible to make such statements 
of cause and effect, or if they were made they would be too com- 
plex to be useful. A simple example is provided by the release of 
a penny. If the penny is given a spinning motion it is still true 
2 PROBABILITY 
that the penny will fall but it is not possible to say whether the 
effect will be that it will come to rest with the head or with the 
tail uppermost. Even if the initial conditions, or causes, were 
described with great care so that it would, in theory, be possible 
to predict the exposed face, it would not be useful to do so. 
Other, more practical, examples are commonplace. It is not 
possible to say whether or not an Englishman aged 40 will die 
within 10 years. It is not possible to say what the weather will 
be on a specified day a year hence. It is not possible to say what 
the hair colour of the child of brunette parents will be. It is not 
possible to say whether a given atom of uranium will disintegrate 
within 10 years. Here are several initial conditions but we can- 
not say what will be the corresponding effects. Although state- 
ments of the form, if A then B, cannot be made, important 
statements of a different kind can be made: witness, in the four 
examples quoted, the use of actuarial life tables, statements 
about climate, the science of genetics and the theory of radio- 
active decay. 
Granted that it is possib!e to. make prec. ise statements about 
the toss of a penny (the way this can be done is described in the 
following sections) it is possible to deduce other results. 'For 
example, it can be calculated how long one can expect to go on 
tossing until the numbers of heads and tails are equal (�4.4); or 
how many heads one can expect to get in ten tosses (�2.1). This 
is a matter of mathematical deduction like deducing that the 
sum of the angles of a triangle is two right angles from the postu- 
lated properties of lines and points. From the random way in 
which telephone calls are made we can deduce the demand on an 
exchange to which a group of persons are connected (��4.2, 4.3). 
We can answer questions such as what will be the effect of pro- 
viding more telephone operators? These are deductive prob- 
ability problems. Consider next a problem which is, in a sense, 
converse to the problem of the number of heads in ten tosses of 
a coin. If a penny has been observed to give eight heads in ten 
tosses is it likely to be a fair one obtained from a reputable mint ? 
By fair we mean, to anticipate terms to be introduced later, that 
it is 'equally likely' to come down heads or tails in a single toss. 
From the fairness of a single toss the number of heads to be 
INTRODUCTION  
expected in ten tosses can be deduced, as just mentioned. To go 
in the reverse direction, from the results of the tosses to the fair- 
ness, means an inductive process, and is a problem typical of 
statistics. It is discussed in �7.2. Examples of more practical 
statistical problems are, to infer from agricultural experiments 
(which are subject to substantial random variation) the relative 
merits of different strains of wheat (��6.4, 6.5); to compare the 
potencies of different drugs in an experiment on animals; to 
assess the accuracy of determination 'of a physical or chemical 
constant from an experiment which, like most experiments, 
must contain some randomness; and to detect and measure 
linkage between two genes. 
1.1. The concept of a frequency limit 
Consider a situation in which A can either cause an event B to 
occur or not, so that the situation is not deterministic. We say 
A either produces B or not-B, which we denote by . In many 
such situations it is possible to repeat A and observe, on each 
repetition, B or B. It is an empirical fact that often, as the 
number, n, of repetitions increases, the ratio of the number, m, 
of times B occurs to the total number of repetitions becomes 
stable and appears to tend to a limit. Each repetition is termed 
a trial, the occurrence of the event B is a success (and of B, a 
fitilure) and the ratio m/n the success (or frequency) ratio. The 
empirical observation can be expressed by saying that 'lim' m/n 
exists, where the limit symbol has been placed in quotation 
marks to indicate that the notion is not the same as the ordinary 
mathematical limit. The limiting number is the empirical value 
of the probability of B given A, which is written p(BIA). Any 
probability is a function of two arguments which are separated 
by a vertical line; the first is the event being considered, the 
second describes the conditions under which it is being con- 
sidered and is called the conditioning event, or simply the 
condition' here, the event 'the occurrence of B' is being con- 
sidered under condition A. In the next section axioms for 
probability suggested by this empirical fact will be given. 
4 PROBABILITY [1ol 
Empirical resttits 
The simplest examples of repetitions of trials are provided by 
games of chance. If A denotes the toss of a penny and B denotes 
the fall of it with head uppermost, then repetitions are possible 
and the empirical fact observed. The limit is the probability of 
head on the toss of a coin. Kerrich (1946) carried out numerous 
experiments in order to demonstrate the stability of the success 
ratio' for example, he spun a coin 10,000 times and demon- 
strated that the ratio for 'heads' kept very near to 1/2. 
If A denotes the roll of a die and B the occurrence of some 
number, or set of numbers, then again the empirical limit can be 
observed. Weldon rolled some dice and exhibited the stability of 
the success ratio for the event B, ' a 5 or 6'. The limit was not 1/3 
as one might expect for a 'fair' die but somewhat more. It is 
relevant to notice that there is nothing in the above statement' 
about the existence of the limit to say what the limit is. For a. 
newly minted coin in our first example the limit is probably 1/2, 
but for a badly bent one it might well, as with Weldon's dice, be 
different from the ideal value. 
The ultimate justification for probability does not lie in such 
experiments but rather in the practical success with which the' 
theory has been applied. The prosperity of insurance houses is 
a witness to the value of statements about the probability of 
death. The science of genetics is based on the same sort of head 
or tail phenomenon as coin-tossing' will the gene transferred 
from parent to offspring be B or b ( = B) ? A breeding programme 
will provide the repetitions in which the stability can be observed, 
but this is secondary to the success of deductions from the 
theory. Games of chance provide the oldest example. The 
Chevalier de M6r6 played so many games that he was able, on 
empirical evidence alone, to detect that a certain limiting success 
ratio was less than 1/2: the mathematician Pascal showed that 
it was 0.491 by suitable application 'of probability theory. In 
radioactive studies the' half-life' term is another way of express- 
ing the limit' in repeated observations on different atoms, a 
success, namely decay, will Mve been observed in about 1/2 of 
them after the lapse of time equal to the 'half-life'. 
The conditioning event 
It is important to notice that the conditioning event A is just 
as relevant to the probability as is the event B. Consider tossing 
a coin where the event B, of success, is a head. Then, if the coin is 
a newly minted one, the probability will be about 1/2, but if the 
coin is badly bent, or if a piece of chewing-gum is stuck on to 
one face, the probability of the same event may be very far 
from 1/2. It is easy to produce paradoxes by failing to mention 
the conditioning event. Of course, in a series of trials it is impos- 
sible to keep the conditioning event completely constant. At 
least the time the trials are carried out will be different and 
typically the coin or die will show wear. But such difficulties of 
precision always arise in discussing the relationship between 
theory and practice :' it is useful to think of an object as having 
a fixed weight, for example in use on a balance, but this is not 
precisely true. Conditions for the limit to exist within the 
theory will be given in {}3.6 (theorems 2 and 3). 
The form of' lin' 
The limit here is not a mathematical limit. That is to say, given 
any small positive number c, it is not possible to find a value N 
such that Im/n-pl < c for all n > N, where p = 'lira' m/n, as 
would be required of a mathematical limit. For there is nothing 
impossible in m/n differing from p by as much as 2e, it is merely 
rather unlikely. And the word unlikely involves probability 
ideas so that the attempt at a definition of 'limit' using the 
mathematical limit becomes circular. The axiomatic approach 
(� 1.2) avoids the difficulty,. and the empirical observation will 
not be used to define probability, but only to suggest the axioms. 
Examples 
The probability statements that can be made in the. examples 
used in the introduction are the following. The probability 
that an Englishman aged 40 will die within 10 years is 0.05: 
the event B is death within 10 years, A is the condition 'an 
Englishman aged 40'. The probability of rain at a specified 
6 PROBABILITY [1.1 
place on a given date can be found from the rainfall statistics. 
The probability that the offspring of heterozygous parents will 
exhibit the recessive phenotype is �. The probability of decay of 
a uranium atom within 4.49 x 10 9 years is �. All these results are 
based on the observation of repeated trials, supported, in the 
genetic case particularly, by additional indirect evidence. 
1.2. The axioms of probability 
The notion of an event is first formalized, and then the notion 
of the probability o� an event. We consider a sample space, A, 
consisting of points, a, called elementary events. An event is a 
collection or set of elementary events and is denoted by a capital 
letter A, B, C, ..., with suffixes A, A2, ..., where necessary. If 
a belongs to A we write a c A. Selection of a particular a is 
referred to by saying 'a has occurred'. If a A and a has 
occurred we say A has occurred. If A and B are two events, the 
set of a such that both a c A and a  B is denoted by AB. If AB 
has occurred then both A and B have occurred, and conversely. 
If {As} is a sequence of events, the set of a which belong to at 
least one A,,. is denoted by 22 A,. If 5; A has occurred then at 
least one A,. has occurred, and conversely. The members of the 
sequence are exclusive given C, if whenever C has occurred no 
two of them can occur together, that is if A,,AC is the empty 
set whenever m 4= n. If the Conditioning event C is A, the 
sample space, then, in this last definition, and similar ones, the 
words 'given A' are omitted. If Z A,, = A, that is, if every a 
belongs to at least one A;, then {A,} is said to be exhaustive. 
For certain pairs of events, A and B, a real numberp(A{B) is 
defined and called the probability of A given B. These numbers 
satisfy the following axioms: 
Axiom 1. 0 </(A]B) < 1 and p(A I A) = 1. 
Axiom 2. If the events in {A,} are exclusive given B then 
p(22A, lB) = Zp(A[B). 
Axiom 3 p(CIAB)p(AIB ) = p(ACIB). 
1.2] THE AXIOMS OF PROBABILITY 
The role of the axioms 
The principle behind the construction of any axiom system is 
that a mathematical representation should be made of certain 
aspects of the real world. The elements in the mathematics are 
not parts of the real world but only representations of them. 
The elements are given properties (called axioms) supposed to 
reflect the behaviour of the corresponding parts of the real 
world. These properties can then be used in conjunction with the 
rules of mathematical logic to deduce other properties (within 
the mathematical system) which may be compared with the real 
world. If the axiomatization has been successful the comparison 
will lead to fruitful new ideas. The classical example is Euclid's 
geometry with axioms about lines and points, etc., such as 
'through two points passes a unique line' and deductions like 
'the sum of the angles of a triangle is two right angles'. Let us 
consider the axiom system described above in relation to the 
real phenomenon of tossing a penny. 
The sample space 
The event of a penny being tossed is more complicated than 
a mere occurrence of heads or tails: we could also consider its 
position of fall, the time of fall, etc., indeed countless other 
facets of the toss. Any particular toss may be represented by 
a point a and all possible tosses form the sample space. The 
collection of those a which result in heads is the event of heads 
having occurred. Any elementary event then will contain 
details of what penny was tossed, when and where it was tossed, 
etc. It is not necessary to be explicit in saying what is or is not 
contained in the description of an elementary event: it can be 
thought of quite abstractly as the toss being considered. It is 
often helpful to represent each elementary event by a point on 
the paper, and an event by a region of the paper containing the 
points representing the elementary events contained in the event. 
If A and B are two events so represented then the event A + B is 
represented by the region which consists of the sum of the two 
regions for A and B. The event AB is represented by the region 
common to that for A and that for B. Thus in fig. 1.2.1 the event 
8 PROBABILITY [1.2 
A is represented by the horizontal rectangle: the event B by the 
vertical rectangle. A + B is represented by the T-shaped figure 
and AB by the shaded square. Such a representation is called 
a Venn diagram. It will be found useful in understanding the 
proofs of the theorems in the next section. 
Empirical justification for the axions 
Consider an event consisting of all tosses with a given coin 
under a standard set of conditions. Denote this event by B and 
the event of heads by A. Then p(A[B) is the mathematical 
representation of the frequency limit discussed in � 1.1. To see 
.4 
B 
Fig. 1.2.1. Venn diagram for two events, A and B. 
this, consider each axiom in turn. The frequency limit obviously 
lies between 0 and 1 and if we confine attention to tosses 
resulting in heads, so that the conditioning event is 'heads', 
then heads will always result and the limit necessarily be one, so 
that in any representation p(AIA ) must be one. This explains 
the first axiom. To appreciate the second consider N different 
events A, A2, ..., AN concerning the outcome of the toss which 
are such that, given B, no two can occur together (they are 
exclusive, given B). For example, let At be the event that in the 
final rest position of the penny the acute angle between a fixed 
line on the head of the penny and a fixed line on the table lies 
between (i- 1) rt/2M and irr/2M, the former limit being included 
and the latter excluded and M exceeding N. Then if, in n tosses, 
1.2l THE AXIOMS OF PROBABILITY 
Ai occurs mi times, the event Z A (at least one A occurs) 
occurs Z m times. (This would not necessarily be true if the 
were not exclusive.) The success ratio for Z At is 5', m/n, the 
sum of the success ratios for the individual events. Since the 
success ratios have this property it is reasonable to assume the 
same for their limits. Hence the second axiom. It is mathe- 
matically convenient to suppose this property holds for a count- 
ably infinite number of events' as well as for a finite number; the 
right-hand side will then be an infinite series, converging to the 
value on the left. 
The first two axioms apply with a fixed conditioning event B. 
This is not so with the third axiom where two conditioning 
events B and/lB both occur. To interpret this axiom let .4 and B 
be as before and let C be the event/l, say, just referred to. Con- 
sider n tosses with the given penny under standard conditions, 
that is n occurrences of event B. Suppose there are rn heads, 
occurs m times. Suppose that amongst those m occasions C also 
occurs on r of them; so that r is the number of times the event 
A C occurs. Then trivially we have 
Now let n - , and hence m -- c unless/(AIB) = 0. Then 
'lim' r _- lo(C[AB), 
since the conditioning event is AB which occurs rn times, and 
the observed event is C which occurs on r of these m occasions; 
'lim' rn = p(AIB) and 'lim'r = lo(,4C[B) similarly. 
Consequently the third axiom is a reasonable limiting inter- 
pretation of the trivial result. If p(AIB ) -- 0, then necessarily 
p(ACIB) = 0 since/lC is of rarer occurrence than A, and the 
result persists in that case. This completes the justification for 
' The number of events (or other concepts) is countably infinite if they can be 
put into one-to-one correspondence with the integers 1, 2, .... 
10 PROBABILITY [1.2 
the axioms in the coin-tossing case: the reader might like to 
carry through one of the other examples similarly. 
The reader may wonder why the complicated sample space 
of elementary events was introduced at all. Certainly, in simple 
problems like heads or tails in tossing pennies, it is not essential 
to have more than two distinct elementary events, 'heads' and 
'tails' and it is often enough to use this sample space. But it is 
an advantage to consider the full sample space because then any 
event (such as C above) can also be discussed without changing 
the sample space. Had the sample space of only two elements 
been used, it would have had to have been altered before C 
could be discussed. Since the elementary events need not be 
formulated explicitly there is great advantage and little real 
addition in complexity in enlarging the sample space to its full 
extent. Furthermore, in defining the probabilities, it is only 
necessary to consider the events, and not the elementary events, 
so that the introduction of complicated elementary events does 
not increase the difficulty of defining the probabilities. Thus, in 
coin tossing, however invol. ved the description of the individual 
tosses be, only the events of heads and tails need be considered. 
Fixed conditions 
It often happens throughout a probability calculation that 
one event B always occurs as part or the whole of the condi- 
tioning event: for example, the event B just defined as tosses 
with a single coin under standard conditions. B is often the 
whole sample space, A, or may be taken to be that (see the 
comment on theorem (1.4.1) below). It then economizes on 
notation to write p(A) for p(A[A) and p(A[ C) for p(A [AC), 
omitting reference to B = A. Indeed most writers on probability 
define probability as p(A), a function of a single event: but this 
can be misleading and it pays to remember the conditioning 
event. To omit it is rather like considering an effect without its 
cause. (Compare the discussion in � 1.1.) 
One method of constructing a probability system is as follows. 
With certain events, A, associate a real number p(A) satisfying 
Axiom la. 0 <p(A) < 1 and p(A) = 1. 
.21 
Axiom 2a. 
THE AXIOMS OF PROBABILITY 11 
If the events in {A,,} are exclusive, given A, then 
P(Z &) = Z P(An). 
Define p(AIB) by p(Al B) = p(AB)/p(B) unless p(B) = 0 when 
it is undefined. Then it is easy to verify that P(AIB ) satisfies 
axioms 1-3. Most probability systems can be constructed this 
way but there are exceptions (see example 3, below). Notice 
thatp(A) = p(A I A). p(A) is sometimes called an absolute prob- 
ability and p(A I B) a conditional probability: but all probabilities 
are really conditional ones. 
Notice that we have not stated for which events p(A[B) is 
defined: we have merely said 'for certain pairs of events, 
A and B, ... '. At the level of mathematical discussion used in 
this book we shall scarcely ever have any trouble over this 
matter. The only difficulty we shall encounter is that sometimes 
p(A[B) cannot be defined because p(B) = 0. This is especially 
so in the construction of a probability system using axioms 1 a 
and 2a wherein p(A]B) = p(AB)/p(B). Within the full axiom 
system this point does not arise so often: an illustration is giv 
in example 3 below where p(B), in the notation of that example, 
is zero yet p(AjlB ) is defined. Readers with the requisite mathe- 
matical knowledge may recognize that the observed events A will 
have to belong to a Borel fieM or it-algebra. The conditioning 
events will have to belong to a subcollection of the Borel field. 
A complete discussion is given by Renyi (1962), or using axioms 
1 a and 2a by Love (1960) and many others. 
Odds 
It is sometimes convenient to use another language to describe 
probabilities. This is the language favoured by bookmakers and 
will be used in � 1.6 when we discuss a different type of prob- 
ability from that based, as here, on frequency considerations. 
If Ax and A. are two exclusive events (usually A. -- Ax) then the 
odds on A against A., given B, is the ratio p(Axl B)/p(A21 B) to 1. 
Odds do not usually have such simple properties as probabilities 
but sometimes, especially in using Bayes's theorem (1.4.6), the 
ratio occurs more naturally than the separate probabilities. An 
12 PROBABILXTY [1.2 
illustration occurs in example 1.4.2. If A2 = A- andp(Atl B) =p, 
then the odds are p/(1-p) = b, say, to 1 and p -- b/(1 +b), so 
that the odds and probabilities are equivalent in the sense that 
one can be found from the other. 
Examples 
It is remarkable that these three quite simple axioms are 
enough to build up the whole structure of probability theory 
with the aid only of mathematical logic; but it is so, and the rest 
of this book will demonstrate it. There is an advantage in 
keeping the axioms few and simple because it becomes an easy 
matter to check whether any system is a probability system by 
seeing if it satisfies the axioms. If it does, any probability 
theorem may immediately be applied to this system. We now 
give four examples of probability .systems. 
Example 1. Let A be the unit interval of real numbers a. The 
method of axioms 1 a and 2a is used to construct a probability 
system. Let A be any interval contained therein: that is A is the 
set of numbers a satisfying at < a < a. where 0 < at < a2 < 1. 
Define p(A) as the length(a.-a) of the interval A. Let other 
sets have probabilities defined by axiom 2a. It is clear that 
p(A) satisfies those two axioms and consequently p(AIB ) = 
p(AB)/p(B) satisfies axioms 1-3, provided B has not zero length, 
when p(A[B) is undefined. 
Two important points emerge from this example. First, 
length has basically the same mathematical properties as 
absolute probability--indeed it is a special case. Probability is 
therefore often called, for a fixed conditioning event, a measure; 
length is a particular measure. It will often be convenient in 
subsequent developments to use an interpretation of probability 
in terms of length, area or volume. Secondly, we see how the 
brevity and simplicity of the axioms make it easy to verify 
whether or not any mathematical set-up can be interpreted as 
a probability. 
The example might be relevant if an experimenter was 
measuring an angle. If t7 is the angle in radians with a fixed 
direction, then a = t9/2r lying between at and a. would corre- 
spond to the occurrence of the event A above. If all angles were 
1.2] THE AXIOMS OF PROBABILITY 13 
equally likely (in the colloquial use of the term) then p(A) is as 
in the example, and the mathematical set-up is an interpretation 
of the colloquialism. Roulette is a possible situation where all 
angles are equally likely: if A is the event 'black' and B the 
event' even' then p(A [ B).is the probability of' black' given that 
the ball is in a compartment with an even number. 
Example 2. Suppose that, in a single trial, there are only a 
finite number of possible exclusive events, At, A., ..., A. These 
may be taken as the elementary events and the sample space 
contains k points. Let Pt, P2, ..., P be non-negative numbers 
with Z Pi = 1. It is easy to verify that with p(AO = Pt, axioms 
1 a and 2a are satisfied and hence a probability system can be 
constructed. It is called the finite discrete case. In the case 
k - 2, A2 = At and the event At is observed either to occur or 
not. k = 6 is relevant when rolling a die and for a 'true' die 
Pt = 1/6 for all i. The sample space consists of k points and Pi is 
often called the probability mass at the point. Indeed an analogy 
with mechanics is possible in both examples 1 and 2. The first 
may be compared with a uniform rod of unit length: the second 
with a number of particles of masses proportional to the prob- 
ability masses and situated at the points in sample space. The 
notions of centre of gravity and moment of inertia have 
probability analogues (see ��2.1, 2.2, 2.4). 
Example 3. The former example extends to a countably 
infinite number of exclusive events, At, with {Pt} a sequence of 
non-negative numbers whose sum converges to one. Whilst this 
covers a wide class it does not include the case where all events 
have the same probability, because an infinity of numbers Pt 
cannot be all equal and have sum 1. To include this important 
case the full axiom structure has to be used; the probability 
system cannot be defined by absolute probabilities as in the 
other examples. Instead we define p(AjlB ) whenever B = Y Am 
=1 
(the summation being over any finite number, n, of events) as 
n - if A. is one of A and 0 otherwise. We leave the reader to 
check that this defines a probability system satisfying axioms 1-3. 
The definition of p(AjlB ) means that amongst any finite collec- 
tion, B, all events are equally likely. 
14 PROBABILITY [1.2 
Example 4. Suppose an actuary is considering the insurance 
of lives of Englishmen. Then he will formally be considering 
a sample space of all Englishmen alive at a given date, and each 
elementary event will correspond to one Englishman. Part of 
the description of a man is his age and consequently he will be 
able to talk of the event of being over 40 as that event which 
contains only those elementary events having that property. If 
only this event is of interest then the finite discrete case of 
example 2 is relevant with k = 2, Ax being over 40 and A2 = ,T, 
and probability may be defined as in that example. But he may 
also wish to consider the men's heights, weights, blood-sugar 
contents, etc., and more complicated events have to be con- 
sidered. We shall have to leave the problem of defining proba- 
bilities for such events until chapters 2 and 3. 
1.3. Independence 
Two events, A and B, are said to be independent given C if 
p(aB I C) = p(a [ c) p(B[ C). (1) 
This is a particular case or'the following important 
Definition. The events, finite or infinite, of a sequence {A,,} are 
independent given B if, for any finite collection of them, say 
A.,q, A,, ..., A, k, the equation 
p(A,q A,, ... A,,k I B) = p(An 1 B) p(A, l B) ... p(An lB) (2) 
obtains. 
An A,=... A,, denotes the event which occurs iff' all the events 
A, A., ..., A,, occur: it is an extension of the notation AB 
used in � 1.2. If B = A we sometimes omit reference to the 
conditioning event (cf. �1.2) and speak of the events being 
independent, writing p(A, I A) = p(A), etc. 
Justification for the definition 
The motivation behind the first definition is that in some 
circumstances the occurrence of B may not affect the probability 
of occurrence of A. Suppose C has occurred and is the condi- 
tioningevent; thenp(A [ C)measures the frequency of occurrence 
 ' iff' means ' if and only if'. 
1.3] INDEPENDENCE 15 
of A in these conditions. Suppose one is then told that, in 
addition to C, another event B has occurred: then the condi- 
tioning event is BC and one appears to have been given more 
information than originally when one was told only that C had 
occurred. Or, to look at it another way, BC contains certainly 
no more, and typically fewer, elementary events than C. The 
new frequency of A is measured by p(AIBC). Now it may 
happen that B in fact provides no new information about the 
probability of A, that is 
p(A I BC) = p(A l C), (3) 
in which case it is reasonable to describe A as independent of B 
given C. As it stands this definition is not symmetric in A andB 
but if each side of (3) is multiplied by p(B]C), and axiom 3, 
Which in the notation of this section reads 
P(A I BC ) p(B[ C) = p(AB I C), 
is used on the left-hand side, we obtain (1) and use this as a 
(symmetric) definition of independence. 
An example of independent events is provided by considering 
the sample space consisting of simultaneous tosses of two coins: 
under reasonable conditions the events 'head for first coin' and 
'head for second coin' will be independent (given A). An 
example of non-independent events is provided by considering 
the sample space of all possible weather conditions at a fixed 
place over two consecutive days: the events 'rain on the first 
day', A, and 'rain on the second day', B, are not independent 
(given A), for it is an empirical fact that P(BIA ) > p(B), since 
consecutive days tend to be alike. Independence of transmission 
of two genes, and non-linkage of them, are two expressions of 
the same idea. For if one gene is linked with another the occur- 
rence of one in an offspring increases the probability of occurrence 
of the other: this does not happen if they are not linked. 
The extension to more than two events requires care. If a set 
of events is to be independent it should mean that if any number 
of them are known to have occurred the probability of any other 
one of them should be unaltered: in symbols 
P(& [ & ... AskS) = p(& lB). (4) 
16 VROB,Bg.rY [1.: 
'The symmetrical form of this is equation (2). It is enough in 
most applications to use only finite collections. Notice that, 
even for a finite set of N events, it is not enough that 
p(AxAa ... ANIB) = p(AxlB)p(A.IB) ...p(AvlB), (5) 
for this does not imply, for example, when N > 2, 
p(AA lB) = p(A lB) p(A [ B), (6) 
so that, when ts equation is violated, A on its own may give 
formation about Av Equations (2) and (4) must hold for all 
finite collections. The phrase stochastically independent is some- 
times used to distinguish the concept from that of functional 
independence. It is usually clear which is intended and only 
in cases of doubt will the qualification be inserted. Stochastic 
is a synonym for probability (as an adjective). 
Random trials 
An important case of independence arises in certain types of 
trial (�1.1). Each trial can result in success or failure. It is 
convenient to represent a success by 1 and a failure by 0. Then 
the outcome of a sequence of trials can be represented by a 
sequence (finite or infinite according to the number of trials) of 
O's and l's, and each elementary event-is such a sequence. Let 
At be the event, a 1 in the ith place, or equivalently a success in 
the ith trial. If the At are independent (given A) we say that the 
sequence of trials is random: the result of one trial does not 
affect probabilities in any other trial. Coin tossing provides an 
example. A random sequence of trials with p(A) = p for all i 
is called a random sequence with constant probability of success, 4f 
and it is to such a sequence that the empirical limit of the success 
ratio' applies. In �3.6 a result will be proved which represents, 
within the mathematics, the empirical fact of the existence of the 
limit. Notice that the limit may exist when the trials are not 
independent; for example, where the trials are days and failure 
is rain; then climate is an expression of the limit but, as 
already mentioned, successive days are not independent. 
Sometimes it is called a Bernoulli sequence. 
1.3] INDEPFNDENCI 17 
Populations 
A second example of independence arises with groups of 
people, animals, insects, etc. Such a group is termed a popula- 
tion. Let a population contain N members, and consider a 
sample space of N ' points, each point consisting of n members 
of the population arranged in order, repetitions being allowed, 
no two points being the same. Define a probability system by 
letting each elementary event have probability N-'*. This is a 
finite discrete sample space (example 2 of � 1.2). Let A o be the 
event that the jth member in the order be the ith member of the 
population. Then clearly P(Aij ) = N - and Aij and Ak are 
independent for j e k. Each elementary event is termed a 
random sample of size n with replacement from the population. 
In practice this example arises when one member of the popula- 
tion is taken, inspected and returned to the population; then a 
second member taken, and so on; where, at any stage, each 
member has the same chance (or probability) of being taken, 
namely N -, and n members are taken. Such a process is called 
random sampling with replacement. It is more usual to sample 
without replacement, i.e. the taken member is not returned to 
the population. Here the sample space contains only the 
N(N- 1) ... (N-n + 1) = N!/(N-n)! arrangements ofn different 
members in order, and, if each member left has the same chance 
of being taken, each elementary event has probability (N- n) !IN!. 
Clearly p(A.) = N -x but p(Ai21AO = (N-l) - for i q= j 
because the second member cannot be j, so there are only 
(N- 1) left to choose from. Hence Ai. and A.t are not indepen- 
dent. Each elementary event is a random sample of size n without 
replacement: this being the more common form it is often called 
simply a random sample. Such a sampling technique is some- 
times used with human populations in social studies but it is 
often difficult to ensure that all members have the same chance of 
appearing in the sample, and more complicated methods are used. 
If N is large compared with n, that is a small sample is taken, 
then the departure from independence due to the non-replace- 
ment is not every great as (N-1) -x is little different from N -x. 
Even when the last member of the sample is about to be 
18 PROBABILITY [1.3 
taken each member left in the population has only probability 
(N-n + 1) - of being taken, again little different from 
Often N is taken to be infinite. The mathematical model for this 
is more complicated and cannot be constructed from absolute 
probabilities as described in � 1.2 and used here for finite N. 
The method of example 3, � 1.2, has to be used. The elementar3 
events are arrangements of n different members of the popula- 
tion. Let B be any set of k (finite) elementary events. Then 
p((a)l B ) = k - if a � B and zero otherwise, where (a) is the 
event consisting of the single elementary event a. This defines 
a random sample of size n from an infinite population. The 
reader can verify that p(Ai[ AjB) = p(A.,: [ B) whenever B is 
finite and symmetric in a finite number of members including 
i an.d j, i 4= j; that is, conditional on a finite number of members 
of the population being used to form the sample. Hence given 
B, Ai and Ajx are independent. 
If a proportion p of the members of a population possess 
some character, then the random sampling may be thought of as 
n independent trials with probability p of success (an individual 
possessing the character). If the population is finite this ignores 
the dependence due to nonreplacement of members in the 
population; but is exact for infinite populations and is a reason- 
able approximation for large populations. Hence a probability 
may often be thought of as a proportion in a population. This is 
useful in genetics. The relationship between 'probability of 
rain tomorrow' and' proportion of rainy days' is similar, though 
here the population of days is not as real as an animal popula- 
tion. Some authors use hypothetical populations (usually 
infinite) but this is unnecessary. Populations need never be used 
but the idea is often useful. When they really exist (as with 
animals) then they can be represented, as just described, within 
the axiom system. 
The idea of the last paragraph may be generalized from the 
case where each member does, or does not, possess a character- 
istic, to the case where each member has associated with him 
a real number; for example, his height (see the discussion on 
histograms in � 2.4). Random samples of this type are basic in 
statistical arguments (see � 5.1). 
1.4] BAY�S'$ TH�OR�M 19 
1.4. Bayes's theorem 
The second axiom is often called the addition law of proba- 
bilities. Similarly, the independence condition (1.3.2) is often 
called the multiplication law of probabilities. Notice that the 
addition law only holds for exclusive events and the multiplica- 
tion law for independent events. We now deduce, from the 
axioms, other simple but useful results. Where they do not lose 
their content by doing so, the theorems will be stated and proved 
with A as the conditioning event. p(A[A) will be written p(A). 
The general result for any conditioning event B can be obtained 
by inserting 'given B' at obvious places (for example, after 
'independent'), inserting B after the vertical line and replacing 
p(.) by p(. lB). The advantage in only using A is that the results 
are more easily understood. Notice that with B = A the third 
axiom reads 
p(ClA) p(A) = p(CA). (1) 
Theorem 1. p(AIB) = p(ABI B). 
This follows from the third axiom which says that 
p(AB I B) = P(A I BB) p(B I B) 
which equals p(A[B) since BB = B and p(BIB ) = 1 by the first 
axiom. 
An event A is said to imply, given C, an event B if, given C, 
whenever A occurs, B occurs: alternatively, every a E AC also 
belongs to B; or the part of the set A which is in C is part of the 
set B. Then ABC = A C, or if C = A, AB = A. 'A Venn diagram 
may help the reader (�1.2). 
Theorem 2. If A implies B 
- p(AIB) p(B) = p(A). 
This follows, with a change of notation (A for C, B for A), 
from (1) with the condition AB = A. 
Theorem 3. If A implies B, p(A) < p(B). 
We have, from theorem 2, p(A) = p(A[B)p(B); 
p(AIB) < 1 by the first axiom and the result follows. 
but 
20 PROBABILITY [1.4 
Theorent 4 (Generalized addition law). If (A) are exclusive and 
exhaustive and B is ao' event, then 
p(B) =  p(Bl& ) p(n,3. 
By (1) each term on the right-hand side is p(BA,,). Since the 
(A,,} are exclusive and exhaustive the {BA,,} are exclusive and 
 A,,B = B. The result follows from the addition law. 
Theorem 5. If p(B) does not vanish then 
p(A I B) = p(BI A) p(A)/p(B). 
This is immediate from (1): 
Theorent 6 (Bayes's theorem). If {A,} is a sequence of events and 
B is ao' other event with p(B) 4= O, then 
p(A., lB) oc p(B l &) p(A 
This follows from theorem 5 on putting A, for A. The missing 
constant of proportionality is p(B) 4. 
Corollary. If, h addition, the {A,,} are exclusive and exhaustive 
then 
p(A lB) = p(B I A,,. ) p(A.,)/Z p(B I A,) p(AO. 
�  
This is immediate on rewriting p(B) as a summation, by the 
generalized addition law (theorem 4). 
Theorem 7. If {A,,} are exclusive and not all p(A,,) = 0, and B is 
any event, then 
p(B I ; A = Y, p(B l &) p(A,,)/Y p(A,,). 
The left-hand side is 
p(B Z A,,)/p(5 A,,) = Y, p(BA,,)/Y, p(A,,), 
on application of the addition law to numerator and denomi- 
nator; which is valid since {A,,} and hence {BA,,} are exclusive. 
The result follows since p(BA,) = p(BIA, ) �(A,). 
1.41 BAYES'S THEOREM :21 
Theorem 8 (Generalized multiplication law). lf ,,l, A2, ..., As are 
any et;ents and the e;ent ,,tt,,t2 ... ,,l_ has not zero probability, 
then 
p(AA. ... A,) = p(A) p(A [A) p(Al AA2) ... 
p(A [ Ai A. ... A_i). 
The result is immediate by repeated use of (1). 
The reader should follow through the simple proofs if only to 
convince himself that our results do follow from the simple 
axioms. Theorem 1 is a reflexion of the fact that, given B, only 
elementary events in B need be considered and A may be re- 
placed by AB: elementary events il A but not in B are irrelevant. 
This explains why, if one conditioning event occurs throughout 
a calculation, reference to it can be omitted. For, if B always 
occurs, since p(AB[ B) = p(A [ B), only that part of A in B need 
be considered in place of A. It is unnecessary to take account 
of A without B. Theorem 2 is merely a special case of (1) and is 
used, for example, in deriving equation 1.5.7. Theorem 3 is 
useful when proving that a sequence of probabilities {p(A,.) 
tends to zero. If A, implies B it may be easier to prove p(B,) 
tends to zero. Wide use is made of theorem 4 in calculating 
p(B) when B can happen in several ways, corresponding to the 
A,. The following example illustrates a use of theorem 4. 
Example 1. The sample space is the space of all human twins 
(cf. �1.3). A pair of twins can either be identical, an event 
denoted by A, or they can be fraternal, which is the comple- 
mentary event to A and therefore denoted by A. Similarly, the 
pair can either be both male, MM, both female, FF, or of mixed 
sex, MF. The problem is to estimate empirically the probability 
of a pair of twins being identical' in other words the proportion 
of identical twins amongst the population of twins. This is 
somewhat difficult to do directly because it would involve 
determining whether or not a given pair was identical; a diffi- 
cult, if not impossible, procedure. However, the probability 
of both members being male can easily be found, and using the 
conncxions between the events MM, MF and FF on the one 
hand, and the event A on the other, the unknown p(A) can be 
22 PROBABILITY [1.4 
found. We shall assume these connexions to be of the following 
form .' 
p(MMI,4) = p(FFI.4) = �, p(MF[ A) - 0; 
p(gM I -) p(FF X) = �, p(MFI,) =  
These .equations express the facts that males and females 
are equally likely and that the two members of a pair ot r 
fraternal. twins have independent determinations of sex (since 
p(MMIX) = p(MI,)p(MIX), etc.). Actually it is known that 
the sex ratio of male to female at birth is a little over one but 
this will only affect the arithmetical details. Now theorem 4 says 
that in this situation 
p(mM) = p(MMIA ) p(A) +p(MMI X)p(X), 
and, inserting the known values, 
p(Mm) = �p(A) +�(1-p(A)). 
Whence p(A) = 4p(MM)- 1. 
p(MM) can be found from observation and hence p(A). 
Theorem 5 is useful in calculating p(A I B) from p(B} A) and in 
the form given in theorem 6 is the most important result in the 
book, at least for the inductive, statistical applications. Rev. 
Thomas Bayes (1702-61) had his famous paper published after 
his death, in 1763. The paper has recently been republished 
(1958) because of its great importance. Virtually the whole of 
the second part (chapters 5-8) of this book is an application of 
his result and here we only give two simple uses of it. 
Example 2. A machine producing articles can go wrong in 
a number of ways: when it does it may produce defective 
articles. The problem is to determine what is wrong with the 
machine from inspection of the nature of the defect. Each 
elementary event concerns a particular breakdown, with which 
may be associated a particular defective article. Ai (1 < i < m) 
is the event that the breakdown is of the ith type. By (1 < j  n) 
is the event that the article's defect is of thejth type. It is assumed 
that neither can the machine break down nor the article be 
defective in more than one way at the same time ({Ai} and {By} 
are both collections of exclusive events) and that a defective 
article is necessarily a product of a broken machine. The break- 
1.4] BAYES'S THEOREM 23 
down rates (the p(Ai)) are known from past experience, as 
are the proportions of the different types of defective articles 
produced by each type of breakdown (the �(Bj ] Ai) ). Theorem 6 
enables _p(A� lB j) to be' calculated. Then if a defect of type j is 
observed (that is B is the conditioning event) the probability 
that the machine breakdown is of type i is known: in particular 
if one A� has probability near one, then that type of breakdown 
would be the one suspected. 
with m = n = 2: suppose 
p(A)t = �, 
p(Bx lax) =  
p(& I A) = ?, 
Consider a numerical example 
p(m lax) = ; 
p(B2 .A2) = x 
4' 
Notice that Bz and B, are not exhaustive: a breakdown need not 
cause a defect. We use the theorem first for Bx. 
If Bx occurs' 
1 1 
p(AxIBx) c � x3 - 6, 
2 __ 1 
.v(A: lbs) o:  x  - , 
so that the odds are 5 to 2 ( divided by g) on Ax against A, 
although, without knowledge of Bx, A.x only occurs half as 
often as A. The mechanic should suspect that Ax is the cause of 
the observed defect. 
If B. occurs' 
1 __ 1 
p(A I&)oc ? x x - , 
2 __ 1 
p(AzlBz)cc �x- , 
so that the odds are 5 to 1 on A2 against A: hence Az is sus- 
pected as the cause. Notice that it is not necessary to calculate 
the constant of proportionality; it would be easy to do so. The 
probabilities can be determined from the condition that, since 
the {Ai) are exhaustive given a defect, their sum must be one. 
The above is a fairly typical example of the use of Bayes's 
theorem. The main points to notice are the presence of a num- 
ber of possibilities (the {A,i)) of which one, and only one, must 
obtain, but it is not known which; and some event which has 
That is p(Ax[ A). 
24 PROBABILITY [1.4 
been observed to occur (one of the {Bj}) and which is influenced 
by the {Ai} (through p(Bj [Ai)). We wish to state what we know 
about which unknown possibility occurred (the p(Ai[Bj)). 
Examples are, where {A} correspond to different diseases and 
B. is an observed symptom; where {A} are the possible chemical 
structures an unknown product might have and Bj is the result 
of a chemical analysis; where {Ai} correspond to different 
scientific theories that are available to explain a phenomenon 
and B is an experimental result; where {Ai} are the suspects and 
{B} the clues in a detective novel. 
The more important applications of Bayes's theorem require 
an extension of the concept of probability, which is given in 
�1.6. For the moment we content ourselves with a second 
example in which the main interest lies in the language used 
in the or. iginal formulation and the 'translation' of it into 
probability language. 
Example 3. Particles of s types are in proportions P,P2,...,Ps. 
They meet a barrier and the probability of the rth type of 
particle passing through the barrier is qt. Find the proportions 
of the s types after passage through the barrier. 
The sample space is obviously made up of elementary events 
consisting of particles arriving at the barrier. Let A r be the set 
of all elementary events in which the particle is of type r: then 
p(A) = pr (cf. � 1.3 again). Let B be the set of all elementary 
events in which the particle passes through the barrier. Then 
p(B[A) = q. Now p(AIB) means the probability that the 
particle is of type r given that it has passed the barrier, which is 
the required proportion. So Bayes's theorem says 
the required result. 
p(AIS) = 
qrPr 
Y qp' 
An example of the use of theorem 7 will be given at the end 
of � 1.5. The principal use of theorem 8 is to derive the prob- 
ability of several events occurring (left-hand side) in terms of the 
conditional probabilities of each event separately (right-hand 
side). The following example illustrates this and also the formu- 
lation of a probabihty system of trials which are not independent. 
1.4] BA��S'S TH.ORV. M 25 
Example 4. A sequence of trials is considered, each of which, 
except the first, can result in a 0 or a 1. The first trial always 
results in a 0. In any subsequent trial the probability of a 
result 1, given that the previous trial resulted i.n a 0, is p in- 
dependently of the results of all earlier trials; and the same 
statement is true with 0 and 1 interchanged. In other words, the 
probability of a change of the values in consecutive trials is p. 
We write q = 1-p. This is a model for a random telegraph 
signal, the signal being provided by the change in the result. 
Let A be the event, a 1 on the ith trial, and, as before, A be the 
event, a 0 on the ith trial. Then the probability of the sequence 
0011 is, by theorem 8, 
p(A AAa A) = p(A) p(A IAO p(Aa I p(A [ A A Aa) 
= p(A) p(A [A0 p(Aa I J2) p(A I 
because of the independence of the result of a trial from the 
results of all trials other than the immediately preceding one. 
Hence 
p(AAAaA) = 1 .q.p.q = pq. 
Notice that the trials are not independent, unless p = k, because 
otherwise, p = p(AA)  p(AaA) = q. A sequence of trials 
in which, as here, 
where C_ is any result of the first (n-2) trials, is called 
a Markov sequence after the Russian mathematician of that 
name. They will be discussed in 4.5 and 4.6. 
1.5. Genetical applications 
An important field of application of probability theory is 
genetics, the basic Mendelian laws being essentially probabilistic. 
Throughout this section some familiarity with elementary 
genetical ideas will be assumed. The results will not be used 
outside this section. 
Example 1. First consider the case of a single gene, with alleles 
A and a, for which the three genotypes AA, Aa, aa give rise to 
three distinct phenotypes, and suppose that the proportions of the 
three phenotypes in the population are initially P0, qo, ro respec- 
26 'ROBA}XXIX� [1.5 
tively. If mating takes place randomly, we are concerned with 
random samples of size 2 (cf. � 1.3) from the population, sup- 
posed infinite, and the six possible types of mating with their 
probabilities are: 
AA x AA AA x Aa AA x aa Aa x Aa Aa x aa aa x aa} 
P0  2poqo 2p0ro qo  2qoro r0  ' 
(1) 
(The factor 2 in the probabilities of mixed matings arises because 
AA x Aa, for example, is identical with Aa x AA, each having 
probability Poqo.) For any type of mating (corresponding to the 
conditioning event) the conditional probabilities of the offspring 
follow from Mendel's laws. Thus, if Aa also denotes the event of 
an offspring being of type Aa, p(AalAA x Aa) = �, etc. The 
proportions of phenotypes in the next generation, p(AA), etc., 
Can be found from the generalized addition law. For example, 
p(AA) = p(AA I AA x AA) p(AA x AA) 
+p(AA I AA x Aa) p(AA x Aa) 
+p()tA [ Aa x Aa) p(Aa x Aa), (2) 
the remaining conditional probabilities being zero. Hence 
p(AA)= lxp+�X2poqo+�Xqo=(po+�qo) '. (3) 
This result can be obtained more easily by noticing that the 
proportion of A genes originally is P0 + �q0 = 0, say, and under 
random mating the offspring receives two independent (random) 
genes from the population: hence p(AA) = 0 , which is (3). 
Similarly, p(Aa) = 20(1 - 0) and p(aa) = (1 - 0) . These are the 
proportions of the three genotypes in the first generation, so 
denote them by px, qx, r, respectively. The proportion of A genes 
is px + �q, which a little algebra shows is still 0. Hence, if p is 
the proportion of the first genotype in the second generation, 
p. -- px, etc., and the proportions of the genotypes remain con- 
stant in all subsequent generations atpx, qx and rx. This is known 
as Hardy's law. 
Example 2. In contrast with random mating consider the 
same situation with inbreeding, where an individual of one geno- 
type always mates with an individual of the same genotype. 
1.5] OENETICAL APPLICATIONS 27 
Letting p,, q,, and r, be as before for the nth generation, we 
easily have, corresponding to (2), since 
p(AA x AA) = p(AA) = 
P,+x - P, +�q, 
q,,+x = 
r,+ = �q, + r,,; 
or, in matrix notation, 
p,+ = Ap, 
etc., 
(4) 
where p., is the column vector of elements p,,, q, and r, and A is 
the matrix 
P, = P0 + [�- (�)'*+l q0,} 
q, (�)qo, [ 
r [�- (�)+q qo+ro, J 
(6) 
so that the proportions are not stable after the first generation, 
as with random mating, though they tend rapidly (because of the 
factor (�)'9 to the limiting form, 
P=, =Po+�qo, qoo =0, r, =ro+�qo, 
which, as in Hardy's law, will be maintained in subsequent 
generations, because only pure lines, AA or aa, are present. In 
more complex examples an equation of the same matrix type 
as (5) persists and may be solved by raising the matrix A to the 
appropriate power. Methods for doing this are given in many 
text-books on algebra; for example, Frazer, DunCan and Collar 
(1946) or Faddeeva (1959). They all depend on the characteristic 
roots of the matrix, and the limiting behaviour depends on their 
values. The columns of the matrix sum to one (since the entries 
Consequently p = A"po. (5) 
It is easy to verify (by induction or by summation of a geo- 
metric progression) that 
28 PROBABILITY [1.5 
are probabilities) and therefore at least one of its characteristic 
roots is unity: here unity is a double root. These matrix tech- 
niques will be discussed again in connexion with the closely 
related Markov chains in �4.5. 
Example '3. Consider the case where the allele a is recessive 
so that the two genotypes, AA and Aa, are recognizable as a 
single phenotype, aa say; that is, not aa. The matings allowed 
in inbreeding will now be aa x aa and d x a, so that AA x Aa 
can occur. The phenotype aa will breed true but even with in- 
breeding the phenotype aa will produce some offspring of the 
other phenotype aa. We consider how the proportions of these 
offspring change with successive generations. Considering only 
matings 3-d x aa, the three possible types of mating of the nth 
generation, with their probabilities, are: 
AA x AA AA x Aa 
(1 _p)2 2p(1 -p) 
Aa x Aa 
p, 
where p,, is the proportion of heterozygotes (Aa's) in the nth 
generation of 's: that is, p(Aa [) = p,. The probability of 
a heterozygote in the next generation is, again by the generalized 
addition law,' 
p(Aa) = p(Aa l AA x Aa) p(AA x Aa) 
+ p(Aa I Aa x Aa) p(Aa x Aa) 
= p,(1-p) + 2P = p(1-�p). 
Similarly the probability of the other phenotype is p(aa) - �p[. 
Hence the probability of the phenotype, 3-5, is 1 -  ' 
,p,, = p(). 
Consequently, in the next generation, by theorem (1.4.2), 
p.,+ = p(Aa[ 3-5) = p(Aa)/p(3-5) 
= - = p/(1 +�p,O. (7) 
p,(1 
This equation may be rewritten, P7,} = P+�, 
whence p}_ = p-+�(n+ 1) 
and p = po/(1 +�npo). (8) 
' All these probabilities are conditional on the mating aa x aa. This condition, 
being constant throughout, is omitted in agreement with the convention explained 
in �1.2. 
1.5] GENETICAL APPLICATIONS 29 
The proportion p, of heterozygotes in a- tends to zero as n -, 
not as fast as the proportion of heterozygotes tended to zero 
(as 2-'9 in the non-recessive case. 
Example 4. Continuing with the recessive case, sometimes 
the phenotype aa corresponds to an abnormality and individuals 
of the two phenotypes are referred to as normal (-) and 
abnormal (aa). It is then of interest to calculate, given a family 
tree of the parents, the probability that a child of theirs will be 
normal. Such a calculation may be of value to cousins con- 
templating marriage. Consider, as a simple example, the prob- 
ability that the first child of parents, about whose family history 
nothing is known except that the parents are normal, be 
abnormal. In the notation just used this is p(aala-- x g-). To 
calculate this we use theorem 1.4.7, with At (the notation of the 
theorem) = AA x AA, A. = AA x Aa, A3 = Aa x Aa, so that 
 As = a-g x aa. Then 
p(aa[ aa x g-g) = p(aa[ Aa x Aa) p(Aa x Aa)/g(- x ), (9) 
the other conditional probabilities in the numerator being zero. 
Let � be the proportion of a genes in the population and assume 
random mating. Then by Hardy's law the three genotypes are in 
proportions (1-p)'2p(1-p):p 2 and p()= 1-p 2. Hence, 
inserting these values in (9), we obtain 
p(aa]a-3x') = � x {2p(1-p)}2/(1-p')2 = p/(1 +p)". (10) 
Modifications to this formula will be necessary if the mating is 
not random, but (9) will still be valid. When more is known 
about the family tree the computations become more involved 
since corresponding to the known phenotypic structure more 
genotypic arrangements are possible. The example illustrates the 
use of theorem 1.4.7 in deriving a probability conditional on an 
event (phenotypic structure) which can occur in a number of 
exclusive ways (genotypic structure). 
1.6. Degrees of belief 
Mathematical probability (� 1.2) has been suggested by pro- 
perties of events and success ratios of those events (� 1.1). We 
now take a step which widens very significantly the applications 
30 PROBABILITY [1.6 
of probability theory. We pass from events to propositions, 
which are collections of events: thus the proposition 'a penny, 
when released, will fall to the floor' is a statement that all 
events like'this penny, when released, will fall to the floor' will 
occur. And we pass from probabilities of events to probabilities 
of propositions, and axiomatize these in exactly the same way. 
Thus to certain pairs, A, B, each of which may either be a pro- 
position or an event, is associated a number p(A[B) satisfying 
the three axioms of � 1.2. Such an extension is not useful until 
we are clear what it is that these probabilities are supposed 
to represent in the real world; clearly they cannot be success 
ratios since it is highly artificial to imagine repetitions in each of 
which a proposition is either true or false. If A is a proposition 
then p(A[B) represents one's belief or strength of conviction, 
that A is true, given B. It is a degree of belief in a proposition. 
At one extreme, if A is believed to be true, p(AIB ) = 1: at the 
other extreme, if A is believed to be false, p(AIB) = 0. Other 
points in the interval (0, 1) express intermediate beliefs between 
truth and falsehood. In statistics the word hypothesis is used 
instead of proposition because we are usually interested in a 
proposition whose truth is in doubt and which is only put 
forward hypothetically. The principal use of a measure of 
degree of belief in a hypothesis is in describing how our apprecia- 
tion of a hypothesis changes with increasing evidence relevant 
to the hypothesis. Let E denote one's accumulated knowledge 
at some point of time. Let A be some event and, to avoid 
trivialities, suppose its occurrence or otherwise is not included 
in E. Let H be some hypothesis. Then p(H] E) denotes one's 
degree of belief in H given E: p(A [HE) denotes the probability 
of the event A given the truth of H and given E: p(H[ AE) 
denotes one's degree of belief in H given that A has occurred 
and given E. Usually E is omitted, since it always occurs after 
the vertical line, and we write, as before with frequency ideas, 
p(H) for p(H[E), etc. p(H) is called the prior probability of H. 
p(AIH), which has been used before as the probability of the 
event A, given H, is also called the likelihood of H on A. 
p(H I A)is called the posterior probability of H. The main subject 
matter of statistics is the study of how data (events) change 
1.6] Dv. GR�ES OF B�L.F 31 
degrees of belief; from prior, by observation of A, to posterior. 
They change by Bayes's theorem (1.4.6) since degrees of belief 
obey the axioms of � 1.2. In the form of the corollary to the 
theorem, if {H} is a set of hypotheses and A is some event, 
p(H,, [A) oc p(AIH,,) p(H,), (1) 
for n = 1, 2, ..., and fixed A. In words this reads 'the posterior 
probability is proportional to the product of the likelihood and 
the prior probability'. This result describes how events change 
beliefs. Two hypotheses Hx, Ha, are independent, given A, if 
p(H Ha [ A) = p(H I A) p(H. I A ) (2) 
as before, equation 1.3.1. The justification is also as before: they 
are independent if the degree of belief in H given Hz and A is 
the same as that given A alone. This leads to (2). 
Extension of an axiom system 
A probability system is a representation of certain aspects of 
the world, namely success ratios of events, but there is no reason 
why it should not represent other aspects as well: just as the 
axioms of length could equally well serve as the axioms of mass. 
To see this consider rods, that is, one-dimensional objects, 
denoted by A, B, ..., which may be combined by placing them 
end-to-end. Let A +B denote the rod formed by so placing 
A and B. Then each rod has a length, l(A) say, satisfying 
l(A) � 0 and l(A+B)= I(A)+I(B). 
But, similarly, these rods have masses, m(A) say, and equally 
re(A) > 0 and m(A + B) = m(A)+m(B). 
Hence length and mass have the same mathematical properties. 
This coincidence of mathematical properties happens with fre- 
quency limits and degrees of belief and they are both called 
probabilities. The elements A usually represent events, when 
dealing with success ratios, and proposit!ons, or hypotheses, 
when dealing with degrees of belief. Hypotheses are collections 
of events so it is no great step to pass from one to the other 
and regard certain sets in sample space as hypotheses. It follows 
32 PROBABILITY [1.6 
that hypotheses combine in the same way as events: for example, 
if H and H are two hypotheses, HH is the hypothesis which 
is true iff Hx and H. are both true; H and H are exclusive if 
they cannot both be true. 
The sample space is a space of elementary hypotheses about 
which, as in the case of elementary events, we do not need to be 
too specific. As just explained, a hypothesis may itself be con- 
sidered as a collection of events; and since there is no disadvan- 
tage in using a complex sample space (� 1.2) we might choose 
to use elementary events to form the sample space. As a result 
of these considerations we are able to widen our language by 
using hypotheses as well as events and 'is true' as well as 
' occurs'. 
The meaning of a 'degree of belief' 
We now have to consider what we mean, in the real world, by 
p(AIB). Consider this where A is a hypothesis H and B is E, 
our accumulated knowledge of events and hypotheses at some 
point of time. What is theprobability of a hypothesis H given E? 
What could probability mean in this context ? Certainly not a 
success ratio since indefinite repetitions, in some of which H was 
true, would be highly artificial. We can obtain a clue to this by 
considering the way in which words related to probability are 
used in everyday life. Thus we often hear and use phrases like: 
'He will probably get a scholarship... ', 'The probable cause of 
death was...', 'The Tories will probably win...'. In none of 
these examples are natural repetitions conceivable. Let us 
analyse the following two statements which eminent scientists 
are reported to have made: 
(a) 'It is more probable that a cure for cancer will be found 
through increasing our knowledge of the mechanism of growth 
of normal cells, than through experimental treatments applied 
to cancer patients.' 
(b) 'I am 90 % certain that the neutrons have been produced 
as a result of a thermonuclear reaction' [and not by some other 
process]. 
In (a) two hypotheses, H1 and H.o. say, are compared and one 
is held to be more probable than the other: in other words Hx 
1.6] n�GRWV. S OV B.XA�V 33 
and H2 are given an ordering (one has more than the other) in 
terms of probability. In (b) the ordering is still present, Ht is 
'by thermonuclear reaction' and H. 'by other means', but in 
addition a number is attached to each hypothesis, 90 % to one 
and 10 % to the other. The second scientist is not merely 
ordering his hypotheses (like ordering points on a line from left 
to right) but is attaching numbers to them (like giving the exact 
positions of the points). The numbers are measures of how 
strongly he believes in the hypotheses, or degrees of belief in the 
hypotheses, and can be represented by p(H [E), where E is the 
evidence that the two scientists have. ? It is this degree of belief 
that is represented by the mathematics. 
But this raises two questions: what does this 90 % mean ? and 
why should degrees of belief obey the axioms suggested by 
frequency ideas ? One operational interpretation of the 90 % 
is that the scientist (assuming he had no moral objections to 
gambling) would be prepared to offer a bet at odds of 9 to 1 
on H against Ha; that is, a bet in which he would pay out 
9 units if Ha were true and receive 1 unit if Hx were true (� 1.2). 
Since he is not completely certain about Hx he cannot be sure of 
receiving the one unit, and might therefore assess it as worth 
x units (x < 1). That is, a certainty of x units is as good as this 
chance of receiving 1 unit. Similarly, although he does not 
think H2 is true he might lose his 9 units: and this loss might be 
judged equivalent to a certain loss of 9y units (y < 1). Presum- 
ably he does not expect to be the loser by the offer and therefore 
x > 9), or x/y >. 9. Let us now make the assumption that the 
values x and y do not depend on the units used. For example, 
that a loss of 10 units if Ha were true would be judged equivalent 
to a certain loss of 10y units. This assumption is reasonable 
provided the units are not changed drastically, as we have no 
wish to do. Now the scientist would obviously also be prepared 
to offer 8 to 1, and this is confirmed since x/y > 8. But he 
might, if pressed, offer 10 to 1. This he would do if x/y > 10, in 
virtue of the assumption just made. All his statement, quoted 
' Notice how often the conditioning event is omitted, as in the frequency 
cases previously encountered. In (b) it was very relevant because later experiments 
suggested that Hx was false. 
34 PROBABILITY [1.6 
above, has told us is that x/y > 9. By putting other suggestions 
to him we can determine the exact value of x/y. Thus, if 9 to 1 
on H against Hg is the highest odds he will offer then x/y = 9. 
This upper limit of odds is called the critical limit and we denote 
it by b: so x/y = b. As only the ratio of x to y matters we con- 
ventionally suppose them to add to one, when x/(1- x) = b or 
x = b/(1 + b). This value of x is our degree of belief in H and 
has the properties of probability, and which we term the proba- 
bility of H. Similarly y is the probability of H. The empirical 
content of the former type of probability was a frequency ratio. 
The empirical content of this type is in terms of the critical odds 
for a bet. A bet at the critical odds is said to be fair. The 
reason for this is that, in our case, the scientist would not offer 
a bet at higher odds because he thinks it unfair to him, and if 
he made it at lower odds he would stand to win, which would 
be unfair to his opponent. In language to be developed later 
(�2.1) a fair bet has zero expectation. The 90 % quoted by the 
scientist was probably his assessment of a fair bet, since the 
statement, unlike a bookmaker's, would not be made with 
expectation of gain. 
Justification of the axioms 
The answer 'to the second question at the beginning of the last 
paragraph is more involved and the next two paragraphs may be 
omitted by any reader who is prepared to take the axioms on 
trust. The justification uses the interpretation of degrees of 
belief in terms of betting and the following easily acceptable 
basis for argument: if two bets are both fair then so is the bet 
in which the first bet is taken with probability cz and the second 
with probability (1 -c). The probability here is a frequency one: 
for example with  = 1/3, a fair die could be rolled; if it shows 
a 1 or a 2 the first bet will be taken, otherwise the second will be 
taken. The bets are said to be mixed in the ratio 
The first axiom (� 1.2) is immediate since any degree of belief 
must lie between 0 and 1 (it is b/(b + 1)): and if H is given, H is 
certainly true, when any odds will be offered, so b --> c and the 
degree of belief is 1. To justify the second axiom let H and H. 
be exclusive hypotheses, given E, with critical bets of bx to 1 and 
1.6] DEOR.ES OF BELIEF 35 
b to 1. Since these are fair a mixture in the ratio c: 1 - 0 is fair. 
Table 1.1 may help to clarify the position; the entries are the 
values of a bet (a row) given the truth of a hypothesis (a column). 
Since Ht and H,. are exclusive the only possibilities are H, H. or 
neither Hx nor H,, that is H He. The values for the mixture are 
given in the third row and for Hx and H they are equal if 
= +(l-s), 
or cz = c 0 = (1 +b0/(2 +b +b0. 
With cz = ct o the values are given in the last row. Since the 
values for Hx and H. are equal, and therefore it does not matter 
which is true, this CZo mixture is equivalent to a bet on 
H = Hx + He 
and the odds are (bz + b + 2bx bO to (1 - bz bO, 
or b = (bx +&. +2bzb=)/(1-bzbe) to 1. 
Hence the degree of belief in H is 
b bx + b. + 2bx be 
1 +b 1 +bx+b+bx&. 
bx be 
1 +b + 1 +b-- 
the sum of the degrees of belief for Hx and H.. The extension to 
several exclusive hypotheses is immediate and it is convention- 
ally used for an enumerable infinity. 
TABLE 1.1 
True hypothesis ... Hx H Hx H 
Bet on H + 1 - bx - bx 
Bet on H - b + 1 - ba 
Mixture '' a-(1 -c0b  -abx+ (1- ct) - 0,bx- (1- o0 b a 
1 - bx b2 1 - bx b2 bx + b + 2bx ba 
Mixture ' ao' 
2+b+b 2+bx+ba 2+bx+ba 
To justify the third axiom again consider two hypotheses Hx 
and H., given E, which are not exclusive. Let the critical bet for 
Hx be bx to 1, and for He, given Hx (and E), be b. to 1. In the 
latter bet b. units are paid out if Hx is true but He not, and 1 unit 
is received if Hx and He are both true, otherwise there is no pay- 
ment. In other words, the bet on H.' is only operative if Hx 
36 PROBABILITY [1.6 
obtains. The values are given in table 1.2, together with the 
values for a mixture in the ratio : 1- . The values for this 
latter bet are equal when Hx H2 or Hx are true if 
c-(1-c)b2 = -cb or  = s0 = bo./(1 +bt+bz). 
With  = a 0 the values are given in the last row. This is a bet 
in favour of HH at odds ofb = bb/(1 +bt+b) to 1. Hence 
the degree. of belief in HtHz, given E, is b/(1 +b) = p(HHz[E), 
and 
p(HxH E) = bxb/(1 + bO (1 + b) = p(HIE ) p(HIHxE), 
which is the third axiom. A more complete justification for the 
axioms for degree of belief have been given by Savage (1954). 
Savage also gives reasons for thinking that everyone must be 
able to assess p(H[E), that is, that it always exists, a question we 
now proceed to discuss. 
TABLE 1.2 
True hypothesis ... Ht Ha Ht H Ht 
Bet on/art '+ 1 + 1 - bt 
Bet on Ha given Ht + 1 -b,. 0 
Mixture 'o' + 1 
bt bz 
Mixture ' Co' + 1 
1 +b+b2 1 
Evidence for the numerical assessment of a belief 
It has been shown that a degree of belief, if measured numeri- 
cally, will satisfy the same axioms as are suggested by frequency 
considerations. But the question remains: can a degree of belief 
be measured numerically? No one would dispute that we all 
have beliefs, some more strongly held than others, but many 
people object to any attempt to describe them in numerical 
terms. We now give an outline of the method that is used to 
establish the existence of numerical degrees of belief. 
The method is to consider the way in which any person must 
act, to impose on his actions sensible restrictions that almost all 
people would accept as rational, and to demand that his actions 
.be consistent. From axioms concerning actions it is possible to 
deduce, by the usual methods of mathematics, that the only way 
1.6] r)�oR..s ov BE.�V 37 
of acting that is rational and consistent must involve a numerical 
statement of relevant degrees of belief, or must be equivalent to 
such a statement. This method was used by yon Neumann and 
Morgenstern (1947) to consider utility (a topic that is briefly 
discussed in �5.6) and extended by Savage (1954) to cover 
degrees of belief, or what he calls personal probability. 
The axioms that Savage consider.s concern two sets of elements 
that he calls the 'states' and the 'consequences'. The states are 
the possible hypotheses concerning the topic under discussion. 
For example, in the situation (b) above the states are the various 
possible ways in which the observed neutrons could have been 
produced. One of these is by a thermonuclear reaction. The 
probabilities concern these states. The consequences are what 
will ensue if actions are taken on the basis of the beliefs. Again 
in the example from nuclear physics, one can imagine actions, 
costing considerable sums of money, being taken on the basis of 
beliefs (or opinions) about the process which produced the 
neutrons. An action, or a decision, can be thought of as a func- 
tion which defines, for each state, a consequence. Thus the 
action of building a larger machine will result in the production 
of more neutrons and considerable benefits if the thermonuclear 
reaction was the cause; but it will be largely wasted if it was not 
the cause :--that is if some other state obtained. 
It is then possible to develop axioms concerning these 
elements, the states and the consequences, and the acts which 
relate them. The first axiom is that all acts can be ordered: that 
is, given any two, one is preferred to the other (or they are 
equally preferred) and if a is preferred to a., and a. to aa, then 
a is preferred to a3. This axiom is a severe assumption but one 
that is difficult to attack. For it is always conceivable that you 
may have to decide between two given acts and, if they are the 
only ones available to you, you will act in one of those two ways. 
That choice of action is itself an ordering; namely that the 
rejected action is not preferred to the chosen one. Thus any 
person deserving to be called rational must order the acts 
available to him. 
A second axiom is that if action a is preferred to action 
when the state of the world is sx, and ax is still preferred to 
:38 PROBABILITY [1.6 
when the state is s2, then at is preferred to a.2 even if it is not 
known whether the state is s or as (that is, irrespective of beliefs 
about s, or s2). For example, if it is better to build a larger 
machine than not to, when the neutrons were produced by a 
thermonuclear reaction, and also better if they were produced 
differently, then it is better to build the machine in any state of 
mind about .how they were produced. This is essentially an 
axiom of consistency on the part of the person taking the action. 
These are the basic axioms. By adding others of a less funda- 
mental nature just as the first axiom in � 1.2 is not so basic as 
either of the others--it is possible to demonstrate the existence 
of numbers attached to the states, which satisfy our axioms of 
probability, and which therefore deserve to be called degrees 
of belief probabilities. It is also possible to demonstrate the 
existence of a utility function (for a brief discussion of this see 
�5.6). 
The attitude we adopt in this book is that these axioms are 
reasonable, that the deductions from them described in detail 
by Savage are correct, and that therefore we may use prob- 
abilities in the sense of degrees of belief. It must be pointed out, 
however, that in adopting this attitude, and developing statistics 
in chapters 5-8 on this basis, we are pursuing an unorthodox 
approach. Most statisticians adopt a different attitude in which 
only frequency probabilities are admitted. The present approach 
seems preferable to the author. The point is discussed more 
fully at the end of �5.6. The student who learns his statistics 
from this book need not fear that he will learn different results. 
The methods developed are the same, in all essentials, for the 
two schools of thought. We indicate the few points where they 
differ. The distinction between the two schools is irrelevant in 
chapters 2-4. 
Likelihood 
The word likelihood was introduced by Fisher, who was 
responsible for many of the important ideas in modern statistics. 
It may seem unusual to have two different words for the same 
quantity. The reason is this: in some problems, usually deductive 
ones, one is concerned with the probabilities of different events 
1.61 DEGREES OV BEr. XEF 39 
A, A.,... all given the same hypothesis H, so that in p641 m), 
A is the variable. Whereas in other problems, usually inductive 
ones, an event, A, has occurred and (usually in order to apply 
Bayes's theorem) one is interested in the probability of A given 
different hypotheses, H, H2, ... (compare the insulin example, 
below), so that in p(A ] H0, HE is the variable. Therefore, depend- 
ing on which is the variable, or the argument of the probability 
function, the terms probability (p(Ai [ H)) or likelihood (p(A I HO) 
are used. One speaks of the probability of an event or the likeli- 
hood of a hypothesis. For example, one difference between 
probability and likelihood is that if {At} are exclusive and ex- 
haustive the probabilities sum to one, whereas if {H} are exclusive 
and exhaustive the likelihoods do not usually sum to one. 
Relation between the two types of trobability 
In this book we have chosen to develop frequency ideas first 
and then pass to degrees of belief: we do this because the former 
are the easier to understand. It is possible, and perhaps even 
desirable, to proceed the other way round; starting from a notion 
of probability developed from beliefs and deducing frequency 
ideas. This has been done most successfully by de Finetti (1937); 
an account of some of his work in English is given by Savage 
(1954). 
We have, we hope, thus justified the use of two types of 
probability. These can occur together in an equation. Further- 
more both interpretations are sometimes possible, and when this 
is so the two values agree. Thus, suppose we have a newly 
minted coin, one that is known to be just as likely to fall heads 
or tails. Then our degree of belief that it will fall heads in a 
single toss is 1/2, as is the frequency probability. Of course, if we 
have a bent coin the frequency probability may be p, say, and 
our degree of belief may be p' 4: p. But that is because the 
conditioning event is different in the two cases. Tke frequency 
probability can' only be stated ifp is known, whenp(heads [p) =p. 
The degree of belief is the probability of heads without know- 
ledge ofp. If we tossed the bent coin a large number of times we 
should learn the value of p and the degree of belief in heads 
would move towards p (see �7.2). 
40 PROBABILITY [1.6 
There is some disagreement among writers about the objec- 
tivity ofp(HIE ). Some maintain that it is a subjective value and 
that two people will not necessarily assign the same number 
to H, given E. The view taken in this book is that if two people 
differ in their probabilities of H, where H is a scientific question 
and not, for example, a question of taste, it is because they have 
different evidence; in other words, one is considering �(H I E) 
and the otherp(HlE'). If they were to pool their knowledge then 
they should agree on p(H[ EE'). It is easy to make the mistake 
of thinking the probabilities are different, when it is really the 
evidence that is different, because, as repeatedly mentioned, the 
evidence is often omitted 
course, it is sometimes 
different people' but Jt is 
a common assessment of 
in the statement of a probability. Of 
difficult to pool the knowledge of 
important to do so in order to reach 
probability, and the need to do this is 
an important reason for improving scientific communication. 
Attempt.s have been made to develop statistical theories which 
use only probabilities of events, which are therefore objective, 
but none have been entirely successful. Reasons for rejecting 
them will be given later (�5.6). 
Scientific use of Bayes's theorem 
Although Bayes's theorem is basic in understanding how we 
accumulate knowledge, it must be noted that in a well-designed 
experiment the result it gives is often trivial. Suppose that there 
are only two hypotheses, Hx and H, under consideration and 
that there exists an experiment in which an event A has, under 
the hypotheses, the probabilities p(A [ Hx) = 1 and p(A [ H) = 0; 
whence it follows that p(,[ H0 = 0 and p(,[.H2) = 1. Then, 
provided neither of the prior probabilities p(HO nor p(H) is 
zero, whether A or A occurs one of the posterior probabilities 
will be zero and the other non-zero. The experiment is conclusive 
in favour of one of H or H.. (If A, H is true; if ,4, H. is true.) 
This then is an excellent experiment for distinguishing between 
the rival hypotheses and the result is obvious without an appeal 
to the theorem. It is the method used by scientists throughout 
scientific history. An excellent example is the experiment on the 
curvature of light rays during an eclipse which decided the 
1.6] DEGREES OF aELt�V 41 
issue between the special theory of relativity and Newton's laws. 
It often happens, however, that it is not possible to design such 
an unequivocal experiment. For example, the measurement of 
potency, or the assay, of insulin, is carried out with animals. 
Some animals are affected by a given dose and some are not, and 
the frequency concept applies to give the probability of an 
animal being affected, which can be used as a measure of the 
potency. Trials on a number of animals with a fixed type of 
insulin form random trials with constant probability of 
success (=affected animal), compare �1.3. Suppose that the 
required potency of standard insulin is such that the probability 
is 1/2. If, in an experiment on 20 animals, 15 are affected does 
this mean that the insulin is too potent ? 15 could be affected 
even if/ was 1/2, just as one could get 15 heads in 20 tosses of 
a fair coin, but 15 is more probable when p = 3/4. So this 
experiment is not completely successful in deciding between 
these two values of p, it suggests, but nothing stronger, that p is 
nearer 3/4 and 1/2. Nevertheless, apart from using more 
animals or other refinements such as measuring the effect, it is 
the best available experiment. Such experiments will be dis- 
cussed from chapter 5 onwards, but particularly in �7.2. 
Suggestions for further reading 
There are many books which discuss the foundations of prob- 
ability and, in particular, the relationship to the frequency concept 
and the concept of a degree of belief. A modern reference which 
has had a substantial influence on the present author is Savage 
(1954). Savage's work is derived from that of Ramsey (1931); 
de Finetti, references to whose work are given in Savage, a con- 
venient article is (1937); and the axiomatic approach of von 
Neumann in the appendix to (1947). Other important books are 
those by Keynes (1921), Reichenbach (1949), Braithwaite (1953) 
and Carnap (1950). Two historical references, easily available in 
modern printings, are Laplace (1951) and Bayes (1958). Few of 
these books attempt to go beyond a discussion of the founda- 
tions and apply the results: notable exceptions are Jeffreys (1961) 
and Good (1950), both of which include substantial develop- 
ments of the calculus. 
42 PROBABILITY [1.6 
Two books that discuss the mathematical calculus of prob- 
abilities are Feller (1957) and Gnedenko (1962). Both authors 
adopt a frequency view-point and dismiss any other attitude 
toward probability, but since their primary concern is with the 
mathematics this scarcely matters. The first book to present the 
modern axiomatic theory is still worth reading, Kolmogorov 
(1956). Modern probability theory is based on concepts of 
measure and Lebesgue-Stieltje integration. These topics are dis- 
cussed by Munroe (1953), Halmos (1950) and Pitt (1963). 
Some people enjoy the combinatorial side of probability 
which we have not discussed. Essentially this deals with the 
special case where all the elementary events are equally likely 
and the problems concern the computation of probabilities of 
other events, often involving permutations and combinations. 
A delightful elementary book in this field, which anyone who 
enjoys puzzles would appreciate, is Whitworth (1901). Two 
modern, more sophisticated, books are by David and Barton 
(1962) and Riordan (1958). A classic in this branch of the 
subject is MacMahon (1916), 
Exercises 
1. Roll a die, toss a coin, spin a roulette wheel or use some other random 
device with an appropriate event for success, and plot the success ratio 
against the number of trials as the latter increases. Notice the decrease in 
oscillation of the ratio as the trials grow in number. 
(This exercise is best done in a class in order to combine all the results 
into a single series. If a suitable random device is inconvenient tables of 
random sampling numbers (�3.5) may be used instead.) 
2. At the beginning of each period of I minute duration there is a one- 
third chance of a customer arriving at a counter to be served. If the server 
is free he serves the customer for 2 minutes. If the server is not free the 
customer joins a queue and is served, again for a period of 2 minutes, as soon 
as the customer immediately in front of him has been served. By rolling 
a die and assuming a customer arrives if a 1 or 2 is exposed, follow through 
such a process for at least 30 periods and record: 
(a) the proportion of customers who did not have to wait; 
(b) the proportion of time the server was free; 
(c) the maximum time any customer had to wait; 
(d) the maximum size of queue formed. 
[Imitation of a process using random numbers is called simulation.] 
EXERCISES 43 
3. If you had only a fair coin available how could you have produced an 
event of probability one-third for the above example 9. 
4, Simulate (see exercise 2) random mating of two alleles ,4 and a with 
three distinct phenotypes AA, ,4a, aa; in which the allele ,4 is twice as 
frequent as a in the population. Suppose that each mating produces two 
independent offspring (all parents have two children). 
5. Seven tickets are numbered consecutively from 1 to 7. Two of them 
are selected in order without replacement. Enumerate the sample space 
of possible results of the selection and identify the following events: 
,4, the numbers on the two tickets add up to 9; 
B, both tickets have prime numbers (count 1 as a prime); 
C, the numbers on the two tickets differ by 3. 
Identify also the events ,4B, BC, ,4 + B. 
If each elementary event has probability 1/42 (the event 1,7 being 
counted as distinct from 7,1), find �(,4 [ B), o(Bl �), p(C[ ,4). 
6. Each member of a group of persons has his height and weight recorded. 
Each point of the sample space (elementary event) may be represented as 
a point on the paper with height as abscissa and weight as ordinate. 
Identify the following events in a Venn diagram: 
,4, height over 5 ft. 11 in., weight over 12 stone; 
B, weight over 2 lb per inch of height; 
C, weight between 9 and 11 stone. 
Identify the events ,4B and BC. 
7. A needle of length l is thrown onto a level table marked with parallel 
lines at distance tt (> l) apart. Prove, under reasonable assumptions which 
should be stated, that if the needle makes an angle 0 with the lines the 
probability that it will cross a line is lsinO/h. 
8. Each point in a plane has co-ordinates with respect to a pair of rect- 
angular axes. A circular disc of radius r < � is thrown on to the plane. 
What is the probability that it will cover some point whose co-ordinates 
are both integers ? 
9. A circle of diameter } in. is placed with its centre at a randomly 
determined point in a square of side 1 in. Prove that, if P(r) is the prob- 
ability that exactly r corners of the square lie in the ring, 
16 3 47 
P(2) = � cos 
4rr 
and P(1) = 9 2P(2). 
(Aberdeen Dipl.). 
10. Comment on the dependence and independence of height, weight and 
colour in a population consisting of 25 % short-thin-coloured, 25 % short- 
fat-white, 25 % tall-thin-white and 25 % tall-fat-coloured persons. 
44 PROBABILITY 
11. A finite discrete sample space consists of the four points denoted 
(110), (101), (011), (000), 
and each has a probability 1/4. The event Ai (i = 1,2, 3) occurs if there is 
a 1 in the ith place: thus, A contains the two points (110) and (101). Show 
that Ai and A(i4:j) are independent but that Ax, A2 and Aa are not 
independent. 
Construct a similar example to show that three events A, B, C can 
satisfy 
p(BC) = p(B) p(C) 
xvithout any pair of them being independent. 
12. A box contains n balls, r of which are white and n-r black. Two 
balls are drawn at random: (i) with replacement, (ii) without replacement. 
Calculate the probabilities that both balls be white, one ball be white and 
one black, in the two cases. Show that if n ---> or, with r/n - p fixed, the 
limits are the same in the two cases (i) and (ii). 
13. Show that if A is independent of each Bi(i = 1, 2, ..., n) and the B 
are exclusive, then A is independent of ZBi. Show, by an example with 
n = 2, that this result is not necessarily true when the B are not exclusive. 
14. An urn contains M balls of which W(<M)are white. n(<M)balls 
are drawn and laid aside (not rep19ced in the urn), their colour unnoted. 
Another ball is drawn. What is the probability it will be white ? 
15. Colour-blindness appears in 1% of the people in a certain population. 
How large must a random sample (with replacements) be if the probability 
of its containing a colour-blind person is to be 0.95 or more? 
16. An event A is said tofiivour an event B ifp(BIA) > p(B). IfA favours 
B, and B favours C, does it follow that A favours C? If so, prove the 
result' if not, give an example where the result is false. 
17. Circular discs of radius r are thrown at random on to a plane circular 
table of radius R which is surrounded by a border of uniform width r lying 
in the same plane as the table. If the discs are thrown independently and 
at random, and N stay on the table, show that the probability that a fixed 
point on the table, but not on the border, will be covered is 
1 - (1 r . 
(Rr)-) } 
(Camb. Dipl.) 
18. Prove that 
p(A + B+ ... +Z) < p(A) +p(B) + ... +p(Z). 
Express p(A + B+ C) in terms of p(A), p(B), p(C), p(BC), p(AC), p(AB), 
v(ABC). 
Prove that p(AB ... Z) > 1-t(A)- ... -�(Z). 
19. ,4, B are two events. 
express: 
EXERCISES 45 
In terms of p(A), p(B), p(AB) for k = 0, 1, 2 
(i) p (exactly k of A, B occur); 
0i) p (at least k of A, B occur); 
(iii) p (at most k of A, B occur). 
20. A certain university course contains two examinations, one of which, 
known as ' Prelim', is taken at the end of the first year and the other, known 
as ' Part I' at the end of the second year. Results in Prelim are classified as 
1st, 2nd, 3rd or fail: the probabilities of a randomly selected candidate 
being classed in these groups are respectively, p, P2, Pa and P4. Candidates 
for Part I are classified as 1st, 2nd (upper division), 2nd (lower division), 
3rd or fail. A randomly selected student who has been placed in group i 
in Prelim has chances Pi, Pi., Pia, Pi4 andp5 of being placed in the 5 groups 
possible in Part I. (Assume that a candidate who fails in Prelim does not 
take Part I.) Write down the probabilities of the following events: 
(i) a college with 24 randomly selected candidates having less than 
3 failures in Prelim; 
(ii) a randomly selected candidate obtaining a 1st class in Part I; 
(iii) a candidate getting a better class in Part I than in Prelim; 
(iv) a candidate failing at some stage; 
(v) in a group of six friends one obtaining a 1 st class both in Prelim and 
Part I, two obtaining 1 st class in Prelim and 2nd class in Part I and three 
obtaining 2nd class both in Prelim and Part I. (Camb. N.S.) 
21. An r-partition of n is a collection without regard to order of r integers 
(>1) whose sum is n. Galileo was given, and solved, the following 
problem. There are six 3-partitions with no integer above 6 of 10 and 
of 12 yet when 3 six-sided fair dice are thrown simultaneously the total 
10 appears more frequently than 12. Why? 
22. A man tosses a coin either until he gets two heads in succession or 
until he has three tails (not necessarily in succession). Enumerate the 
sample space. If the probability of a head is 1/2 and is uninfluenced by the 
other tosses, calculate the probabilities attached to each elementary event. 
What is the probability that he will toss the coin more than three times ? 
23. Suppose that in answering a question in a multiple choice test, an 
examinee either knows the answer, with probability p, or he guesses, with 
probability 1-p. Assume that the probability of answering a question 
correctly is unity for an examinee who knows the answer and 1/m for the 
examinee who guesses, where m is the number of multiple choice alterna- 
tives. Show that the probability that an examinee knew the answer to a 
question, given that he has correctly answered it, is 
mp 
l +(tn-1)p' 
24. A sequence of 4 signals, 'on' or 'off' is produced in the following way. 
The probability that the first is 'on' is 1/2 (and therefore 'off' is 1/2). The 
'6 PROBABILITY 
probability that the rth signal is the same as the (r- 1)th is 0'9 (and there- 
fore that it is different is 0.1) for r = 2, 3, 4. Calculate the probabilities 
o� s 'on' and 4-s 'off' for 0 < s < 4. Compare these values with the 
same probabilities calculated on the assumption that each signal is equally 
likely to be 'on' or 'off' irrespective of the other signal. 
25. There are 6 men in a room, 2 pairs of brothers and 2 unrelated men. 
The probability that any one of them has blood-group ,Y is 1/4. The 
probability that if one brother has blood-group ,Y, the other brother has 
also ,Y is 3/4, otherwise the blood-groups are independent. Calculate the 
probability that exactly 3 men in the room have blood-group ,Y. 
26. Two players, ,4 and B, play the following game with a fair die. 
,4 throws the die and then has a second set of throws equal in number to 
that shown on the die the first time it was thrown. The total, s, on the 
second set of throws is recorded. Ifs > 12, B gives .4 one unit. Ifs = 12 
there is no payment. Ifs < 12, `4 gives B one unit. What is the probability 
that s = 127 Is it better to be `4 or B? (This problem is due to James 
Bernoulli.) 
27. Two players 2' and [Y play the following game with a perfect six-sided 
die with sides labelled 1, 2, ..., 6. At each round, the players shake the die 
(.Y shaking first), and the first to obtain a six wins. If in any round a player 
shakes a 1, then he has one more shake in the same round (but only one 
more, whatever the outcome). 
What is the probability that the game ends in either the first or the 
second round ? What is ,Y's chance of winning the whole game ? 
(London Ancil.) 
28. Two players take turns in drawing a ball out of an urn containing 
three white and five black balls. The player who begins requires a white 
ball, the other a black, he who first obtains a ball of his required colour 
winning the game. Find the relative chances of winning: 
(i) if each ball is replaced before the next draw; 
(ii) if no replacements are made. 
29. The following are the rules for the game of' Craps'. A player has two 
dice which are thrown together If the total is 7 or 11 he wins (a 'natural'): 
if 2, 3 or 12 he loses (a 'crap'). If neither of these results, he continues 
throwing until either he repeats his original score, when he wins, or he 
throws a 7, when he loses. Show that the probability of losing is 251/495. 
(Assume that the dice are not 'loaded'.) 
30. Assume that the genotype frequencies in a population are P = v 2, 
tt = 2�q, ( = q2. Given that an offspring, O, is of gcnotype ,4a, show that 
the probability that a sibling (another offspring of O's parents) is of the 
same gcnotypc is �(1 +�q). 
31. A male rat is either doubly dominant (`4,4) or heterozygous (,4a) and, 
owing to Mendelian properties, the probability of either being true is 1/2. 
The male rat is mated with a doubly recessive (aa) female. If the male rat 
EXERCISES 47 
is doubly dominant, the offspring will exhibit the dominant characteristic; 
if heterozygous, half of the offspring will exhibit the dominant character- 
istic and the other half the recessive characteristic. Suppose of three 
offspring all exhibit the dominant characteristic. What is the probability 
that the male is doubly dominant ? 
32. In each individual there is a pair of genes, each of which may be of 
type X or of type x. Individuals with Xx or xX are termed heterozygotes; 
those with xx are abnormal; both heterozygotes and those with XX are 
normal. The proportion of abnormal individuals of either sex in a popula- 
tion is p' and of heterozygotes is 2p(1 -p), where 0 < p < 1. Each of the 
parents of a child transmits one of its own genes to the child; if a parent is 
a heterozygote, the probability that it transmits the gene of type X is 1/2. 
Mating in the population is to be assumed to be random. Show that 
among normal children of normal parents, the expected proportion of 
heterozygotes is 2p/(l + 2p). 
James, a normal child of normal parents, marries a heterozygote and 
they have n children, all normal. Find, in the light of this information, 
the probability that James is a heterozygote and the probability that his 
first grandchild will be abnormal. (Camb. Tripos.) 
33. A certain phenomenon is either present or not. An apparatus has a 
probability Px > 12 of detecting the phenomenon (by giving a positive 
response) if it is present and a probability P2 < � of giving a positive 
response even if it is absent. If the phenomenon is equally likely to be 
present or absent and three independent uses of the apparatus give two 
positive responses and one negative what is the probability that the 
phenomenon is present? What is the probability that a fourth test will 
yield a positive response ? 
34. If H, H2, ..., H,, are exclusive and exhaustive hypotheses with degrees 
of belief try, r, ..., rr n then 
7l. 
I = Y trilnrti 
is called the information about the Hi. Show that I is least when rr = n -x 
for all n. 
Apply this to exercise 33 and find the information available about the 
presence of the phenomenon before and after the three responses had been 
obtained. 
35. If a person is suspected of having an undesirably high alcohol content 
in his blood a rapid test is carried out. This test has only 75 % chance of 
being correct: i.e. of giving a positive response when the alcohol level is 
high, or of giving a negative response when it is low. If the rapid test 
gives a positive response the subject is taken to a laboratory and given a 
second test. If the alcohol content was high at the time of the original 
test, this test has 90 % chance of detecting it (the delay in getting to the 
laboratory accounts for the 10 9'0 errors). If the content was low the second 
test never gives a false result. These are independent of the first test. If a 
48 PROBABILITY 
person is initially classed as a suspect when the prior probability of his 
having a high alcohol content is 20 % answer the following questions: 
(i) What proportion of suspects will have a second test which does not 
detect alcohol? 
(ii) What is the posterior probability that such a person had a high 
alcohol content? 
(iii) What proportion of suspects will not have a second test? 
(iv) If. a person is not tested in the laboratory, what is the posterior 
probability that he had a high alcohol content? 
36. In a bolt factory, machines ,4, B and C manufacture 25, 35 and 400/0 ' 
of the total respectively. Of their output, 5, 4 and 2 % are defective bolts, 
respectively. A bolt is drawn at random from the production and is found 
defective. What are the probabilities that it was manufactured by machines 
,4, B and C? 
37. A newspaper reported that 'the odds are two to one against the 
Government bringing in the bill .... If it does bring it in, reliable sources 
suggest that the odds are about even that it will get through.' What is the 
probability that the bill will become law ? 
38. A patient thinks he may have cancer and consults his doctor, ,4, who 
after examination declares he has not. The patient feels his doctor is over- 
cautious about diagnosing cancer so he consults a second doctor, B, who 
declares that he has cancer. How is the patient's belief that he has cancer 
affected by these two medical opinions ? 
Show that, if doctor ,4 diagnoses cancer in only 60 o/0 of those patients 
who have it, and never in the case of those who do not: and if doctor B 
diagnoses cancer in 80% of those patients who have it and in 10% of 
those who do not, then the patient's odds against not having cancer are 
'multiplied by 16/5 as a result of the two opinions (which are supposed given 
independently). 
39. A, A., ..., A, are events which could result from an experiment. 
Show that the probability that at least one of these events occurs is given by 
Px = .p(A)- Y. ?E p(AA) 
i 
+ Z Y, Z p(AAA)- ... + (-1)'-1p(,4,4 ... A,), 
where, for example, p(,4i,4) is the probability that both `4i and .45 occur. 
Sixteen married couples are the only people involved in an accident from 
which only six persons survive. Calculate the probability that there is at 
least one married couple among the survivors. (Leicester.) 
49 
PROBABILITY 
ONE 
2 
DISTRIBUTIONS-- 
VARIABLE 
In the first chapter the discussion concerned the occurrence or 
non-occurrence of an event (or the truth or falsity of a hypo- 
thesis). Observations are often more detailed than merely 
looking to see if an event has occurred or not, and in this 
chapter the concept of probability is extended to the case where 
the observation is a single real number. 
2.1. The discrete case 
Consider a random sequence of n trials with constant prob- 
ability, p, of success (�1.3). We evaluate the probability, Pt, of r 
successes (and therefore (n- r) failures) in the n trials. The r suc- 
cesses and (n-r) failures can take place in several orders. 
Consider any particular order, for example r successes followed 
by (n- r) failures. Since the trials are random, that is the events 
of success or failure are independent, the multiplication law 
(equation 1.3.2) applies and the probability of obtaining r suc- 
cesses followed by (n- r) failures is �q'-r, where q = 1 -p, the 
probability of a failure. This probability is the same for any 
other order in which the r successes occurred. But the different 
orders are certainly exclusive, and there are (r n) of them,' so 
that the addition law (axiom 2, � 1.2) applies and the required 
probability is given by 
The situation just considered is a particular case of the 
following. Associated with each elementary event a in the 
sample space is an integer which may be positive or negative or 
' ()denotes the number of combinations of n things taken r at a time. It is 
equal to n I/r! (n- r) ! and is alternatively written 
50 PROBABILITY DISTRIBUTIONS [2.1 
zero; Ar is the set of. a for which the associated integer is r and 
p, = p(Arl A) = p(&.), say. The events (A,.) are exclusive and 
exhaustive, so the (p,} satisfy: 
p>0, 2]p= 1. (2) 
A sequence {p} satisfying (2) is said to be a probability density. 
The integer associated with each a is called a random variable, 
and (p) is the probability density of the random variable. 
Probability density will usually be abbreviated to density. The 
random variable is said to have a distribution (of probability), 
and one way of describing the distribution is by its density. The 
special distribution whose density is given by (1) is called the 
binomial distribution: n is termed the index and p the parameter 
of the distribution. A random variable with a binomial distribu- 
tion is called a binomial variable and we often say a random 
variable is B(n, p), meaning that it is binomial with index n and 
parameter p. 
If {p} is a density (of a random variable) 
Pr = 
is called a distribution function (of a random variable) and 
provides another way of describing a distribution. Clearly, 
5; As is the event that the random variable is less than or 
equal to r. Hence by the addition law, P is the probability that 
the random variable is less than or equal to r. We also have that 
P < Ps if r < s, (3) 
and since 22 pr is a convergent series of non-negative terms, 
lim P = 0, lim P = 1. (4) 
Any function satisfying (3) and (4) is said to be a distribution 
function. 
If the series Zrp, (5) 
converges absolutely (that is if Z I rlp, converges) its sum is 
called the mean of the distribution, and is usually denoted by/, 
or the expectation of the random variable with this distribution. 
2.1] TH� DISCR�T� CAS. 
In the latter context it is usual to write (5) as P(r). 
a function of the random variable, 
Zf(r) p 
51 
If f(r) is 
(6) 
is, if absolutely convergent, called the expectation off(r), and 
(6) is written P[f(r)]. The following theorems are immediate 
from the usual properties of absolutely convergent series, where 
the terms may be summed in any order. 
Theorem 1. If f(r), g(r) are two functions of a random variable 
whose expectations exist, then 
[f(r) + g(r)l = [_f(r)] +[g(r)]. (7) 
Theorem 2. If the random variable is non-negative then its 
expectation is 
'=0 
co oo 
For Y,(1-P) = Y YP8 = Y 
r=0 r=0 
8--1 o 
8=0 r=O s=O 
(8) 
Binomial examples 
There are many applications of the binomial distribution and 
we consider only a few. In factory inspection a random sample 
(� 1.3) is taken from a lot and the items in the sample are each 
tested to see if they are satisfactory (success) or defective. If the 
sample is small compared with the lot size (see � 1.3 again) the 
distribution of the number, r, of defectives is, because of the way 
the sample has been taken, binomial with index n and para- 
meter p, the proportion of defectives in the lot. The distribution 
of r tells one how often, in samples of size n' for a given value 
of p, r defectives will be found. Although it is intuitively obvious 
that about np defectives will occur in the sample, it is not clear, 
without knowledge of the distribution, how much departure 
from np is likely to occur just because of the randomness. The 
binomial density provides this information. Notice that 
although the conditioning event has not been explicitly stated 
here it is still relevant. It is the event, H, that a random sample 
of size n has been taken from a (large) lot in which the propor- 
tion defective is p. The distribution is binomial, given H. With 
32 PROBABILITY DISTRIBUTIONS [2.1 
other conditioning events it need not be binomial: thus, if the 
samples were to be taken from different lots with different p's 
we might obtain another distribution. 
Sometimes the samples are taken, not from a lot randomly, 
but from the production line at regular intervals. The binomial 
distribution may be relevant to this sampling method, but not 
necessarily so: for the production process may change with time 
so that defectives become more or less common, and the succes- 
sive samples may not be independent, because one defective may 
alter the probability for the next one taken. In any application 
2 4 6 8 10 12 
Fig. 2.1.1. The binomial density, B(12, 0.4) 
of the binomial distribution one should check that the assump- 
tions on which its derivation is based, i.e. of independence and 
constant p (the hypothesis H above), are reasonably true. 
A second, similar example is the inspection of seeds for 
germination in order to test if they reach the minimum standard 
laid down by law. A third application is to genetics: for 
example, in the mating of two heterozygotes the probability of 
a heterozygote resulting is 1/2, and so the distribution of the 
number of heterozygotes from n independent matings will have 
a binomial distribution with index n and parameter 1/2. The 
number of animals affected in the insulin example (� 1.6) will 
usually have a binomial distribution of index 20 and parameter 
1/2 if the insulin is of the correct potency, but otherwise will be 
different from 1/2. Another application, to the random walk, is 
given in {} 2.5. 
2.1] xR� DSCa�T. CAS� 53 
The name, binomial, is applied to this distribution because 
(1) is the coefficient of x r in the expansion of (px +q)' by the 
binomial theorem. Fig. 2.1.1 represents the density in the case 
p = 0.4, n = 12. The abscissa is r and a solid line of height Pr 
is erected vertically for each r, 0 < r < 12. The probability 
increases with r up to a maximum (here at r = 5) and then 
diminishes steadily. This is the usual shape, but for p near 0 the 
maximum may occur at r = 0 and pr steadily diminish with r: 
similarly, with q near 0 the maximum may occur at r = n. 
P 
r k 
1'0- 
0'5 
I 
! 
I 
I 
I 
I I I I It' 
0 2 4 6 8 10 12 
Fig. 2.1.2. The binomial distribution function, B (12, 0'4) 
Vr =  (12 (0.4) (0.6)_s. 
8=0\$/ 
Fig. 2.1.2 represents the distribution function for the same case. 
r is still the abscissa, and the ordinate at r is P,, equal to 
 pq-. 
$0 
The definition of a distribution function may usefully be 
extended by defining it as F(x), the probability that the random 
variable is less than or equal to x, for any real number x, not 
merely for an integer (cf. � 2.2, below). Clearly F(x) = P where 
r is the integral part of x. The figure has been completed by 
adding the horizontal portions for F(x). Notice that the vertical 
54 PROBABILITY DISTRIBUTIONS [2.1 
'jump' of the function at x = r is �r, the probability that the 
random variable equals r. 
The mean value of the binomial distribution is easily found 
by the binomial theorem 
Y, rpr = r Pq'- = Z (r- 1)(n-r) 
r=O r=O r=l � � 
= n� 
 1 
= np(p +q)-I =np. 
Random variables 
The general situation described above is one 
(9) 
measurement, or observation, which is necessarily an integer, is 
made and is subject to random fluctuations. Each such observa- 
tion corresponds, in the way described in � 1.2, to a point in the 
sample space and hence to the integer associated with that point 
(or elementary event). For example, we may observe the number 
of particles in a field of view of a microscope, the number of 
errors on a page of a book the number of insurance claims in 
a fixed period of time. Such integer observations vary according 
to the point in the sample space, and, because of the probability 
structure over the space, they vary in a probabilistic or random 
way: hence the name random variable. An integer is an example 
of a discrete variable. Other discrete variables occur in practice 
but can nearly always be changed to an integer form. For 
example, measurements may be made of length to the nearest 
i in., so yielding discrete values' multiplication by 4 will convert 
them to integers. 
We shall find it convenient in the early stages of the discussion 
to distinguish in the notation between the random variable and 
the values it takes. Each a c A has associated with it an integer 
r(a). r(a) is the value the random variable takes at a. On the 
other hand, the random variable is the rule of association which 
attaches an integer r to each a. This association may be denoted 
by r(.), reserving r(a) for the value of the random variable at a. 
The distinction is the same as that between the cosine function 
which associates with every angle a real value and cos x which 
in which a 
2.1] :H� r>IscR�T. CAS. 55 
is the value of the cosine function for angle x. The cosine func- 
tion can be written cos (.). The notation r(.) is a little cumber- 
some and we shall follow Raiffa and Schlaifer (1961) and use ?. 
Thus ? is the random variable and r is a typical value that it 
takes. In this notation (5) may be written 
(?) = Zrpr 
and (7) becomes 
t[f() + g()] = t[f(?)] + t[g()]. 
The. distinction between ? and r may assist the understanding in 
the early stages, but is more conveniently dropped in later work 
where it does more harm than good. We shall not therefore 
adhere rigorously to it: only using the tilde when the distinction 
seem s helpful. The situation is analogous to the reference to 
'a table of cos x', meaning a table of the cosine function, not 
merely the value of that function for angle x. 
The manner of the random variation can be described in 
several ways. Two are described above, the density and the 
distribution function. Others will be met later. Either of these 
gives the probability that ? will assume any given integer value r, 
the former directly, the latter by minor calculations. The way 
that the probability is distributed amongst the integers describes 
the probability distribution of the random variable. Distribu- 
tions are often considered without any random variable in 
mind, but merely as a set of numbers satisfying (2). Properties 
of distributions derived from such considerations can be applied 
to any random variable having that distribution. Examples of 
distributions besides the binomial will occur throughout the 
book. 
Expectation 
The idea of expectation occurs very early in the study of 
probability and it is even possible to start with the concept of 
expectation as the basic idea and develop probability from the 
properties of expectation, contrary to the method used here. It 
first arose in games of chance.  Suppose after each play: of the 
' Like roulette; as distinct from a game of skill, like bridge.  
: The garre roulette: a play of roulette is a single throw of the ball. 
$6 PROBABILITY DISTRIBUTIONS [2.1 
game a player is given a prize, ?, supposed integer valued, and 
1 < r  /c, depending on the outcome of the play. Let A be 
the event of obtaining a prize r and let p(Ar) = p, so that {p} is 
the density of a distribution. If a large number, n, of indepen- 
dent plays result in ,4 occurring m times, then, as explained in 
� 1.1, 'lira' m/n = P.r. The player's total prize after n plays is 
22 rm,. and hence his average prize per play is Y r(m,./n). Now 
r=l r=l 
let n-.*c and with a commonsense interpretation of the 
limiting operation this will tend to  rpr.= .d(). Hence ,(?) is 
'=1 
the average prize per play in a long series of plays: iris the amount 
the player 'expects' to win in each .play: it is the amount he 
should pay the prize-giver before he plays in order that the game 
be fair. Of course, this explanation is only an interpretation' we 
shall later (�3.6) prove a result, within the mathematical system, 
which says that the long-run average of a random variable is its 
expectation. 
Expectation has also a maning in connexion with degrees of 
belief. The scientist quoted in � 1.6 would expect to gain nothing 
from a bet at odds of 9 to 1 in favour of H, and expect to gain 
- unit from a bet at odds of 4 to 1 with a stake of 1 unit. This is 
2 
obtained, as (5), by multiplying each prize (one of which is 
negative) by its probability (1 x  -4 x x[ = -}). The generaliza- 
tion to [f(?)] is needed if, for example, the value of a prize of 
amount r is equal to f(r). It is not necessary to calculate the 
distribution of the new prize in order to find its expectation; the 
latter can be calculated in terms of {p,.} directly by (6). 
Another interpretation of expectation is of interest. It has 
already been explained (example 2, � 1.2--and we use the notation 
of that example) that the elementary events in a discrete sample 
space may be thought of as particles with masses, m, propor- 
tional to the probabilities of the events, p. If, with each ele- 
mentary event, is associated an integer r, the particles may be 
placed at distances r along a line from some convenient origin. 
This association also defines a random variable, ?. Let/t be the 
distance of the centre of gravity of the particles so placed from 
the origin. Then since the moment about the centre of gravity is 
2.1] xlt. rSCRE?� CASh 57 
zero, Z(r-/t) mr = 0; but mr is proportional to p, and Zpr = 1, so 
that/t = Y, rp, Hence with this placing of the particles the mean 
is at the centre of gravity. The expectation off(f) can similarly 
be associated with the centre of gravity when the mass mr is 
distantf (r) from the origin. 
The reason for insisting on the series (5), if infinite, being 
absolutely convergent is that the sum of a conditionally con- 
vergent series depends on the order in which the terms are taken, 
and this would conflict with the intuitiv6 concept of expectation 
which does not involve any notion of ordering. Despite this, if 
the random variable is non-negativet and (5) diverges we some- 
times say that the expectation is +co; and similarly -co with 
a non-positive random variable. An example is provided in 
theorem 2: the series (8) diverges iff that for the mean does. We 
need this result later (in proving theorem 4.4.2). 
Geometric distribution 
This section is concluded by giving another example of a dis- 
crete random variable. Consider again a random sequence of 
trials with constant probability p of success but, instead of 
fixing n, the number of trials, and calculating the density of r, 
take the random variable, g, which is the number of trials up to, 
but not including, the first success. This can only take the value s 
if the first s. trials all result in failures and the (s + 1)st trial 
results in a success. Hence. by the multiplication law and the 
independence of the trials 
Ps = qSp (s > 0). (10) 
This is the density of a geometric distribution with parameter q: 
we denote it G(q). The reason for the name is that the successive 
terms have a common ratio q. The mean is 
oo 
rpr=)2, rqrp=pq dqr d 1 _q/p. (11) 
r=o r=o r=o- =Pq-q 
2.2. The continuous case 
An extension of the general situation discussed in the previous 
section is to consider associated with each elementary event a 
' That is it never assumes negative values (or does so with probability zero). 
$8 PROBABILITY DISTRIBUTIONS [2.2 
real finite number, �, not necessarily an integer. Let B be the 
set of a for which   x, where x is any real number. Write 
�(Bx); F(x). Clearly F(x) is non-decreasing, that is 
F(x) < F(y) if x <y, (1) 
since the event B implies B u (theorem 1.4.3). It also possesses 
the properties lim F(x)= 0, lim F(x)= 1. (2) 
To prove the first of these statements, we remark that if x is 
an integer, then, with n also an integer, 
F(x)= 7E p(n-1 <  < n): 
the series being convergent, we must be able to find a large 
negative x such that F(x) is arbitrarily small. The second follows 
similarly on considering 1- F(x). A function satisfying (1) and 
(2) is called a distribution function. The number, , associated 
with each a is called a random variable and F(x) is the distribu- 
tion function of the random variable. The random variable is 
said to have a distribution, and one way of describing it is by the 
distribution function. These definitions agree with and extend 
those of � 2.1. 
The distribution function of � 2.1 (in the form with continuous 
x) had discontinuities at the integer values. Suppose instead that 
there exists a functionf (x) such that 
f( )dt 
F(x) = t , 
(3) 
then f(t) is called a (probability) density (of a random variable). 
Since F(x) satisfies (1) and (2), we have 
f(x) > O, x)dx-- 1. (4) 
Any function satisfying (4) is called a (probability) density. It 
follows from the fundamental theorem of the integral calculus 
that iff(x) is continuous, then 
f(x) = dF(x)/dx. (5) 
2.2] TIE CONTINUOUS CASE 59 
Let A be the set of a having some property R; then we write 
p(A) = p(R). For example, if R is the property � < x we write 
p(Bx)--P( < x)= F(x). This economizes on notation, and 
p(') is to be read 'the probability that...'. An immediate 
consequence of (3) is that 
F(xo)-F(Xl) = p(xt <  < x.) = f'f(t)dt, (6) 
in words, the area under a density between two limits is the 
probability that a random variable with that density lies between 
those limits. If the integral 
f _ xf(x) dx (7) 
is absolutely convergent its value is called the mean of the 
density,/, or the expectation of the random variable (�). If 
g(x) is any function and 
f _g(x)f(x)dx 
is absolutely convergent, the integral is called the expectation of 
g(g) and written $[g(g)]. Theorem 2.1.1 extends to this case. 
The analogue of theorem 2.1.2 is 
Theorem 1. If the random variable, with density f(x), is non- 
negative then its expectation is 
Forf 
(8) 
Continuous random variables 
All observations in the real .world are discrete because they 
are made to the limits of accuracy of the measuring instrument, 
for example to the nearest tenth of a second. But there are con- 
60 PROBABILITY DISTRIBUTIONS [2.2 
siderable mathematical advantages in introducing the idea of 
continuity and the field of probability is no exception. The real 
difference between the discrete and continuous cases is that in 
the former no finer measurement is imagined (there cannot be 
3� successes, for example), whereas in the latter refinements are 
conceptually possible by using a more accurate apparatus. 
The definition given in this section of a distribution function, 
equations (1) and (2), is general and includes the discrete case: 
namely, it is the probability that the random variable is less than 
or equal to a given number. Any random variable has a distribu- 
tion function and it is a remarkable fact, that we shall not prove, 
that given the distribution function the probability of any event 
concerning solely the random variable can be calculated: we 
have seen how this can be done for the probability that it lies 
between two limits (equation (6)). Thus the distribution function 
completely defines the distribution of the random variable. In 
the discrete case we saw that the distribution function was con- 
stant in intervals with integer end-points and was discontinuous, 
or had 'jumps' at integer values equal to the probabilities of the 
random variable being equal  to those integer values. On the 
other hand, if F(x) can be written as an integral (equation (3)), 
it is necessarily continuous everywhere since an indefinite 
integral is a continuous function. The converse is not true, 
namely a continuous distribution function cannot necessarily be 
written in the form of (3), but the possibility of a continuous 
F(x) not satisfying (3) can be ignored in most applications. An 
example will be given in �3.2. The case where (3) obtains will be 
referred to as the continuous case, and we shall refer to a random 
variable with a density in the sense of this section as a con- 
tinuous random variable. 
Probability density 
To help understand the meaning of the density and equa- 
tion (5) in the continuous case, an analogy from mechanics is 
again useful. Consider a rod such that the total mass of the rod 
to the left of x is F(x). (If  can take arbitrarily large values the 
rod will be infinite in extent: consideration of the case where 
necessarily xx <   x. so that we have a finite rod of length 
2.2] TIIE CONTINUOUS CASE 61 
x2-x may be easier.) The case of a uniform rod was given in 
example 1 in � 1.2. In the general case what is the mass density 
of the rod at x? Density is defined by taking a small interval 
about x, dividing the mass of the rod in the interval by the width 
of the interval and allowing the latter to approach zero. If the 
intervfil (x, x + h) is taken the ratio is {F(x + h)-F(x)}/h which 
tends to f(x) (equation (5)). Hence, in the analogy, f(x) is the 
mass density of the rod, and the term probability density is 
natural for the general case. Consequently the probability that 
a continuous random variable lies in a small interval of width h 
about x is approximatelyf(x) h. Sometimesf(x) is defined by (5), 
but this, besides being wrong in general, misses the main func- 
tion off(x), namely its use in (6): the density is a function which, 
when integrated over a region (and in particular an interval), 
gives the probability of the random variable belonging to that 
region. Notice that density has slightly different meanings in the 
discrete and continuous cases. The justification for a common 
name is that the two functions behave in exactly the same way in 
most cases, as we shall see repeatedly below. 
Notice that we have supposed a random variable'to be finite. 
Thus, if ? is a random variable with non-zero probability of 
being itself zero, then 1/? is not a random variable. Our random 
variables are often said to be honest. 
Although most distribution functions will either be discrete 
(�2.1) or continuous, we shall sometimes meet the mixed case. 
An example (�4.2) is the time a customer has to wait to be 
served by a shop-assistant. If the shop-assistant is free when the 
customer enters the shop the time will (with an attentive 
assistant) be zero. However, if there are other customers present 
the new arrival will have to wait until they have been attended to. 
The waiting-time is measured continuously (from 0 to + oo) but, 
if p is the probability that the assistant is free, p will typically 
(for the assistant's sake) be non-zero. Hence we can expect 
F(x) to be zero for x < 0, be equal to p at x -- 0 and be con- 
tinuous for x > 0. It cannot therefore be written in the form (3) 
but it can be written for x > 0 as 
F(x) = p+ f(t)dt, 
62 PROBABILITY DISTRIBUTIONS [2.2 
and with obvious modifications can be handled like a continuous 
distribution function. Notice generally that if F(x) is dis- 
continuous at x = x0 the 'jump' at the discontinuity is the 
probability that the random variable equals x0: conversely, if 
F(x) is continuous the probability that the random variable 
equals Xo is zero. This last result explains why we could not 
proceed, as in �2.1, by defining an event A.,. containing all 
elementary events for which the random variable equals x and 
using p(Ax): it would, in the continuous case, be zero. 
Expectation 
The definition by (7) of the mean or expectation is a natural 
generalization of the corresponding definition (equation 2.1.5) 
in the discrete case. Suppose the range of g divided into small 
intervals of equal widths 8x. The probability of  lying in one of 
these intervals is approximately f(xr)8x (by what we have just 
discussed), where xr is some point of the interval. Hencef(x,.) x 
may be compared with p and the mean value is approximately 
Yxrf(x) 8x, which is an approximating sum to the integral 
_ xf(x)dx. The justification for the integral for o[g()] is 
oo 
similar. As in the discrete case/ is the position of the centre of 
gravity of the rod just described. 
The idea of replacing a summation (ZrpO by an integration 
(fxf(x) dx) in passing from the discrete case to the continuous 
one is of frequent use. The proof of theorem 1 is an example of 
such a change from that of theorem 2.1.2. We shall often give 
a proof of a theorem that covers only one of the cases and then 
remark that the other case follows on changing from sum- 
mation to integration or vice versa. There is a mathematical 
technique (Stieltje's integration) which unites the two cases, but 
it is beyond the mathematical level of this book. Notice that the 
density, {pt} orf(x), is used similarly in the two definitions of the 
expectation: this is the reason for using the same name to 
describe {Pt} and f(x). In order to give interesting examples of 
continuous distributions we pass, in the next Section, to, the 
consideration of an important probability problem. 
2.3] THE POISSON PROCESS 63 
2.3. The Poisson process 
Consider a sample space in which each elementary event 
consists of an infinite sequence of real numbers {t} with 
0 < t < t2 < ... < t, < t,+ < .... The elementary event cor- 
responds to the observation of a process, beginning at time 
t = 0, during which any number of incidents can occur; the rth 
incident occurring at time tr. Let t and h be such that 
0 < t < t+h. LetA be any event which refers only to in- 
cidents in the interval (0, t) and, for any non-negative integer k, 
let B be the event of k incidents in the interval (t, t + h). ' If the 
events A and B, so defined, are always independent the prob- 
ability system is said to be a purely random process. If p(B[A), 
which, in virtue of the independence, may be written p(B), 
depends only on h and k, and not on t, the process is said to be 
stationary and the system is said to be a purely random stationary 
process, or a Poisson process. 
Theorem 1. In a Poisson process, po(t), the probability of no 
incidents in a fixed .interval of length t, is e -xt, where/l is non- 
negative. 
Consider an interval of length t + h. Because the process is 
stationary it does not matter where the interval begins. No 
incidents occur in it iff none occur in either of the non-over- 
lapping subintervals of lengths t and h. These last two events are 
independent, by the definition of a Poisson process. Hence by 
the multiplication law (equation 1.3.2), 
po(t + h) = po(t) po(h). (1) 
Taking logarithms of each side shows that In po(t)  is an additive 
function of its argument, and so is -/it, for some/1. Finally, 
must be non-negative since only probability solutions, that is 
solutions in (0, 1), are meaningful. 
Theorem 2. In a Poisson process the density, f(x), of the time, 
to the first incident is/1 e -xx,.for x > O. For x < 0 it is obviously 
zero. 
' The instant t may belong to either, but not both, of the intervals. 
, Throughout this book we use natural logarithms, to the base e, and denote 
them by In. 
64 PROBIBILIT� DISTRIBUTIONS 
Let x be any positive number. Then [ > x iff no incidents 
occur in (0, x). But by theorem 1 this probability is e -xx. 
Hence 
p(/ < x)= 1-e-5 (2) 
and the left-hand side is, by definition, the distribution function 
of [x, which clearly has a density, obtained by differentiation; 
namely f(x) = ,te -x. (3) 
Corollary. In a Poisson process the density of the time between 
any two successive incidents is also given by (3). 
Consider, for example, 2- t = g, say, and consider its distri- 
bution when the conditioning event is that  is some fixed 
value, u. That is, consider the Poisson process when the first 
incident happens at u. The basic assumptions of independence 
of events concerning the intervals (0, u) and (u, u + x) and the 
stationarity mean that the same arguments used in the proof of 
the theorem for the interval (0, x) apply to the interval (u, u + x). 
Hence the density is still given by (3). Since this does not 
involve u, g must be independent of/r, and hence (3) is the 
density for general u. 
Equation (3) is our first example of a density: it is referred to 
as the density of the exponential distribution with parameter 
It is a special case of the F-distribution below. The distribution 
will be denoted by EO). 
Theorem $. Let t be any fixed positive number. In a Poisson 
process, p(t), the probability of n incidents in an interval of 
length t, is e-Xt(At)**/n!. 
Considers any interval of length t, say (0, t) and divide it up 
into a large number, N, of intervals each of length 8s = t/N, 
let m be an integer, 1 < m  N, and s = mt/N. Then the event 
of n ( > 0) incidents in (0, t) can take place in one of the following 
N exclusive and exhaustive ways: the first incident occurs in the 
interval [(m- 1)t/N, mt/N] and there are (n- 1) incidents in the 
interval [mt/N, t], which two events are independent. Now if N 
' The independence of two random variables, here g and [, has not been 
defined. This will be done in {}3.2. Here we mean by 'independent of ir', 'the 
distribution does not depend on the value of/;', namely u. 
:l: The proof contains a minor gap. This will be discussed below. 
2.3] THE POISSON PROCESS 65 
is large so that tin = Os is small, the first probability is approxi- 
mately, by (3) and the general property of a density, A e -x8 &; 
that is, the density at some point (here s = mt/N) of the interval 
times the width of the interval. The second probability is 
p,,_(t - s). Hence, by the addition law, p,,(t) is approximately 
N 
22 Ae-XSp,_x(t- s) Os (s = mt/N). (4) 
But this is an approximating sum to an integral so that, on 
allowing N to tend to infinity (Os -> 0), we have 
p(t) = fl Ae-XSP"-x(t-s)ds. (5) 
The result now follows by induction. If 
p._x(t-s) = e -art-s>A'-(t-s)'*-x/(n- 1)! 
then, by (5), 
p,,(t) = e-XtA"fl (t-s)'-Xds/(n - 1)! 
=e-Xt(At)r/n!. (6) 
Hence if the result to be proved is true for (n- 1) it is true for n. 
But it is true for n = 0 (theorem 1). Hence it is true generally. 
{p,(t)}, for fixed t, is a probability density (of the random 
variable h). It is called the density of the Poisson distribution. 
It depends only on the product At =/t, say: / is called the 
parameter of the distribution and we write P(/0 for a Poisson 
distribution with parameter 
Theorem 4. The expected number of incidents in any time interval 
of length t is At.  
The probability distribution of the number is POt) so we have 
only to find the mean of the Poisson distribution. This is, where 
!  = At, oo 
Y, np.,(t) = e-/'t* 22 "-/(n- 1) = , 
n=0 
since the series is the exponential series with sum e. 
This theorem enables a physical interpretation to be given 
of A: it is the expected number of incidents per unit time. It is 
66 PROBABILITY DISTRIBUTIONS [2.3 
the ,fate of occurrence of the incidents. (See also the discussion 
below). 
Theorem $. In a Poisson process, t,'f n is a fixed number, the time, 
g,,.from the start to the n-th incident has a density f,,(x) given by 
f(x) = e-XA'*x'*-/(n - 1)! (7) 
for x >.>. 0 and zero for x < O. 
The theorem is a generalization of theorem 2, and the proof 
is similar to the proof of that theorem. Let x be any positive 
number. Then , > xiff (n- 1), or fewer, incidents occur in (0, x). 
But by theorem 3 and the addition law this has probability 
e-X{1 + (,x)+(Ax)"/2! + ... +(Ax)'-X/(n - 1)!}. (8) 
Hence p(/, < x), the distribution function, is 1 minus this 
expression. Differentiation of that function gives, because most 
of the terms cancel in pairs, the result (7). 
Corollary. In a Poisson process the density of the time between 
two incidents which are n apart is also given by (7). 
The proof is similar to the proof of the corollary to theorem 2. 
The density (7) is said to be the density of a gamma distribution. 
X is called the parameter and n the index. We write F(n, A) for 
a gamma (P) distribution of index n and parameter A. The 
exponential distribution (above) is P(1, A). 
Theorem 6. The expectation of the time up.to the n-th incident, 
is n/It. 
The probability distribution of the time is P(n, ) so we have 
only to find the mean of the P-distribution. This is (equation 
2.2.7) 
f xf,,(x)dx = Io e-'(itx)'*dx/(n-1)!. 
Substitute Ax = t, so that X dx = dt. Then the expression is 
The integral is well-known to be n! and the result follows. 
This theorem gives a second interpretation of ,. With n = 1 
the expected (or average) time between successive events is -!. 
2.3] THe. 'OSSON 'ROCESS 67 
Examples 
There are many practical situations where observations are 
made on incidents: that is, happenings that occupy only an 
incident of time and are not spread over an interval. A famous 
example is a Geiger counter, which counts the incidents of the 
arrival of atomic particles at the counter. Other incidents are 
the breakdowns of a machine, accidents to a worker, demands 
for connexion from telephone subscribers, aircraft arriving at 
an airport and requesting permission to land and, generally, 
arrivals of' customers' requiring ' service' at a ' counter'. Such 
incidents form a process and if the process is subject to prob- 
ability laws it is called a random or stochastic process. The 
most important feature of any stochastic process is the way 
in which the past behaviour of the process influences the future 
behaviour. The purely random process is one in which this 
influence is nil: that is, the future is independent. of the past. 
If, in the formal definition above, t is thought of as the present, 
the definition says that whatever happened in the past (that is, 
whatever A is) does not affect the probability of an incident in 
the future. It might be thought that such 'processes are too 
random, or too chaotic, either to occur in practice or, if they do, 
to be usefully studied. But this is not so. The Geiger counter 
provides an excellent example: the individual particles behave 
quite independently of each other in many situations, the only 
slight difficulty resides in the fact that the counter has a 'dead 
time' immediately after a particle has arrived during which it 
cannot record the arrival of another. But even then the basic 
arrival process is purely random and from its properties one can 
deduce the properties of the recorded process. Another excellent 
example is the telephone one: subscribers act without know- 
ledge of each other's behaviour and there is an extensive and 
useful theory of the capacity of telephone exchanges based on 
the theory of the Poisson process. The other examples may 
sometimes be purely random, but not always. Thus the aircraft 
may tend to arrive in groups because of weather conditions, or 
they may arrive rather regularly because they have been 
scheduled to do so. A newly repaired machine may be more or 
less reftable than one that has not broken down for a while, and 
68 PROBABILITY DISTRIBUTIONS [2.3 
there�ore the knowledge of its age since last repair (that is, an 
event of the type of A) may influence, and not be independent of, 
a breakdown in the future (this will be discussed in �4.4). 
Nevertheless, the purely random process provides the founda- 
tions for many stochastic processes (�or example the queueing 
process, ��4.2, 4.3). It has been shown that when incidents are 
of several different types, each type occurring with some degree 
of regularity, the over-all picture o� incidents may be random. 
The stationarity restriction means that the origin of time is 
irrelevant. For example, the telephone process is clearly not 
stationary, the probability of no calls between 02.00 and 02.05 h 
is cle.arly greater than between 14.00 and 14.05 h: nevertheless, 
it may be stationary over short periods of time, say between 
14.00 and 17.00 h. In all these examples the variable, t, has been 
referred to as time, but it may represent a spatial variable. For 
.example, consider a crop growing in a row. The {ti} may be the 
distances from the end o the row of points of infection, and the 
infection is then said to be purely randomly distributed along 
the row. The notion can also be extended to processes in the 
plane or in space: the basic requirement is that the probability 
of an incident in a region is independent of any event con- 
cerning incidents outside the region. Flaws in a sheet of metal, 
dust particles on a plate, raisins in a cake, are three examples 
where such a probability structure might apply. 
Exponential distribution 
Theorem 2 provides our first example of a density in the 
continuous case. The reader should sketch the distribution func- 
tion (equation (2)) and the density (equation (3)) and consider 
how they depend on ,. The former is continuous so there are no 
single values of non-zero probability. The density is discon- 
tinuous at the origin, changing from zero to ,k, and then dimin- 
ishing steadily with time. The occurrence of a maximum of the 
density at t -- 0 is interesting because it means that the small 
intervals between successive events are more probable than the 
longer ones. In a real process (such as telephony) which is 
purely random, there is more clustering together of the incidents 
than most people expect. I they are asked to put points at 
2.3] THE POISSON PROCESS 69 
random on a line, say (that is, a spatial case), they tend to distri- 
bute them too uniformly. Perhaps this clustering is what lies 
behind the proverb 'It never rains, but it pours'. An interesting 
example is the position of fall of flying-bombs on London 
during the last war. Some places were described as getting an 
unfair share of the bombs: in fact the distribution was just what 
one would expect from a Poisson process. An interesting con- 
sequence of the purely random property is that you can expect 
to wait as long for an incident whether one has just occurred or 
not. This follows from theorem 2 and its corollary. 
There is a close connexion between the exponential distribu- 
tion and the geometric distribution (�2.1). The geometric distri- 
bution was obtained by considering a random sequence of trials 
with constant probability of success and taking the number of 
trials up to, but not including, the first success. If we think of 
a success as an incident which can only happen at discrete, 
equally spaced time points (the trials) then, in virtue of the 
independence of the trials and the constancy of success at each 
one, we have a situation analogous to the Poisson process 
wherein the events in different time-intervals are independent 
and the chance of an event constant. Consequently the number 
of trials before the first success is analogous to the time up to the 
first incident. The densities both have the property that an 
increase in the value of the random variable from s to s + m 
causes the density to be divided by a quantity which depends 
only on m and not on s. 
Poisson distribution 
Theorem 3, the proof of the Poisson distribution, is an 
important result. It applies to the number of incidents in a fixed 
period of time: the number of telephone calls, the number of 
atomic particles, etc. Fig. 2.3.1 shows the densities (using the 
same method as with the binomial in � 2.1) for #, the mean, equal 
to 1 and 3. Fig. 2.3.2 similarly shows the distribution functions. 
For all but small/x the density increases to a maximum with n 
and then diminishes. The increase is more rapid than the 
decrease and the right-hand 'tail' of the density is longer than 
the left-hand one. For small/ the maximum is at n = 0. It is 
70 PROBABILITY DISTRIBUTIONS [2.3 
worth remembering, though the proof is beyond the level of this 
book, that the Poisson distribution characterizes the Poisson 
process. That is, not only does the process yield the distribution 
but the distribution, with mean proportional to the length 
of the interval, can only arise from the process. A common way 
of testing whether a process is Poisson is to test whether the 
number of incidents has a Poisson distribution (�7.5) and then 
use the characterization. 
Pt/ 
0.1 
0.3 
0.2 
0.1 
0 
Fig. 2.3.1. 
0 
2 4 6 
(a) 
! 
2 4 8 
.I 
(b) 
(a) The Poisson density, P(1) 
(b) The Poisson density, P(3) p. = e43"/n !. 
2.31 
0'5 - 
o 
THE POISSON- PROC!]SS 
I I I 
2 4 6 
(a) 
0.5 
0 
I I I I I 
2 4 6 8 I0 
() 
Fig. 2.3.2. 
(a) 
The Poisson distribution function, P(1) P, =. 
8----0 
(b) The Poisson distribution function, P(3) P, = Y e-'38/s!. 
71 
72 PROBABILITY DISTRIBUTIONS [2.3 
Suppose that the interval, (0, t), in theorem 3 is small. From (6) 
we have that lira p(t)/t = A and lim p,(t)/t--0 for n y 1. 
t--0 t--0 
A can therefore be interpreted as the rate' of occurrence of 
incidents and we shall speak of a Poisson process of rate ,. The 
probability of one incident in a small interval is approximately A 
times the length of the interval; the probability of two or more 
incidents is small in comparison with the length of the interval. 
A process with the property of the last sentence is often called 
a Poisson process but in fact that is only part of the definition: 
the independence of past incidents is the kernel of the definition. 
The proof of theorem 3 is not quite rigorous for it involves 
a limiting argument and ignores the possibility of two or more 
incidents occurring in [(m- 1)t/N, mr/N]. In fact, the latter has 
a probability which is small in comparison with the length, t/N, 
of the interval, so that it can be ignored as N - c by what has 
just been said. Nevertheless, the type of argument used in the 
proof is often useful (and that is why it has been given) because 
it extends the generalized addition law (theorem 1.4.4) from an 
enumerable infinity of events to a continuous infinity. If As is 
the event T = s, that the first incident occurs at time s, and 
p,(tlAs) is the probability of n incidents in (0, t), given As, then 
the expression  p,,(tlA)p(A) which would have been used to 
$ 
calculate p.,(t) had Tx been discrete, is replaced by equation (5) 
where p*(A) is the density of fx. This is another example of a 
summation in the discrete case being replaced by an integration 
in the continuous case. As here, the continuous case can be 
reached by considering the discrete case first, with the prob- 
abilities being products of densities and lengths of small intervals 
of the random variable, and then passing to a limit as these 
lengths tend to zero: the discrete sums are approximating sums 
to the integral limit. This will be discussed further in �3.2. 
A rigorous proof of the Poisson distribution goes along the 
' Compare the concept of velocity (or rate of motion). A particle has velocity v 
if the distance covered in a small interval is approximately v times the length of 
the interval. 
2.3] THE POISSON PROCESS 
following lines. Divide the interval (0, t) into 
(0, u) and (u, t). Then using the addition law and 
independence property of the process we have 
px(t) = po(u) p(t- u) + pdu) po(t- u) 
(cfi equation (1)). Since po(t) is known this is an equation for 
px(t). Generally pn(t) can be written as an expression involving 
{p(t)} for r < n. Successive solutions of these equations give 
the required result (cf. also example 2.6.3). Notice that we have 
tacitly made the assumption that the incidents are ordered. That 
is, at any point of time there is a next incident, the first to occur 
after that point. Thus the possibility of two incidents occurring 
at the same time is not admitted, nor is the more recondite 
possibility of them occurring at times n -x (n = 1, 2, ...) so that 
there is no next incident at t = 0. 
73 
two intervals 
the basic 
Alternative derivation of the Poisson distribution 
The Poisson distribution is named after the French mathe- 
matician, Poisson, but he derived it in a different way, namely 
as a.limit of the binomial distribution. We now give the modern 
version of his derivation, although it amounts to a third proof 
of theorem 3, because it is still of some interest. Let {p} be the 
density of a binomial distribution B(n,p). The mean is np 
(equation 2.1.9) so that if we allow n to approach infinity and p 
to approach zero with np =/t, constant, we might expect the 
distribution to tend to a limit since its mean will remain finite. 
With p = tt/n, (2.1.1) becomes, with some rearranging, 
Now allow n to tend to infinity. The first term does not involve n, 
so remains W'/r !; the second tends to 1 since it is the product of r 
terms each of which tends to 1; the third tends to e- by a 
standard result; the fourth term tends to 1-' = 1. Hence the 
limit of p is e-y'/r, the density .of the Poisson distribution. 
The practical significance of this is that for binomial situations 
with large n and small p the more easily calculated PG0 may 
replace B(n, p) if tt = rip. A classic, but not very good, example 
is deaths from the hcks of horses in the Prussian cavalry. The 
74 PROBABILITY DISTRIBUTIONS [2�3. 
number of exposures, n, to being kicked was large, but the 
chance of death when exposed, p, small. But it is possibly more 
realistic to think of it as a Poisson process with incidents (death 
from the kick of a horse) occurring independently of past inci- 
dents. The formal connexion between the proof just given and 
the process is obtained by dividing the interval (0, t) into n small 
intervals. The probability of an incident in a small interval of 
length t/n is ,t/n =p and, because of the independence and 
stationarity, the n intervals are like a random sequence of n trials 
with constant probability p of success. Hence for finite n the 
distribution is binomial B(n, p) and p = At/n. Allow n-- c, 
A and t fixed, apply the above result and we have a proof (not 
quite rigorous again) of theorem 3. 
The gamma distribution 
The gamma distribution of theorem 5 will occur again later 
(example 3.5.1;�5.3). Meanwhile we remark that the density 
(for n > 1) has the value zero at x = 0, increases to a maximum 
at x -- (n- 1)/, and then decreases: the rate of decrease being 
slower than the increase. Notice that this distribution is of 
the random variable, 'the time taken for a fixed number of 
incidents'; in contrast to the Poisson distribution, which is of 
the random variable, 'the number of incidents in a fixed time'. 
In other contexts the index of the F-disfribution need not be 
an integer. The function f,(x) in (7) represents a density; that 
is, satisfies equation 2.2.4, provided n > 0 and n! is defined 
by ff e-tt  dr. This integral is usually called the gamma function 
and is denoted by F(n + 1); hence the name of the distribution. 
The F-notation for the integral will not be used in this book 
because of the confusion over the n + 1 in the argument when 
n is the power of t in the integrand. The integral will be called the 
factoriM finction. ( - �) ! will be evaluated in � 2.5. 
2.4. Features of distributions 
The mean of a distribution has already been defined (�� 2.1,2.2) 
as the expectation of a random variable with that distribution. 
The elementary results 
= = 
2.4] VEArUR�S OV DISrROtrXOS 75 
where c is a constant and 2 a random variable, discrete or 
continuous, follow immediately from the definitions. The 
variance of a distribution is deftned,, provided that the expres- 
sions converge, as 
f (x-/)'"f(x)dx or Z(r-/)'pr (2) 
in the continuous and discrete cases respectively, and is usually 
denoted by rr '. Here g is the mean. If  is a random variable 
with a distribution of variance r2 we speak of  as having 
variance rr ' and write it '(). From equations 2.1.6 or 2.2.7 
and (2) above it follows that 
: ,(e): m[{e- m()p-], 
expressing the variance in terms of expectations. 
(3) it follows that 
.(c): 
(3) 
From (1) and 
(x + c) = (). 
(4) 
The positive square root,  or 9(2), is called the standard 
deviation of the distribution or of the random variable. 
Theorem 1.: (): d(� 2) - (2). (5) 
For 
-() = ['-2o()+'()], by (3), 
= do(.)_ 2.() + $o(g), by (2.1.7), 
as required. 
A slightly different version of this theorem is useful for some 
discrete distributions. The proof is immediate from theorem 1. 
Theorem 2. (5:) = d�[( - 1)l + d(�) - d�:(�) � (6) 
Theorem 3 (Chebychev's inequality). If  is a random variable for 
which d�( ') exists and c is a positive constant, then 
p(ll > c) < (')/c . 
(7) 
'[ Integrals and sums whose ranges are from -oo to +oo will be written without 
the limits. 
$ $%) means {$()}a. 
76 PROBABILITY DISTRIBUTIONS [2.4 
The proof is given for the continuous case, with densityf(x). 
o( 2) =f x2f(x)dx, by definition, 
>.>.f xSf(x)dx, since the integrand is positive, 
xl > c 
> c' f(x)dx, since Ixl c in the range of 
x.>c integration, 
= cp(X' I > c), 
from the basic property of the density (equation 2.2.6). 
Corollary. If/ and o. are respectively the expectation 
standard deviation of :, 
and 
P(--t4 > co') -4< c -2. 
(8) 
This follows from (7) on replacing . by -tt and c by co'. 
Measures of location 
The probability structure of a random variable is described by 
its distribution function, or something equivalent to it such as 
a density. These are relatively complex descriptions, being 
functions, but they completely describe the probability structure. 
In this section we discuss certain numbers which describe 
feattires of the probability structure but do not characterize it. 
That is, a whole function is replaced by a single number; the 
loss of information being compensated for by a gain in simpli- 
city: several distributions having the same number associated 
with them. The mean, or expectation, is the most important 
feature and its interpretation has already been discussed. In 
virtue of the property in (1) of increasing by c if the random 
variable is increased by c, it is called a measure of location of 
the distribution: it describes the centre or location of the dis- 
tribution (see also �5.3). Other measures of location some- 
times used are the median and the mode. A median of a 
distribution is a value x such that, if 5: is a random variable with 
that distribution, p( < x) > � and p( > x) > �. If F(x) is 
continuous it is a root of the equation F(x) = �, and the random 
variable is equally likely to be above or below the median. If 
2.4] .ArUR.S Ot DISXRInUTONS 77 
F(x) is never constant in an interval the median is unique. 
A mode of a distribution is a value for which the density has 
a local maximum. Most distributions have a single local maxi- 
mum which is the greatest value, such distributions are unimodal: 
all distributions so far encountered are unimodal. One occa- 
sionally meets distributions with two modes; they are called 
bimodal. 
Measures of spreat 
In contrast the variance (or standard deviation) measures the 
scatter of the distribution about the central value, in this case 
the mean. It is the expectation of the square of the departure of 
the random variable from the mean. If the random variable is 
constant there is no scatter and the variance is zero: the more 
the scatter, the larger the variance. Notice, from (4), that the 
variance has the dimension of the square of the random variable 
whereas the standard deviation has the same dimension. The 
variance is the easier to handle mathematically but the standard 
deviation is the easier to interpret. In calculations (numerical 
or algebraic) we usually work with the variance and only at the 
end convert it into a standard deviation (cf. ��3.3, 5.1). In 
virtue of its properties in (4) the standard deviation is called 
a measure of spread. Other measures of spread sometimes used 
are the mean deviation, the range and the inter-quartile range. 
The mean deviation is defined as 
f lx-/lf(x)dx or Z Ir-/IP,, 
that is [1-/1], but the moduli signs make it awkward to 
handle. The range is only applied to a variable which always lies 
between two finite limits and is the least difference between 
the limits. For a continuous, strictly increasing distribution 
function the quartiles are the roots x and x. of the equations 
F(xO = �, F(X,0 =  and the inter-quartile range is (x2-x0. A 
random variable is equally likely to lie between or outside the 
quartiles. Modifications have to be made, like those for the 
median, with general distribution functions. 
We illustrate the use of theorem 1 by computing the variance 
78 PROBABILITY DISTRIBUTIONS [2,4 
o� the F-distribution. We have already seen (theorem 2.3.6) that 
its mean is n//, so [() = n/A, if  has a F-distribution. Then 
.(2) = f: x2f,,(x)dx 
and the substitution/lx = t gives (2 2) = n(n + 1)//l 2. Hence, 
by theorem 1, 
= n(n + 1)lit2-(n/)2 = n/it (9) 
In terms of the mechanical analogy that has been used before 
(�2.1) in discussing the mean, which was then the centre of 
gravity of a mass distribution, the variance is the moment of 
inertia about the centre of gravity. Theorem 1 is the familiar 
result which enables this moment to be calculated from the 
moment about the origin, ('), by subtracting the moment 
about the origin of the total mass situated at the centre of 
gravity, o2(). 
In the dis,zrete case theorem 2 is more useful and we use the 
binomial fc.r illustration. (?) -- np, if ? is B(n, p) (equation 
2.1.9). Then (compare the derivation of 2.1.9) 
[?(?- 1)] = 2] r(r- 1) prq-r 
' (n-2)r--2(n-2)-(r-2) 
=n(n-1)p 2Z P q 
r=2 r-2 
= n(n - 1)p=(p + q)- = n(n - 1) pZ. 
Hence, by theorem 2, 
z(F) = n(n- 1)pZ +np-n2p  = npq. 
We leave the reader to show that if F is P() then 
= a. 
(10) 
(11) 
Chebychev' s inequality 
The major use of. Chebychev's inequality is in deriving other 
theoretical results, particularly the law of large numbers (�3.6). 
But in the form given in the corollary it does immediately show 
that a random variable can only rarely depart substantially from 
its mean, the actual departure depending on the standard de- 
2.4] FEATURES OF DISTRIBUTIONS 79 
viation. For example, with B(100, �), which might arise with 100 
tosses of a newly minted coin, the mean is 100 x � = 50 and the 
standard deviation is /(100 x � x �) = 5 (equation (10)). Hence, 
with c = 2 in (8), the probability of either fewer than 40 or more 
than 60 heads is not more than 1/4. Actually the inequality, 
valid for any distribution with a variance, is too coarse for much 
use with those distributions which occur in practice. With a 
large class of distributions the right-hand side of (8) can be 
considerably reduced: for example with c = 2 we often have 
1/20 instead of 1/4. In the binomial the probability of the event 
mentioned is about 1/20 (cf. {}2.5). 
Other features of distributions 
Other features besides measures of location and spread are 
sometimes used. One particularly important one is the coefficient 
of variation, defined as the ratio of the standard deviation. to the 
mean, tr//t. This is only used when/t > 0 and usually only for 
positive random variables. The idea behind its use is that a 
deviation of amount tr is less important when/3 is large than 
when/t is small: a deviation of an inch in a mile is usually trivial 
compared with a deviation of an inch in a foot. The coefficient 
of variation of F(n,//) is n-t, which does not depend on/1. It is 
quite common to find in practice that the coefficient of variation 
stays fairly constant even when/t and  vary: for example, with 
wheat yields the mean changes from season to season and variety 
to variety but the coefficient remains at about 10%. It is com- 
monly multiplied by 100 and expressed as a percentage. It is not 
affected by a change of units of the random variable. No 
standard notation is available; we shall use (). 
An important group of numbers associated with a distribu- 
tion is the moments. The n-th moment about the origin, tt}, is 
defined as 
f xf(x)dx or Zr'pr, (12). 
provided that flxlf(x)ax or Z Irlp, (13) 
are finite. The latter is called the n-th absolute moment about the 
80 PROBABILITY DISTRIBUTIONS [2.4 
origin, h'. If g is a random variable with the corresponding 
distribution, we have 
tt is the mean, also denoted by #. The corresponding moments 
about the mean are similarly defined and the same notation is 
used without the primes. Thus 
t,, = f (x-tt)'*f(x)dx = [('-#)'], (15) 
provided that the corresponding absolute moment, 
= 
is finite. /t 2 is the variance. Other moments are sometimes used, 
but not in this book. In modern work the moments are largely 
replaced by cumulants, to be introduced later (�2.6). 
Histograms 
In discussing in chapter 1 the relationship between the axioms 
and the real world, the concept of a limiting frequency observed 
in practice was intimately relaied to the notion of probability. 
We now introduce some further empirical material which corre- 
sponds to the mathematical concept of a density. In � 1.3 we 
discussed the idea of random sampling from an infinite popula- 
tion and remarked that if each member of the population did, or 
did not, possess a characteristic then the sampling would be a 
sequence of random trials with constant probability of suc- 
cess (equal to the proportion of the population possessing the 
characteristic); and such trials exhibit the limiting success-ratio 
property. Consider again random sampling from a population 
but suppose that associated with each individual is an integer 
(or generally some discrete measurement), not the same for all 
individuals. In a sample of size n suppose mr individuals have 
the associated integer r. Then if'having the value r' is thought 
of as the event, A, a success, it is clear that 'lim' mr/n is 
Pr -- p(AO. But (�2.1) p(Ar) is the definition of the. density of 
the random variable which is this measured integer. Conse- 
quently 'lim' mr/n is the real world counterpart of the density. 
2.4] FEATURES OF DISTRIBUTIONS 81 
If the measurement, now x say, is continuous, a similar corre- 
spondence can be established by grouping the measurements. 
A measurement x is said to be grouped in intervals of width h 
if x is replaced by the nearest value in the series (e + nh) (n = O, 
+ 1, _ 2, ...): e is usually zero. Then if Ar is the event that the 
grouped value is c +rh, 'lim' mdn is p(A,) which is approxi- 
mately equal to f(c +rh)h, where f(x) is the mathematical 
density. Hence 'lim' mdnh corresponds to the density. In the 
discrete case with integers, h was one. The discussion may be 
summarized by saying that with a large n, (mdnh) is the em- 
pirical counterpart of the density. Its graph against r is a 
0 �1000 
I I 
�2000 �30OO �4000 
Fig. 2.4.1. Histogram of incomes. 
histogram. The features of mathematical distributions (or den- 
sities) defined in this section may be similarly defined for 
histograms. For example, the mean is 
Z(c+rh)mdn (= Y, rmdn if c = 0, h = 1) 
corresponding to  rp. Such a feature is called a statistic. 
A statistic is a function of the sample values (cf. �5.5). 
The mean has such attractive mathematical properties that 
within the mathematics it is almost the only measure of location 
used. But in descriptive statistics, where we are merely attempt- 
ing to describe the data, the other measures of location are often 
82 PROBABILITY VISTRIBUTIONS [2.4 
no less useful than the mean. For example, the histogramS- of 
the distribution of income in a population will often have the 
form sketched in fig. 2.4.1. The mean income will be affected by 
the few very rich people. The median income might be a better 
descriptive statistic for comparing two groups because it will not 
be so seriously influenced by the very rich. The mode of the 
income distribution has the same property and is the income- 
group of largest size in the population. Note that it will depend 
on the grouping used. A physical example that we shall meet 
later is the distribution of particle size (example 2 in �3.5). 
2.5. The simple random walk 
Consider a random sequence of trials with constant prob- 
ability, p, of success (� 1.3). Denote a success by the value + 1, 
and a failure by the value -1. Then every elementary event 
consists of an infinite sequence, {t7n} say (n = 1, 2, ...), with 
g = + 1, with the probabilities defined by p and the random- 
ness. Construct a new sequence {�.} (n = 0, 1, 2, ...) from the 
relations 
= 0, = (n 1). (1) 
Then {n} is a stochastic process and is an example of an 
additive process, or a random walk. It will be referred to here as 
the simple random walk. The random variable , is supposed to 
represent the position after n steps of a particle which pursues 
a 'walk' on the integer points of the real line, starting from the 
origin and at each step moving to either of the neighbouring 
integer points according to the outcome of the random sequence. 
Our first theorem gives the density of ,, for fixed n. 
Theorem 1. In a simple random walk p(s ] n), the probability that 
� = s, is equal to 
(n) p-l(+8)q(-s), (2) 
�(n + s) 
provided -(n + s) is an integer in the interval (0, n) ' otherwise it is 
zero. 
Let r the number of + l's, that is successes, in the first 
' Notice .nat the groups are not equal. There are relatively few people with 
large incomes, so that h is increased for large incomes to enable a sensible number 
to appear in each group. Here n = 27,000. 
2.5] THE SIMPLE RANDOM WALK 83 
n trials.. Then  will equal s iff the number of + 1's exceeds the 
number of - l's by s (s may be negative). Hence 
s=r-(n-r) =2r-n, or r =�(n+s). 
But ? has a binomial distribution B(n, p) with density given by 
equation 2.1.1, and (2) is merely equation 2.1.1 with r = �(n + s). 
Corollary. (:) = n(p-q), 2(�) = 4npq. 
From equation 2.1.9 (?) = np, and from equation 2.4.10 
2(?) __ npq. Hence by equation 2.4.1 
= (2r- n) = n = nCo-q), 
and by equation'2.4.4 
.2() = '(27-n) = 42(?) = 4npq. 
An alternative derivation of (2) is important because it illu- 
strates a method of wide applicability. This method consists in 
relating the position of a process now with the positions it could 
have just had. If , is thought of as the position now, then ,,_ 
could have been �, + 1, or ,- 1. Hence 
p(s[n) = p(s- l ln- !)p+p(s + 11n- 1)q, (3) 
from the generalized addition law (theorem 1.4.4) with the 
following correspondence between events, 
Ak: ',_ = k and B: ,=s. 
The {Ak}(k = 0, +1, +2, ...) are certainly exclusive and 
exhaustive, p(A) = p(kln- 1), and the only conditional prob- 
abilities which do not vanish are p(BIAs_ 0 and p(B[As+O of 
values p and q respectively. Equation (2) obviously satisfies 
(3) with p(010) = 1 as the boundary condition, and can easily 
be shown to be the only solution with this boundary condition. 
We are interested in the behaviour of (2) as n --> oo. To study 
this we introduce a time variable (not a random variable) and sup- 
pose the successive steps in the walk take place at time instants 
3t apart. We consider the position after fixed time t when 
n -- t/3t steps will have occurred: then if 3t -> 0, n  0% and we 
shall, in the limit, be discussing continuous time. The position 
of the walk can also be made continuous in the limit by replacing 
the steps, + 1, by steps, + 0x, and allowing 3x to tend to zero. 
84 PROBABILITY DISTRIBUTIONS [2.$ 
Our object is to pass from the difference equation (3) to a 
differential equation by means of these changes of variable. 
Now if the density (2) is to tend to a limit as n -+ c the mean 
and variance should stay finite: provided they do, we know from 
Chebychev's inequality that the probability cannot be distri- 
buted too far from the mean. Also the variance must not tend 
to zero otherwise the distribution will have no scatter and be 
useless. The mean and variance of Y;, the position in the new 
units, will be, from the corollary, on change of units, 
(�.) = t(p-q)ax/at, (�.) = 4pqt(ax)2/at. (4) 
To take care of the variance allow ax and at to tend to zero so 
that 
4pq(ax)2/at ---> o -- > 0, (5) 
and to take care of the mean subtract from each step, + ax, the 
value (p-q)ax and consider .. = �- t(p-q)ax/t, with zero 
mean. Since we are changing from a discrete to a continuous 
time variable,? replace s in (3) by x and let p(x[ t) = p(} = x). 
Then (3) becomes 
p(xlO = p(x-2qxlt-at)p+p(x+2pxlt-at)q. (6) 
(For example, if the particle is at x-2q ax at time t-at, the 
step + &�, of probability p will, when corrected by (p-q) 8x, 
take the particle to x-2qax + ax-(p-q)&� = x at time t.) 
Subtract p(x It-at) from both sides of (6) and divide by at. 
Then 
p(x[ t)-p(x[t- 
_ 2Pq(ax)  { p(x - 2q ax [ 
- at 2pq(ax)  
t-at)p-p(xl t-t)+p(x + 2p&c[ t-at)q}. 
Allow at and ax to tend to zero according to (5) and we have 
ap(a_ l t) = �o.o rO"p(x ] t) 
 , (7) 
since the part in braces is a second difference at unequal intervals. 
Equation (7) is a famous partial differential equation, known as 
? This point will be discussed more fully below, in order to avoid interrupting 
the proof. 
2.fi] THE SIMPLE RANDOM WALK 85 
the Fokker-Planck, diffusion or heat equation' -}(r 2 is called the 
diffusion coefficient. The solution to (7) with the boundary con- 
dition that the particle at t = 0 was at x = 0 is easily found by 
the usual methods, but' it is enough for us to observe that 
p(xl't) = (2rrto'2)-�exp (-x2/2o'2t) (8) 
satisfies the equation and the boundary condition as t---> 0. To 
see that it satisfies the equation it is enough to carry out the 
differentiation. The boundary condition is most easily discussed 
after we have studied (8); which we now proceed to do. 
It is easy to see that p(xlt ) satisfies the conditions (2.2.4) 
for a (continuous) density: for it is obviously positive, and 
the integral gives, on substituting z = x(to'2) -,}, the integral 
f_ e-e'dz//(2zO which is known to be unity (see below). The 
mean of the density is obviously zero since (8) is symmetric 
about zero. The variance is therefore fxp(x[ t)dx which gives 
tf � 
cr  z 2 e- ' dz//(2rr) with the same substitution. An integration 
by parts reduces the integral to the one just considered and 
hence the value is 2t. As t---> 0, therefore, the mean and vari- 
ance tend to zero and the random variable tends to be at the 
origin with probability one. This establishes the correctness of 
the boundary condition. There is no loss in generality, when' 
t > 0, in supposing t = 1. Equation (8) is said to be a normal 
(or Gaussian, or Laplacian) density and a random variable with 
that density is said to have a normal distribution with mean zero 
and variance o '2. This is written N(0, (r'). Still with t = 1 we 
can state the main result we have proved as 
Theorem 2. As n-->oo the distribution of [,-n(p-q)]/(4npq) 
tends to the normal distribution N(O, 1). 
We have shown that the distribution of [-t(p-q)Sx/St] 
tends to N(0, o'20, for fixed t, as 8t--> 0, 8x-> 0 and therefore' 
n = (t/St)-->oo. Dividing by the standard deviation o-t and 
remembering (5) and that * - ,,Sx we see that 
, 8x- t(p-q) Sx/ St 
[4tpq(x)'/at] 
tends to N(0, 1) which, with n = t/St, is the required result. 
86 
Corollary. 
tion of [?-np]/(npq)l tends to the normal distribution N(O, 
as n---> oo. 
This is immediate since  = 2?-n. 
If  is N(0, aa) then  +/ clearly has density 
(2rro'a)-lexp [- (x-/)a/2tr '] 
with mean/. This is a normal density N(/, 0-2). 
called the parameters of the normal distribution. The distribu- 
tion function is 
PROBABILITY DISTRIBUTIONS [2. 
(De Moivre' s theorem.) If? is B(n, p) then the distribu- 
1) 
(2r-r')- exp [-(y-lO'/2valdy 
(9) 
and r 2 are 
(lO) 
(11) 
which, on substituting (y-/)/tr = z, is 
. /'(z-/,)/o- ' 2 
e -* dz. 
The function (2rr)-i e-l2dz 
(12) 
(2rr)-ke-lX' by 
is usually denoted by (I)(x), and its derivative 
5(x). From (11) tI)([x-/,]/) is the distribution function of 
N(/, '). It follows that if g is NOt, tr ') then (g-/t)/tr is N(0, 1). 
A random variable which is N(0, 1) issaid to be a standardized 
normal variable. 
Examples of random walks 
The simple random walk probably first arose in games of 
chance.. Consider a sequence of plays of a game: if you win any 
play you receive 1 unit; if you lose you pay out 1 unit,. that is 
receive -1. The successive plays are presumably independent 
(unless you change strategy according to the results of earlier 
plays) with constant probability '.of winning; hence the {t7,,} 
above correspond to the receipts in the plays and  is one 
player's capital after n plays, starting from zero. The process is 
also a crude m9del for the diffusion of a particle in a fluid. This 
is the one-dimensional form in which the particle undergoes 
bombardment either from the right or left causing it to move 
one. step. Another example occurs in industrial inspection: 
2.$] THE SIMPLE RANDOM WALK 87 
mass-produced articles are randomly sampled giving rise to the 
binomial distribution (�2.1). If one is found satisfactory then 
a 'score' of + 1 is given, otherwise the score is -1. The total 
score obviously forms a simple random walk. 
The adjective 'simple' refers to the case where / is either 
plus or minus one. If the a's have a more general (common) 
distribution, and are independent, then we have a random walk 
or an additive process. The reason for the latter name is that the 
process {,} is formed by adding a random variable am, at any 
stage of the process, gn-x, to obtain the next stage . In many 
applications of random walks there exist barriers, in the sense 
that once the walk reaches one of them it ei[her stops or is 
prevented from proceeding beyond them. For example, games 
of chance may stop when either of the players become bankrupt. 
Such walks will be discussed in ��4.5 and 4.6. 
Normal approximation to the binomial 
The binomial density, or (2), is tedious to calculate and if 
tabulated requires tables of triple entry, for n, r and p (Harvard 
Computation Laboratory, 1955; Romig, 1953). It is therefore 
natural to search for approximations. We already have one in 
the- Poisson distribution (�2.3) valid as n --> co, p -> 0, but it 
would be desirable to have one for any p and large n; for 
this is when the calculation of the binomial density becomes 
tedious. De Moivre's theorem gives us such an approximation. 
We illustrate the use of this theorem by calculating the prob- 
ability of 30 or more heads in 50 tosses of a fair coin--not too 
easy a task using the binomial distribution. The number of 
heads, ?, is B(50, �) and therefore has mean 25 and standard 
deviation /(50 x � x �) = 3.54. Consequently the density of 
(?-25)/3.54 is approximately N(0, 1). Since ?  30 correspond s 
to (?-25)/3.54 > 1.41 the required probability is approximately 
I-q)(1.41), where (I)(x) is the distribution function of an 
N(0, 1) variable. Tables of (x) give the value 0.079. The ap- 
proximation can be improved in a way which is best explained 
by a figure. Fig. 2.5.1 shows the distribution function of 
(?-25)/3.54, in the neighbourhood of r = 30, plotted on the 
same scale as that of N(0, 1). The alternative scale, approxi- 
88 PROBABILITY DISTRIBUTIONS [2.$ 
mating B(50, �) by N(25, 12�), is also shown. It is clear from 
the figure that the probability of 30 or more (the distance the 
point A is below one) is more nearly approximated by taking the 
corresponding normal expression at r = 29�, rather than 30. 
We then obtain 1-(1.27) = 0.102. The exact value obtained 
from the cumbersome binomial tables is 0.1013. Sometimes the 
correction of � has to be added instead of subtracted: which is 
appropriate will be clear from a sketch. It is often called a 
continuity correction. 
0'95 
0.90 
0'85 
0.80 
I I I I 
r 28 29 30 31 
r--25 
0.85 I. 13 1.4.1 1.70 
3.54 
Fig. 2.5.1. Distribution functions for B(50, �) and the normal 
approximation N(25, 12�). 
The great merit of the approximation is that it enables a table 
of triple entry to be replaced by one of single entry. Every 
binomial distribution can be reduced in the way just exemplified 
to the normal form. (x) is not expressible in terms of elemen- 
tary functions but has to be regarded as a new function: to 
anyone. working with random phenomena it is as important as 
2.5] THe. SIMPLE RANDOM WALK 89 
the sine function is to a surveyor. The normal distribution 
occurs in many studies and is used more often than any other 
distribution. It is extensively tabulated, the most compre- 
hensive being that of the 'National Bureau of Standards (1953): 
the simpler table of Lindley and Miller (1961) will be enough 
for our needs. Since the distribution function of N(/, o.) is 
(I) [(x-t0/o.] it follows that once the standardized normal distri- 
bution is tabulated, all normal distributions are effectively 
tabulated. This is why the approximation is so useful. Since the 
table has to be entered at (x-/)/o., or in the binomial case 
(r-np)/(npq)l, the relevant value for the probability calculation 
is the number of standard deviations that x (or r) is from the 
mean. In the example, 30 is 1.41 standard deviations from the 
mean. Notice that since the normal density is symmetric about 
the mean, (I>(x) = 1- (-x). Hence (I)(x) need only be tabu- 
lated for positive argument. It is worth knowing a few values of 
� (x) just as one knows a few values of the trigonometric func- 
tions. Three useful ones are 
� (1.96) -- 0.975, (2.58) = 0.995, (3.29) -- 0.9995. (13) 
It is instructive to compare these values with the limits obtained 
by Chebychev's inequality. If  is a normal random variable 
co.) = co-) - co-) 
= 1-(c)+CI>(-c)= 2(-c). 
(14) 
With c = 1.96 this gives a probability of twice (1-0.975), i.e. 
0.05, or 1 in 20. Chebychev's inequality says that the prob- 
ability is less than (1.96) -', about 1 in 4. Thus the inequality is 
very coarse. The three numerical values quoted above are 
equivalent to saying 'the probability that a normal random 
variable departs from its mean by more than 1.96 (2.58 or 3'29) 
standard deviations is 1 in 20 (100 or 1000)'. 
Limit of the distribution function 
In the main theorem the density for a discrete distribution 
(the binomial) has been approximated by the density for a 
continuous distribution. In applications it is usually the distri. 
90 PROBABILITY DISTRIBUTIONS [2.5 
bution function that is needed (as in the numerical example just 
given) and it is therefore important to notice that theorem 2 
persists with distribution function for density. This is easily seen 
by summing (6) over all x less than some value, which shows 
that the (discrete) distribution function also satisfies (6) and 
hence, in the limit, (7). In solving (7) the boundary conditions 
are different, for at t = 0 the distribution function is zero for 
x < 0 and 1 for x > 0. The solution with this modification is 
� (x/fi), agreeing with the density. It is also easier to under- 
stand how the discrete probability distribation passes into the 
continuous one, if the distribution function replaces the density. 
The 'jumps' in the former become smaller, and because of the 
scaling (by 8x) become closer together: consequently they are 
'smoothed out' and pass to a continuous limit. Fig. 2.5.1 will 
help to clarify this. 
Diffusion with drift 
The limiting diffusion process, satisfying (7), has always zero 
mean (since (8) has zero mean). A drft of amount/x per unit 
time can be introduced on replacing x by x +/it. The usual 
methods for change of variable give 
p(x I t) p(x t) = �tr2 'p(x [ t) (15) 
t ' + tt Ox Ox  ' 
the general diffusion equation. The same change of variable 
shows that the solution is that the distribution, at time t, is 
N(ttt, 
Evaluation of an integral 
The result f5 e-ldz = /(2n), 
o 
(16) 
used above, is easily proved as follows. The double integral of 
e4("+v") over a square of side 2R with centre at the .origin and 
sides parallel to the x- and y-axes is obviously, since the inte- 
grand is positive, bounded below and above by the same 
integral over circles of radii R and /2R respectively with 
2.5] THE SIMPLE RANDOM WALK 91 
centres at the origin. On changing to polar co-ordinates the 
former integral becomes' 
since the element of area dxdy becomes r drdO. As R  ov this 
gives 
Similarly, the upper bound gives the same value; hence 
Notice that the substitution �z ' = t, gives 
 e-tt-i dt = 
previously defined (�2.3) as (-�)!. 
Central limit theorem 
An alternative form of theorem 2 is important for later 
extensions. Froin (1) it follows that  = Z gr and hence the 
theorem says that the sum of the () is, as their number 
increases, approximately normally distributed. We shall see 
later that this is true for cases where the (g,) are fairly general 
random variables and not merely ones which assume only the 
values + 1. This result is the central limit theorem (3.6.1) and is 
one of the reasons for the importance of the normal distribution. 
2.6. Generating functions 
Let {p} be the density of a non-negative, integer-valued 
random variable. The function 
oo 
n(x) = (1) 
r=0 
is called the probability generating function of the distribution 
(or density). The argument x may be complex, and (1) certainly 
t In this book multiple integrals will have the variable of integration placed 
next to the sign of integration so that no confusion arises over the range of each 
variable. 
92 PROBABILITY DISTRIBUTIONS [2.6 
converges for Ix[ < 1 since Y,p,. does, and so is at least defined 
within and on the unit circle. If the random variable can assume 
negative values the probability generating function can still be 
defined bY (1), with summation now from minus to plus infinity, 
but may only exist for Ixl = 1. In what follows we suppose it 
does exist for other values of x, and use the doubly infinite sum. 
The derivatives of II(x) at x = 0 involve the density (�r). The 
derivatives at x = 1 involve the moments (�2.4). For example, 
--/t and = [ff-1)] = v+3-3. (2) 
The second of these follows from theorem 2.4.2. The moments 
may be generated directly by putting x = e* in (1) and defining 
� (z) = Z Pe . (3) 
� (z) is called the moment generating function. If H(x) exists in 
a neighbourhood of Ix[ = 1, (z) exists in a neighbourhood of 
the real part of z = 0. We have, on expanding the exponential 
function, 
O(z) = Z }z/nl ahd (d(z)/&)o = 3. (4) 
=0 
(It will agree with the definition of 3} (equation 2.4.14) to put 
 = 1.) The more useful moments about the mean can be 
similarly obtained by using the function (z)e -*. Notice that 
= 
The moment generating function may only exist when 
z = it, t real, corresponding to Ix[ = 1, when the above results 
may beinvalid. In theoretical work, in order to avoid unneces- 
sary assumptions about the distribution, it is therefore con- 
venient to use the characteristic function defined as 
� (t) = (it), (5) 
where t is real and i = 4- 1. (t) exists for all real t. 
We shall see later (theorem 3.5.4) that (z), and therefore 
� (t), has some useful multiplicative properties. It is therefore 
convenient to introduce the function 
g(z) = *(z), (6) 
 The notation should not be co.used with that for the normal distribution 
function. 
26] GENERATING FUNCTIONS 93 
which will have a power series expansion, if ep(z) does, equal to 
1213 
K(z) = Z K.,c'./.!. (7) 
n= 1 
(Notice the n! which occurs in the expansion of (I)(z), equation 
(4), and K(z).) The {K,) are called the cuulants of the distribu- 
tion and K(z) is called the cumulant generating fnction. The 
cumulants often replace the moments in modern work: they are 
related to them by the result 
In /z 'n = xz n. 
0 =1 
In particular 
xx =,  = z, xa =/ta, r =g-3O. 
The infinite expansions in (4) and (7) are not always possible 
because the moments or cumulants may not exist. However, if 
/ (or }) exists for some n (and therefore, it is easy to see, for 
all smaller n) we may write 
00) = Z /;./j + (z), (8) 
j=0 
where R(z) is a remainder term such that R(z)/z   0 as z  0, 
which is written R(O = o(z'9. Thus (z) generates the moments 
as far as they exist. Similarly, 
K(z) = Z sz/j + '0). (9) 
j=l 
With continuous distributions the probability generating 
function is no longer used, but the definition of the moment 
generating function as (z) = (e v) applies to this case also. 
Iff(x) is a continuous density, then 
� = 
It similarly generates the moments, certainly exists when z = it, 
and gives the characteristic function and the cumulants as in the 
discrete case. 
The uses of generating functions 
Probability distributions can be described in several ways, 
through the density function or the distribution function, for 
94 PROBABILITY DISTRIBUTIONS [2.6 
example. Which way is chosen depends on the problem and the 
properties of the descriptive function. The generating functions 
are descriptions which have some particularly attractive and 
simple properties in a problem involving the sum of random 
variables; for example, the random walk in the form mentioned 
at the end of �2.5. This will be discussed in � 3.6. Furthermore, 
unlike the measures introduced in � 2.4, they describe the distri- 
bution completely; that is, given a generating function there is 
only one distribution with that as its generating function: they 
characterize the distribution. (Hence the name, characteristic 
function.) The moments do not characterize the distribution. 
We have given definitions of the generating functions in terms 
of the density function; formulae which go in the reverse way, 
from the generating function to the density (or distribution) 
function are called inversion formulae. We shall not prove that 
characteristic functions characterize the distribution, nor shall 
we give the inversion formulae, which are not often useful. It 
will be enough for our purpose to recognize the generating 
functions of the distributions we shall meet. An example is 
given after (20) below. InverSion formulae are given in more 
advanced books, for example Love (1960). In the discrete case 
the expansion of II(x) as a power series will give the density: 
but this is not available in the continuous case. 
Some readers may be familiar with generating functions under 
other names. For example, the moment generating function in 
the continuous case (equation (10)) is the two-sided Laplace 
transform off(x). The characteristic function is the two-sided 
Fourier transform. If the random variables are positive the 
transforms are one-sided. It might appear that much use could 
be made of the extensive theory of Laplace and Fourier trans- 
forms, but often the particular property off(x) of being non- 
negative makes the transforms more special than they are in the 
general theory, and therefore they have extra properties not 
always discussed in the literature on transforms. 
Example 1. The Poisson distribution. The probability gene- 
rating function i� 
II(x) = Z e-/rxr/r! = exp[/z(x- 1)] (11) 
'0 
2.6] GENERATING FUNCTIONS 95 
which exists for all x. The derivative at x = 1 is clearly p, the 
mean, agreeing with (2). The moment generating function is 
obtained by putting x = e * in (11), and is 
�(z) = exp [p(e - 1)]. (12) 
About the mean the function is cI)(z)e- = exp [p(e *- 1-z)]. 
The expansion of this begins 1 +pz2/2! + ... so that the vari- 
ance p. --- o -2 is p. Finally K(z) = p(e  - 1) so that all the cumu- 
lants of the Poisson distribution are equal to p. 
Example 2. The normal distribution. The density is given by 
equation (2.5.9), so that the moment generating function is 
rb(z) = (2rro'2)- exp [zx-(x-p)�2rr]dx 
= (2ro'') - exp [- {(x-p- z') ' 
_ 2z/2- 
on completing the square in x. The integral is reduced to the 
usual form (2.5.16) by the substitution x-p-z = t, so that 
cI)(z) = exp [zp +�z'r]. (13) 
The derivative at the origin is p, which is already known to be 
the mean, so that the moment generating function about the 
mean is 
q)(z)e-,  = exp [�z2rr2], (14) 
from which it follows that 
2(2r)! 
?.r+=O and p2r= 2rr! 
= (2r- 1) (2r- 3) ... 3rr . (15) 
The cumulant generating function is zp + �z2o ' so that tq = p, 
c 2 = 0 -2 and all the higher cumulants are zero. 
Example 3. The Poisson process. (This example also serves as 
another illustration of the important probability technique 
used to derive equation 2.5.3.) The notation is that of �2.3. We 
derive an equation for p,(t) by relating the number of incidents 
up to time t, thought of as 'now', with the number up to a.point 
just in the 'past', namely at t-Jt. We saw that the Poisson 
9J PROBABILITY DISTRIBUTIONS [2.6 
process could be formulated by saying that the probability of 
one incident in an interval (t-t, t) is ,t, and of two or more 
is small in comparison with t, independent of the behaviour of 
the process prior to t-t. Consequently there can only be n 
incidents up to t if either there were n up to t- t and none took 
place in (t- $t, t) (the latter event has probability 1 --,tt), or if 
there were (n-1) up to t-t and one occurred in (t-t, t) (of 
probability lt). Hence by the generalized addition law 
(theorem 1.4.4), provided n > 0 and terms of smaller order than 
t are neglected, 
p,,(t) = �,_x(t-&) pin incidents in (0, t) (n- 1) incidents in 
(0, t- *t)] 
+p,(t-St)p[n incidents in (0, t)[n incidents in 
(0, t- 
= p,,_x(t-St) ASt +p,,(t-St)[1 -,St]. (16) 
The reader should make sure he has understood the argument 
used in deriving (16), since it will be used again (�4.1), and the 
use of the independence condition in the derivation. Equa- 
tion (16) may be rewritten 
[p(t)-p(t- t)]/& -- A[p_x(t- t)-p(t- &)], 
which, on allowing & to tend to zero, gives 
dp,(t)/dt-- A[p,_x(t)-p(t)]. 
(17) 
This is a differential-difference equation for p,,(t): that is, it 
involves differentials with respect to t and differences with 
respect to n. The boundary conditions are p0(0) = 1, p,(0) = 0 
for n > 0. Equation (16), and hence (17), also holds for n = 0 
provided P-(O is put equal to zero. The equations can be solved 
in succession starting with n -- O; instead we shall solve them 
more simply using probability generating functions. Let 
II(x, t) = Y, p,(t)x ', (18) 
,0 
the probability generating function for the number of incidents 
in (0, t). Multiply (17) by x'* and sum the two sides over n. The 
result is 
cqH(x, t)/Ot = A(x- 1) H(x, t). (19) 
2.6] GENERATING FUNCTIONS 97 
As there are no differentials with respect to x in the equation, 
x may be regarded as constant; t is the variable and the equation 
is an ordinary (and not a partial) differential equation. We 
easily have dII/II = A(x- 1)dr, 
so that lnII(x, t) = A(x- 1)t +f(x), 
where f(x) is an arbitrary function. The boundary condition at 
t = 0 gives II(x, O) = 1 so thatf(x) = 0 and 
II(x, t) = exp [At(x- 1)]. (20) 
A comparison of (20) with (11) and the fact that the probability 
generating function characterizes the distribution shows that 
{p,,(t)} must be a Poisson distribution with parameter At. This is 
theorem 2.3.3 again. 
Suggestions for further reading 
The two books on the calculus of probabilities mentioned in the 
suggestions in chapter 1 by Feller (1957) and Gnedenko (1962) 
cover material closely related to that of this chapter and the two 
succeeding. The Poisson process is discussed by Khintchine 
(1960), and in the introductory book on probability by Parzen 
(1962). A more advanced book on probability is Love (1960). 
A branch of the subject, not discussed here, is geometrical 
probability; see Kendall and Moran (1963). 
Exercises 
1. In an investigation of animal behaviour, rats have to choose between 
four similar doors, one of which is 'correct'. Correct choice is rewarded 
by food and incorrect choice is punished by an electric shock. If an 
incorrect choice is made, the rat is returned to the starting-point and 
chooses again, this continuing until the correct response is made. The 
random variable, X, is the serial number of the trial on which the correct 
response is first made, X thus taking values 1, 2, .... 
Find the distribution and mean of X under the following different 
hypotheses: 
(i) each door is equally likely to be chosen on each trial, and all trials 
are mutually independent; 
(ii) at each trial, the rat chooses with equal probability between the 
doors that have not so far been tried, no choice cvcr being repeated; 
(iii) the rat never chooses the same door on two successive trials, but 
otherwise chooses at random with equal probabilities. (Lond. B.Sc.) 
98 PROBABILITY DISTRIBUTIONS 
2. In inspecting an industrial process, a gamp'le of material is examined 
every hour and classified as 'satisfactory' (S), 'doubtful' (D), or 'unsatis- 
factory' (U). If $ is observed, no further action is taken. If U is observed, 
corrective action is taken. If D is observed, an additional sample is taken 
at once and additional sampling continued until either S or U is obtained, 
when the appropriate action is taken. The probabilities of S, D, U are 
a, fl, 7 respectively (a+f+ 7 = 1), independently for each sample. 
Prove that the probability that corrective action is taken at a particular 
test period is T/(1 -fl). 
Derive the distribution and mean of the number of times corrective 
action is taken in n inspection periods, , fl, 7 remaining constant. 
(Lond. B.Sc.) 
3. In the game of'Craps' (cx. 29 of chapter 1) find the expected number 
of throws in a single play. 
4. A bag contains a very large number of balls of which a proportion p 
is red and a proportion q = 1-p is white. In a psychological test the 
balls are drawn at random one at a time from the bag and after the first ball 
has been drawn a subject, who does not know the value of p, is asked to 
guess the colour of the second ball; when he has made his guess and the 
second ball has been taken from the bag and shown to the subject, he is 
asked to guess the colour of the third ball, and so on. Show that if the 
subject always guesses the same colour as the previous ball, the probability 
of any guess being correct is p+q'; and that the same probability, given 
that the previous guess was correct, is (pa+qa)/(p2+qa). Show that the 
latter exceeds the former and hence that the number of correct guesses is 
not binomially distributed. Can you suggest a better rule for making his 
guesses, independent of any knowledge ofp ? 
5. The spores of a certain plant are arranged in sets of four in a linear 
chain (with three links). When the spores are projected from the plant, 
each link has a probability 0 of breaking, independently for each link. 
For example, if all links break, four 'groups' each of one spore are 
obtained, whereas if no links break a single ' group' of four spores results. 
Prove that the expected number of' groups'.per set is 1 + 30. 
A large number of 'groups' is collected. Show .that the proportions 
of 'groups' having 1, 2, 3 and 4 spores are respectively 
20(1+0) 0(1-0) (2+0) 20(1-0)  and 
+30 ' +30 ' +30 ' 
(1 - 0) a 
1+30 ' 
(Lond. B.Sc.) 
6. A game between two players, A and B, consists in them playing alter- 
nately a machine until one of them scores a success on it. The first to score 
a success wins. Their probabilities of success on each play of the machine 
are respectively p and p.. Since B is a better player than ,4 (p > p) he 
allows A to have the first turn. All plays of the machine are independent. 
EXERCISES 99 
Show that the game is fair, iff 
p = p/(l 
Show that when ,4 wins, the average number of plays he takes in which 
to win is 
(p + p-pxp2) -. (Wales Maths.) 
7. A timber merchant knows from previous experience that, on average, 
20 % of the consignments of timber received by him come from plantations 
affected by disease, and 80 % from disease-free plantations. On average 
15 % of the logs in consignments from diseased plantations have some 
defect, compared with 5 % of logs from disease-free plantations. Logs are 
selected at random from a consignment and examined. The sampling 
continues until the first log with a defect is selected, when the number of 
defect-free logs sampled is noted. If the number of defect-free logs in the 
sample is 7, what is the probability that the consignment came from a 
diseased plantation ? (Aberdeen Dip.) 
8. It is assumed that the chance of a male birth is constantly equal to a 
known constant p and that the sex of any child is independent of that of 
any other child. A family is known to Contain just r males. What are the 
posterior probabilities and means of the size, n, of this family if the distri- 
bution of family size in the population is: 
2 n 
(i) p(n) =  e - (n = 0, 1, 2, ...); 
(ii) p(n) = 1/2 n+ (n = 0, 1, 2, ...)? 
(Lond. Dip.) 
In a batch of N manufactured items, there are R defectives and N- R 
e 
non-defectives. Show that the distribution of ?, the number of defectives 
in a random sample of n items from the batch, is given by the hyper- 
geometric probability density function 
If R itself is a binomial random variable , with parameter p and 
index N, use Bayes's theorem to show that, given P = r, the distribution 
of -r is independent of r. 
10. A lake contains an unknown number N of fish. A sample of n fish is 
drawn from it and each specimen is marked without injuring it and 
replaced while still alive. A month later a second sample of k fish is drawn 
from the lake and is found to include exactly m marked specimens. Show 
that on the assumptions that the fish have become completely mixed and 
that none has died, entered or left the lake, or has been born during the 
interval, the probability of obtaining this result is given by 
N- 
P = (k-m) () / (N) . 
100 PROBABILITY DISTRIBUTIONS 
The size of the population is cstimatcd' by choosing that value of N 
which makespry as great as possible. By considering the ratio uv = 
or otherwise, show that the estimated number is approximately nk/m. 
11. An urn contains n balls, each a different colour. Let r be any integer. 
Show that the probability that a sample of size r, drawn with replacement, 
will contain r balls of colour 1, r. balls of colour 2, ..., r, balls of colour 
(where r + r. +... + r = r) is given by 
1 r! 
n r ri! r! ... r,!' 
12. A radioactive source, emitting a-particles in random directions (all 
equally likely) is held at unit distance from an infinite plane photographic 
plate. If an a-particle can be stopped by the plate only, what is the distribu- 
tion of 1Ix where x is the distance of the 15oint of impact of a particle from 
the point of the plate nearest the source ? 
13. A patient with a needle 5 cm long in his chest is X-rayed. If the 
orientation of the needle is quite random, what is the distribution function 
of the length of the needle's shadow? What are the mean and variance 
of the shadow length if the needle has a uniform distribution of length 
between 3 and 7 cm ? (A uniform distribution in (a, b) has constant density 
(b-a) -1 in that interval.) 
14. From a point on the circumference of a circle of radius a, a chord is 
drawn in a random direction (i.e. all directions are equally likely). Show 
that the mean of the length of the chord is 4a/r, and that the variance 
of the length is 2a2(1- 8/r). Also, show that the chance is 1/3 that 
the length of the chord will exceed the length of the side of an equilateral 
triangle inscribed in the circle. 
If the chord is drawn parallel to a given straight line, all distances from 
th e centre of the circle being equally likely, show that the mean length of 
chord is �rra and that the variance is a0(32 - 3rr)/12. Also show that the 
chance is now 1/2 that the length will exceed the side of the equilateral 
triangle. 
15. A point P is taken at random in a line AB, of length 2a, all positions 
of the point being equally likely. Show that the mean value of the area of 
the rectangle ,aIP.PB is 2a/3 and that the probability of the area exceeding 
�a ' is l/d2. 
16. Suppose the duration, t, in minutes of long-distance telephone calls 
made from a certain city is found to have a distribution function 
F(t)=0 for t<0 
= 1-Ze--�e-l for t> 0. 
([�t] is the integral part of �t.) 
(i) Sketch the distribution function. 
' Notice that this is an inference problem. Estimation will be formally 
discussed in ��5.2 and 7.1. 
EXERCiSeS 101 
(ii) IS the random variable ! continuous, discrete, neither ? 
(iii) What is the probability that the duration in minutes of a long- 
distance call will be (a) more than 6, (b) less than 4, (c) equal to 3, (d) be- 
tween 4 and 7? 
(iv) What is the conditional probability that the duration of a call will 
be less than 9 minutes, given that it has lasted more than 5 minutes? 
17. The probability density of the velocity, v, of a molecule with mass tn 
in a gas at absolute temperature T is 
g(v) = xvae -t', for v > 0, 
=0, for v<0 
(Maxwell-Boltzmann law): where fl = m/2kT, k is Boltzmann's constant 
and ct is a constant so chosen that 
f  g(v)dv = 1. 
Find the mean and variance of v, and also the mean and variance of the 
kinetic energy E = �my '. Show that the mean and variance of E/(�kT) 
are those of a I'(-, �) variable. 
18. Certain metal bars are such that the probability of a flaw in any section 
of length 8x is, for sufficiently small 8x, equal to ASx, the probabilities 
associated with different sections being 'independent. Prove that the 
probability that a rod of length l is without a flaw is e -At. 
If a rod has no flaw its strength is $x and if it contains one or more flaws 
its strength is Sa, where &, S. are constants such that St > Sa. Find the 
mean and standard deviation of the strength of rods of length I. 
(Camb. N.S.) 
19. The phase 0 of a source of sound of strength A is a random variable 
distributed uniformly in probability over the interval 0 to 2rr. If the effect 
as heard is x = A cos 0, find the mean and variance of the distribution of x. 
(Camb. N.S.) 
20. If In x is normally distributed with mean/z and standard deviation o', 
prove that the mean of x is exp +�o-]. (Camb. N.S.) 
21. A component has a failure-time X, which is a random variable 
continuously distributed with (x) = prob (X > x). The function e(x) is 
defined as the expected future life of a component given to be of age x and 
not to have failed, i.e. e(x) = $(X- x [ X > x). 
Prove that 
e(x) - ,(x) 
Show that if the probability density function of X is e - (x > 0), then 
e(x) = 1, whereas if the probability density function is xe -x (x > 0), then 
e(x) is a decreasing function of x. (Lond. B.Sc.) 
102 
PROBABILITY DISTRIBUTIONS 
22. Construct a realization of a Poisson process in the following way:' 
let 3. = 1 and, from tables of random sampling numbers and natural 
logarithms, obtain a random sample (tx, t, ..., t,) from the probability 
density e-t: let the time between the rth and (r+ 1)st incident be t,+x. 
Divide the time scale into equal non-overlapping intervals of length 2 and 
compare the empirical distribution of the number of incidents in these 
intervals with the Poisson distribution of mean 2. Compare also the 
empirical distribution of the intervals between every other incident with 
the density t e -. 
23. In a Poisson process, exactly one incident is known to have occurred 
in a fixed interval. Show that the incident is equally likely to have occurred 
anywhere in the interval. 
24. A Geiger counter records the arrival of e-particles (each arrival an 
incident). The particles arrive in a Poisson process of rate g. and if the 
particle finds the counter 'alive' it is recorded, a process which takes the 
machine time s, a random variable with density /e -us. During this 
recording time the counter is 'dead'. A particle which arrives and finds 
the counter 'dead' is completely ignored by it. Find the expected interval 
between successive recorded arrivals. What proportion of particles will not 
be recorded by the process ? 
25. In the presence of a steady stream of radiation of z-particles the 
probability that just n particles will hit the sensitive part of a Geiger 
counter in a time interval of length t is 
e-at(At),,/n!, 
where  is a constant. 
After a particle has hit and been recorded by the counter, the counter 
has a dead period of length e during which no impacts are recorded and 
any impact does not extend the dead time. Show that the probability that 
fewer than n particles will be recorded in an interval of length T is 
' f t-e-tdt (T > (n- 1)e). 
(n- 1)! 
(Camb. N.S.) 
26. Ten test-tubes of nutrient material are each inoculated with 1 c.c. of 
a liquid containing an average of three bacteria per c.c. Under reasonable 
assumptions, which should be clearly stated, find the probability .that 
exactly seven test-tubes will show bacterial growth. (Camb. N.S.) 
27. Mice are injected with micro-organisms, each mouse being given 
a dose consisting of equal proportions of two variants A, B. It may be 
assumed that the numbers-of effective organisms of the two v'ariants per 
dose vary independently in Poisson distributions of mean/. The mouse 
This method is explained in detail in � 3.5. 
EXERCISES 103 
will survive if and only if there are no effective organisms in the dose. Dead 
mice are examined to find whether they contain organisms of one or both 
variants. Prove that the probability that a dead mouse contains organisms 
of only one variant is 2 
1 +e" 
[It may be assumed that effective organisms present in the dose will be 
detected on analysis of the dead mouse.] (Lond. B.Sc.) 
28. A plant whose constitution is known to be either A or B is tested by 
raising n offspring from its seeds. If the constitution is A then each off- 
spring has a chance 1/4 of being white and 3/4 of being coloured, but if the 
constitution is B each offspring has an equal chance 1/2 of being white or 
coloured. Write down the probability x of exactly r offspring being white 
when the plant is A, and the probability fl of exactly r offspring being 
white'when the plant is B. The plant is assigned to the class A if  > fl, 
and to the class B if  < fl. Show that this procedure is the same as classify- 
ing the plants on the basis of the sign of the expression (r-kn) where 
ln2 
k--I-- 
In3' 
Show that if 48 offspring are raised a plant which is truly of the constitu- 
tion A will be classified as B if it produces 18 or more white offspring. 
Assuming the normal approximation to the binomial distribution to hold 
for this case, show that the probability of misclassification of A plants is 
about 2� %. (Camb. N.S.) 
29. Use the normal approximation to the binomial to obtain approxima- 
tions to (the values in brackets are the exact values to 5 decimals): 
(a) The probability of 7 or fewer heads in 10 tosses of a fair coin 
(0.94531); 
(b) the probability of fewer than 45 heads in 100 tosses of a fair coin. 
(0.13563); 
(c) the probability of more than 16 plants of genotype aa in a breeding 
programme involving 52 plants when each plant has independently the 
same chance, 1/4, of being genotype aa (0.13220); 
(d) the probability of exactly 16 plants in the situation described in (c) 
(0.07669). 
30. For the exponential'distribution with density ,e -a, x > 0, A > 0, 
compare the exact probability that a random variable with that distri- 
bution departs by more than c (> 1) standard deviations from its mean, 
with the bound c -2 given by Chebychev's inequality. Determine also the 
multiple of the standard deviation that needs to replace c to make the 
exact probability c -. 
Is there a distribution for which Chebychev's inequality becomes an 
equality? 
104 PROBABILITY DISTRIBUTIONS 
31. At each turn of a game consisting of n independent turns, the prob- 
ability that a player scores one point is p and the probability that he scores 
no point is q = 1 -p. Show that the average value of the amount by which 
the player's total score in a game differs from np is 
where f= Z prq,-r 
and s is the least integer greater than np. (Camb. Trip.) 
32. Loaves produced at a bakery have weights normally distributed with 
mean/x and standard deviation % where/ may be set at any desired value 
by adjusting the machinery, but o' is fixed. All loaves lighter than a certain 
minimum weight, m, are rejected and the remainder sold. Find the ratio, 
R, of the number of loaves produced for sale from. a large quantity of 
dough to the number that would have been produced had each loaf 
weighed exactly m. 
If cr/m = k show that the value of/ that maximizes R is m+ 3,% where 3. 
satisfies the equation 
1 
d(2r) exp { - �3.2[(A)] - - k(l + Ak) -) = 0. 
Prove that when k is small, , is approximately [-ln(2nka)]L 
(Camb. N.S.) 
33. In a one-dimensional random walk problem, an insect is assumed in 
every second to move in one direction, called 'forward', with probability 
p, or to remain at rest with probability P2, or to move in the opposite direc- 
tion with probability Pa. Movements in different seconds are supposed 
independent. In n seconds it moves forward r times, remains at rest ra 
times and moves back ra times. Prove by induction or otherwise that 
n! 
P(r. r:, r) = r! ra! ra! a 3' 
The total advance in position in n seconds is denoted by r (r - r:- ra); 
find the mean and variance of r. 
If n is large obtain limits within which r will lie with 95 % probability; 
if you assume normality for any quantity indicate why you expect this 
assumption to be justified. (Camb. N.S.) 
34. Compare the normal approximation, with and without a continuity 
correction, with the exact probability that there are more than six correct 
answers to ten true-false questions, under the hypothesis that each answer 
has a chance of 1/2 of being correct, independently for the different 
questions. (Lond. B.Sc.) 
35. It is desired that a certain job shall be completed at time to. If it is not 
completed until time t (t > to), there is a loss to the producer of amount 
cx(t- to), where cx is a positive constant. If the job is completed before to, at 
xcsEs 105 
time t (t < to), there is a loss c2(to- t) arising from storage costs, where c 
is another positive constant. Suppose that the actual time of completion is 
normally distributed with mean to + A and unit variance. Find the mean 
loss as a function of/x. (Lond. B.Sc.) 
36. Find the probability, moment and cumulant generating functions for 
a variable which is G(q). 
37. Find the probability, moment and cumulant generating functions for 
a variable which is B(n, p). Show that 
,u,. =  + q)n. 
38. Prove that the moment generating function of a variable distributed 
as F(n, A) is (1- z/)-" for z < . 
39. In a sequence of n random trials with constant probability p of 
success let u, be the probability of an even number of successes. Prove the 
recurrence formula 
u. = qu._ +p(1 - u._0 (n = 1, 2, ...), 
with u0 taken to be 1. Deduce that 
1 -qz 
= (1 - z) [1 - (q-p)z]' 
where A(z) = Z u, 
8=0 
and hence find an explicit formula for u,. 
40. Under a newly proposed motor insurance policy, the premium is 
in the first year. If no claim is made in the first year, the premium is Aa in 
the second year where 0 < A < 1 and A is fixed. If no cla is made in the 
first or second years, the premium is Aa in the third year; and; in general, 
if no cla is made in any of the first r years (r  1), the premium is 
in the (r+ 1)st year. 
If in any year a claim is made, the premium in that year is unaffected but 
the next year's premium reverts to , and this year is then treated as if it 
were the first year of the insurance for the purpose of calculating further 
reductions. Assuming that the probability that no claim will arise in any 
year is constant and equal to q, prove that in the nth year (n  2) of the 
policy, the probabilities that the preum paid is 
A"- or "--a (1  j  n-l) 
are q"- and (1 -q) q"-- respectively. 
Hence calculate the expected amount of the premium payable in the nth 
year and show that if this mean must always exceed ka (k > 0), then 
k +q- 1 (Leicester.) 
 > kq ' 
41. A continuous random variable x has the probability density function 
proportional to e-(1 + x) 2 in the rang - 1  x < m, and zero otherwise. 
106 PROBABILITY DISTRIBUTIONS 
Derive the cumulant generating function of x and hence show that Vx and 
y., the coefficients of skewness and kurtosis for the distribution, are 2//3 
and 2 respectively. 
Also show that , the median of the distribution, satisfies the relation 
e ('+) = 1 + (rh + 2) 2. 
[tl = Ka/KI, 'll = K�/K.] (Leicester.) 
42. A ceramic part for an electrical unit is manufactured to order, and as 
a concession to the manufacturer, the customer ordering N items is 
prepared to accept at the same price up to aN items, where c is a given 
constant > 1. However, the manufacturer must supply at least the number 
ordered. Because of production hazards, thenumberofitemsSofapproved 
saleable quality is a fraction x (0 < x < 1) of the initial number I put into 
moulds. On the basis of past experience of the production process, it can 
be assumed that x is approximately distributed in the form with probability 
density 
f(x) = 495x6(1-x) 2 for 0< x< 1. 
If, in general, the initial number I is equal to mN (m > a), determine as 
a function of m and z the probability that: (i) the number of saleable 
items $ will be < N; and (ii) the number of saleable items will be > aN. 
Hence show that the equation for m in the special case in which the 
manufacturer desires 'his risk of not meeting the minimum demand to the 
full to be half his risk of exceeding the maximum number of saleable 
items is 
m n = 55m2(2 + ate) - 99(2 + x �) m + 45(2 + 
(Leicester.) 
107 
3 
PROBABILITY DISTRIBUTIONS-- 
SEVERAL VARIABLES 
The ideas of the last chapter are generalized to the case where an 
observation consists of two real numbers, and then to the case of 
more than two. 
3.1. The discrete case 
Associated with each elementary event a in the sample space 
is a pair of integers; As is the set of a for which the associated 
pair is (r, s) and ps = p(A). 
p, > 0, 
Clearly 
52 p = 1. 
(1) 
A sequence satisfying (1) is said to be a bivariate (probability) 
density and the joint density of the random variables ? and g. 
The random variables are said to have a joint distribution. The 
corresponding joint distribution function is 
= Z 52 p,j. (2) 
i <r 
As with one variable this definition may usefully be extended to 
define F(x, y) = p(?  x, g < y) for all real x and y: clearly 
F(x, y) = P8, where r and s are the integral parts of x and y 
respectively. F(x, y) has possible discontinuities along the lines 
x = r, y = s for integer r and s. 
The relations between the joint density of ? and g and the 
densities of ? and of g are easily found. Let Ar be the set of a for 
which the first member of the pair has the value r' then 
A = 5; A8 (cf. � 1.2 for the notation), and the events on the 
8 
right-hand side are exclusive. Hence the density of ? is 
p(AO = 52 p(Ar,) = X P8 = P., say. (3) 
$ 8 
108 PROBABILITY DISTRIBUTIONS [3.1 
(We shall often have occasion to use a 'dot' as a suffix' it 
replaces a suffix, here s, over which summation has taken place.) 
Similarly, the density of g is 
51 Pt8 -- P. 8. (4) 
The distributions corresponding to (3) and (4) are often called 
the marginal distributions of the joint distribution. 
Consider the conditional probability p(Ar8 I AO for fixed r and 
all s. If p 4= 0 it equals (theorem 1.4.2) p(A)/p(AO = Ps/Pr. 
which we write p(slr). Clearly 
p(slr) O, 52p(s]r)= 1, (5) 
8 
so satisfying the conditions (equation 2.1.2) for a density' it is 
called the density of the random variable g when the other 
random variable, ?, has the value r, or shortly, the conditional 
density of g for F = r. Similarly, p(rls ) = p,./p.s is the condi- 
tional density of ? for g = s. The notation p(s[r) is an obvious 
extension of earlier notation. 
The random variables ? and g are independent if, for all r, s, 
�, = pt. p.. A necessary and sufficient condition for indepen- 
dence is that p8 be the product of a function of r and a function 
of s. For if p8 = fg, summation over s, possible since {p} 
forms a convergent series, gives p. = f,.g, where g = 7E g,, and 
8 
over r gives p. = fg, where f = ;f. But summation over 
both r and s shows thatfg = 1 whence, eliminatingf and g, we 
have Ps = P.P.. The converse is immediate. 
The mean of the conditional density (5) is 
51 sp(s l r) = g(gl r), (6) 
8 
say, and is called the conditional expectation of g for ? = r. It' is 
also called the regression of g on ?. Notice that it is a function 
of r. Similarly, 
o(? s) = 51 rp(rls). 
The expectation of g has already been defined in �2.1 as Y, sp.  
3.1] TE DISCRETE CASE 109 
and may be written in terms of the joint density as 5;sprs. 
Generally iff(r,s) is any function of r and s the expectation of 
f(?, g) is defined as 
[f(e,g)] = Zf(r,s)prs, 
provided the 
expectation 
t',8 
double series is absolutely 
= 
is called the covariance of ? and g. The ratio 
convergent. 
(7) 
The 
= p(r, s) (9) 
is called the correlation coefficient between ? and g, or simply the 
correlation of ? and g. The symmetric matrix 
2(?) c(?, g)] (10) 
s) 2(s) / 
is called the variance-covariance, or dispersion, matrix of ? and g. 
The joint probability generating function of ? and g is defined as 
11(x,y) = Y,psxry 8, (11) 
an obvious generalization of equation 2.6.1, using a double 
series and two variables, x and y. The other definitions of {}2.6 
similarly generalize; thus the characteristic function is obtained 
from (11) by putting x = e it, y = e% t and u real, giving 
F(t, u) = 2 pse i(e+uS) = (ei(t+u)). (12) 
Several random variables 
The definitions introduced in this section are all straight- 
forward generalizations of definitions for a single random vari- 
able given in chapter 2. In most practical situations the observa- 
tion made on the experimental material is not a single number 
but a set of numbers. If we consider the sample space in its full 
complexity as containing a complete description of the experi- 
mental material (�1.2), then each possible result, each elemen- 
tary event, has, as part of its description, the actual observations 
made: thus with each a are associated the numbers called 
random variables. For example, in an investigation into mildew 
110 PROBABILITY DISTRIBUTIONS [3.1 
on apple trees, counts were made of the number of affected 
shoots at bud-burst and at three later occasions during the year. 
Each of these counts is a random variable in the sense discussed 
in the last chapter. The discussion there applied to each count 
separately, but the point of the four counts was to assess the 
relationships between them; for example, was a hig.h count later 
in the year associated with a high count at bud-burst? If so 
the infection was local, f not it probably came from a distance. 
The definitions of this section are designed to provide the 
language in which such questions can be answered. 
The trinomial distribution 
As an example of a discrete random variable we used the 
number of times an event occurs in a random sequence of n trials 
with constant probability of success and obtained the binomial 
distribution (�2.1). Consider, under the same conditions, two 
exclusive events, A and B, with probabilities p and q respectively. 
Let C denote the event, neither A nor B, with probability 
1 -p-q. A, B and C are exclusive and exhaustive. If A and B 
occur r and s times in the n trials, so that C necessarily occurs 
(n- r-s) times, an argument parallel to that in �2.1 shows that 
n! 
P,s = r!s!(n-r-s)! pqs(1 _p_q),--s (13) 
for non-negative integers r, s with r + s  n. This is the density 
of the trinomial distribution: generally, for several exclusive 
events, we have the multinomial distribution. Ps is the coefficient 
of xry  in the expansion of (px + qy + 1 -p-q)'. It is easy to 
verify that Pt. (equation (3)), is B(n, p) and p. (equation (4)), is 
B(n, q). 
Conditional distributions 
The densities of ? and g separately (equations (3) and (4)), can 
be derived from the joint density of ? and g, but the converse is 
not true in general. The reason for this is that the joint density 
expresses how ? and g influence each other, which the separate 
densities cannot. This influence is most completely expressed 
through the conditional densities p(r Is) and p(s[r). In the apple 
3.1] Ta� rISCR.T. �AS� 111 
rnildew example just mentioned, it would be natural to consider 
the distribution of infection later in the year for those trees with 
little or no infection at bud-burst and compare it with the distri- 
bution for those trees which had been heavily infected then. If 
? and g are the counts at bud-burst and later respectively, the 
required distributions are of g for different, fixed values of ?. 
This is the conditional distribution of g for fixed ?, defined by 
the density p(slr). Since Prs = pr.p(s[r) it follows that the 
density of ? and the conditional densities of g for each value of ? 
are together equivalent to the joint density. Hence the condi- 
tional densities characterize the relationship between the two 
variables. The.same is true with ? and g interchanged, for equally 
P,.s = p. sp(r[s), but in most applications one way is more 
natural than another: for example, it would be unnatural to 
consider the distribution of infection at bud-burst for trees with 
high infection later in the year; earlier events influence later ones, 
not the other way round. 
An important special case is where the conditional distribution 
p(slr ) is the same for all r; for example, where the infection 
later in the year is not influenced by that at bud-burst. We may 
then write p(slr)= q, say, so that ps = p.q; which, when 
summed over r, gives p., = q, since Yp = 1. Hence if P(slr ) 
is the same for all r, Ps = Pt. P. , and conversely. This is a sym- 
metrical relation so p(r [ s) must be the same for all s, and we say 
that the random variables are independent (compare the motiva- 
tion for the definition of independent events, � 1.3). An important 
special case of independent random variables arises when we 
take a random sample of size 2 from a population (� 1.3). If ? is 
the measurement on the first and g on the second member of the 
sample then, because of the way the samples have been taken, 
? and g will, for an infinite population, be independent (see � 5.1). 
In the trinomial example we have, since ? is B(n, p), 
P(slr) = r!s(n r s) pqs(1-p-q)'*--* _p)n- 
. - _ . r!(n-r)! p(1 
04) 
112 PROBABILITY DISTRIBUTIONS [3.1 
which is B(n-r, q/(1 -�)). This is otherwise obvious since with 
r fixed only the n-r events in which ,4 does not occur are 
considered and p(B[,)= p(B)/p(,)= q/(1-p). The density 
certainly does depend on r so that ? and  in the trinomial 
distribution are not independent. 
Regression 
When a joint distribution has been expressed by means of a 
distribution of one variable and a set of conditional distributions, 
the features (�2.4) of these separate distributions can be used to 
describe the joint behaviour. The mean of the conditional 
density is by far the most important (equation (6)). The term 
regression was introduced by Francis Gaiton in connexion with 
heights of fathers (?) and sons (g): it was empirically found in 
that situation that if r > o(?) then (gl r) < r, or fathers of 
above (below) average height have on the average sons shorter 
(taller) than themselves, or the heights regress towards the com- 
mon mean (?) = (g). It is important to notice that (gl r) is 
a number which is a function of r: hence with each elementary 
event is associated r and hence a number ([ r), so that the con- 
ditional expectation is a random variable. In particular we may 
take its expectation, 
[(gl?)] = Y (glr)p. = Z [Zsp(slr)]p. 
= E E Spas = 
(15) 
Manipulations like this are often useful in determining an expec- 
tation in stages and are analogous to applications of the general- 
ized addition law for probabilities (theorem 1.4.4). For example, 
by (15), with ?g replacing , 
o(?g) = o[o(?l?)] = o[?(gl?)] (16) 
since, in the conditional expectation within square brackets, ? is 
a constant and equation 2.4.1 applies. If o(gJr) = a +fir for 
constants a and fi, the regression is said to be linear and fi is the 
' Here is an example where the distinction between ? and r is necessary. 
'(gJr), meaning the expectation of g when ? = r, becomes '(gJ?) in (15), the 
expectation of g as a function of a, through ?. 
3.1] THE DISCRETE CASE 113 
(linear) regression coefficient of g on ?. The variances of the con- 
ditional distributions are often used, 
(glr) = [(g-(glr)}lrl . (17) 
If(gl r) is constant for all r, a particularly important case, the 
conditional densities are said to be homoscedastic; otherwise 
they are heteroscedastic. 
A useful generalization of linear regression is to the case 
where the conditional expectation of g for fixed r is a polynomial 
in r of specified degree. The coefficient of r s is the quadratic 
regression coefficient, etc. This case is discussed in {}8.6(c). 
In the trinomial case (g Jr) follows easily, since the conditional 
densities are binomial, and is (n-r)q/(1-p). The regression is 
linear and the regression coefficient is -q/(1 -p). The densities 
are heteroscedastic since is (n-r)q(1-p-q)/(1-p) a, 
depending on r. 
Correlation 
The conditional densities, and in particular the regressions, 
usually provide the most useful way of describing the relations 
between two random variables but there are situations in which 
it is not desirable to have a description which is unsymmetric in 
the two variables. For example, in education it is not usually 
more natural to consider the regression of English marks on 
Arithmetic marks than of Arithmetic on English. In such 
circumstances a feature which is symmetric in the variables and 
describes their joint behaviour would be wanted. The covariance 
satisfies these requirements. If ? and g are independent the 
covariance (equation (8)) is zero, for then Prs = Pt. P.s and 
(?, g) = Z (r-g(rD)Pr. Z {s-g(g))p., = 0 (18) 
since each sum separately is zero. On the other hand, if ? and g 
are positively associated the covariance is positive, for when ? is 
.greater (smaller) than its expectation, g will tend to be greater 
(smaller) than its expectation, and the product in square brackets 
in (8) is positive. Conversely if, as ? increases, g decreases, then 
the product is negative. The correlation coefficient is introduced 
114 PROBABILITY DISTRIBUTIONS [3.1 
because it is unaffected by a change of units in either variable: it 
will later be proved (�3.3) that [p(?, )[ < 1. It is usually true 
(and always true for the bivariate normal' distribution (�3.2)) 
that a correlation coefficient is larger in modulus the more 
closely the two variables are associated: in particular, by (18), 
it is zero when the two variables are independent, but the con- 
verse is not true. To illustrate this let ? have a distribution with 
zero mean and zero third moment ((?a) = 0), and let Y = 
Then a little calculation shows that p(?, g) = 0, but ? and g are 
very far from being independeni. If p(?, Y) = 0 the variables are 
said to be uncorrelated. 
The dispersion matrix, together with the expectations, .ff) 
and t(), often provides a fair description of the joint distribu- 
tion of the two variables. The advantages of writing the vari- 
ances and covariances in matrix form will appear later (�3.5). 
The covariance is most easily calculated from the result 
'ff, = ff) 
(19) 
which is proved by the same methods as was theorem 2.4.1. 
It follows that if ? and g are independent o(?g)= (?)o(g), 
by (18). The relationship between the covariance and a regres- 
sion follows easily from (16) and (19): 
vff, g) = (20) 
In particular if the regression is linear, d�(gl r) = cz+flr; then 
(g) = a + fl(F) by (15) and 
(?, g) = d�[c?+fl?'-a?-fl?o(?)] = fl=(?). (21) 
The joint generating functions are mainly used in the im- 
portant case where the random variables are independent, for 
then II(x, y) = 5'. p,..p. sx"y s = II(x) IIs(y), (22) 
the product of the two generating functions of ? and g. Con- 
versely, if II(x, y) factorizes, the factors are proportional to the 
two generating functions and the variables are independent: 
for if 
II(x, y) = f(x) g (y), 
3.1] ?H. mSCR�T. CAS. 115 
and we put x = 1, the left-hand side is IIs(y ) and the right-hand 
side is a constant multiple of g(y), so Ils(y ) oc g(y) and simi- 
larly IIr(x ) ecf(x). With x = y = 1 the product of the con- 
stants must be 1 and (22) follows. (Compare the necessary and 
sufficient condition for independence given above.) 
The covariance of ? and g in the trinomial distribution can be 
found, directly, using (19), or, since the regression is linear, by 
substituting the values of the regression coefficient/ = - q/(1 -p) 
(above) and the binomial variance of ?, n�(1-�), into (21). It 
gives c/(?, g) = _ n�q. The negative value is to be expected since 
the more times event A occurs the fewer opportunities there are 
for B to occur. The correlation is -[pq/(1-p)(1-q)]. The 
probability generating function is (px + qy + 1 -p- 
Poisson process 
The definitions of this section are particularly useful when 
applied to stochastic processes and we illustrate with the simple 
example of the Poisson process ({}2.3). Let fi(t) denote the 
number of incidents in (0, t): we refer to the stochastic process 
{g(t), t > 0}. In {}2.3 the Poisson distribution of fi(t), for fixed t, 
was obtained: consider now the joint distribution of fi(t) and 
g(t + r), r > 0. The fundamental result is that 
g(t + r) = fi(t) + rh(r), 
where (r), the number of incidents in (t, t + r), and (t) are 
independent, and r(r) has the same distribution as 8(r), namely 
POt): this follows from the definition of the Poisson process. 
Consequently the conditional distribution of g(t +r) for fixed 
(t) has density, for s > r, 
p[g(t+r) = sl(t ) = r] = p[m(r) = s-rl 
= e-X'(Ar)S-r/(s - r)!, 
(23) 
and hence the joint density is 
�[(t +?) = s, (t) = r] 
= 
(24) 
Notice that the joint density is naturally expressed through the 
116 PROBABILITY DISTRIBUTIONS [3.1 
conditional densities (23) expressing the position 'now', at 
t + r, in terms of a fixed value in the ' past', at t. Clearly 
o[g(t + r)[f/(t)] = g(t) + [rh(r)] = g(t) + 
so that the regression is linear, with regression coefficient of 
unity, and, by (21), ([g(t), g(t + r)] = z[h(t)] = At and the 
correlation is therefore {t/(t +r)}i. This correlation decreases 
with r from 1 when r = 0 (and g(t + O = (0) to 0 as r  m, 
expressing the fact that the further apart in time the two counts 
(0 and g(t + r) are, the less is the correlation between them. 
For any stochastic process g(t), the correlation so obtained is 
called the autocorrelation function, a function of t and r. The 
other conditional distribution, of g(t) on g(t + r), is interesting: 
from (24) and the P[X(t + r)] distribution of g(t + r) it follows 
that 
0( t 
p[(t) = rlg(t+r ) = s] = t kt+r/ ' (25) 
which is B[s, t/(t + r)]. We leave the reader to think out for h- 
se why this is otherMse obvious from the definition of the 
Poisson process. 
Generating functions 
The following results will be required in {} 4.1. 
Theorem 1. If II(y ] r) is the probability generating function of g 
for fixed ? = r and II(y) is the probability generating function of g, 
then 
n(y) = 51 n(ylr)pr.. 
We use the same argument as led to (15) 
II(y) = 4(e*V) = &o(e*vl? ) 
= .n(ylg ) 
= Z n(y It)pt.. 
Theorem 2. The joint probability generating function, II(x, y), of 
? and g is given by 
II(x, y) =  rl(y[r)p.x r. 
3.1] 
For 
as required. 
THE DISCRETE CASE 
II(x,y) = Zpsx"ys= Zp(slr)p.xy  
= Zp.x" Zp(s[r)y  
117 
3.2. The continuous case 
Associated with each elementary event a in the sample space 
is a pair of real numbers. This association defines a pair of 
random variables, , y. Let Bx.y be the set of a for Which both 
 < x and y < y, where x and y are any real numbers. Write 
P(Bx, u) = F(x, y). Then the random variables  and y are said 
to have a joint distribution with F(x, y) as their joint distribution 
function. Suppose that there exists a function f(x, y) such that 
F(x, y) = a.f] ao. f(u, v), (1) 
then f(x, y) is called the joint density of the random variables. 
Clearly 
f(x,y) > O and f5 axfdy.f(x,y) = 1, (2) 
and any function satisfying (2) is called a joint (or bivariate) 
density. It follows from the fundamental theorem of the integral 
calculus that if f (x, y) is continuous then 
f(x, y) = 'F(x, y)/x y. (3) 
Let A be any set of a defined in terms of  and y alone. Another 
theorem of the integral calculus gives 
p(A) = f f  dxdy. f(x,.y). (4) 
In particular if A is the set with  < x, (4) or (1) gives 
p( < x) = Fx(x) = f _, a.f dv. f(u, v), (5) 
where Fx(x) is the distribution function of . Comparing (5) 
with equation 2.2.3 we see that the marginal density 
fx(x) = y)dy (6) 
118 PROBABILITY DISTRIBUTIONS [3.2 
is the density of 2: similarly 
f2(Y) = f(x, y) dx 
is the density of y (cfi equation 3.1.4). By analogy with the 
discrete case, iffx(x) 4= 0, the ratio 
f(x, y)/A(x) = A(ylx), say, 
considered as a function of y for fixed x, is called the conditional 
density of y for  = x. It obviously satisfies the conditions 
for a function to be a density. The immediate result that 
is an extension of the generalized addition law (theorem 1.4.4) 
with the suation replaced by an integration and the prob- 
abifities by densities. interchanging the roles of x and y we 
also define A(xly) = f(x, y)/A�) as the conditional density of 
 for y = y. Bayes's theorem (1.4.6) and its corollary have 
similar generalizations, 
A(yl x) = A(xly)A(y) A(xly)A(y)dy (8) 
or A(y l x) oc A(x l y) A(y), (9) 
the constant of proportionality, f(x)% only involving x. 
The random variables are independent if 
f(x, y) = A(x)A(y). (lO) 
The definitions of the discrete case in �3.1, from equation 3.1.6 
onwards, extend to the continuous case in the obvious way, 
replacing summations by integrations. 
Distribution functions and densities 
The definitions of this section extend those of the previous 
section in the same way that those of �2.2 extended those of 
�2.1. In the continuous case we have to start with the distribu- 
3.2] TH� CONTINUOUS CASE 119 
tion function and obtain the density from it. The fundamental 
property of a density in the one-dimensional case is that when 
integrated over a region (this is nearly always an interval) it 
gives the probability that the random variable lies in that 
region (interval). Since there are two variables involved here 
the integrals must be double integrals and the fundamental 
property remains true with the substitution of double for single 
integrals (equation (4)). In the bivariate case the regions are 
often more general than intervals and (4) is a significant exten- 
sion of (1). For example, if  and y are the horizontal and 
vertical distances of the fall of an arrow on a vertical target 
from the centre, we may be interested in A, the set for which 
'+;P' < c 2, where c is the radius of the 'bull'; p(A) is then the 
probability of scoring a 'bull'. If the region of integration is a 
small interval (x <  < x+h, y < .P  y + k) then the prob- 
ability of lying in the interval is approximatelyf(x, y)hk, that is, 
the density times the area (replacing length) of the interval. It is 
helpful to think off(x, y) = z as the third axis in a set of ortho- 
gonal axes, with x and y as the other two. If z is verticalf(x, y) 
may be thought of as a 'mountain' above the 'plane' z = 0. 
The total 'volume' of the mountain above any region in the 
(x, y)-plane is the probability of lying in that region. Alterna- 
tively one can think of a metal plate in the (x, y)-plane with 
mass densityf (x, y) the point (x, y)' (4) is then the mass of the 
part A of the plate. The discrete case may be similarly regarded, 
with 'mass' Ps at the point in the (x, y)-plane with integer 
co-ordinates r and s. 
The distribution function is not much used in the bivariate 
situation but its basic properties may be noted. In the discrete 
case F(x, y) has possible discontinuities along x = r and y --- s, 
where r and s are integers. Except on these lines it is constant. 
In the continuous case, however, it has no discontinuities since 
it can be written as an integral. These two cases do not exhaust 
the possibilities. It can happen that one variable , say, is 
discrete and the other, , is continuous. Then F(x, y) is dis- 
continuous at x = r for some integral r. The distribution is 
then best defined by the discrete density {pt} for the first variable, 
and the conditional (continuous) density for the second, the 
120 PROBABILITY DISTRIBUTIONS [3.2 
latter only being defined for x = r, an integer: or alternatively 
by a (continuous) density f.(y) and a (discrete) conditional 
density for 2, p,(y), say. We met an example of this situation in 
proving theorem 2.3.3 where we used the continuous random 
variable g, the time to the first incident in (0, t), and the discrete 
random variable, there , the number of incidents in (0, t). The 
joint distribution was defined in the second way and equation 
2.3.5 corresponds to (7) above. 
Another possibility is that both variables are measured con- 
tinuously and the distribution function is continuous but does 
not satisfy (1): this was mentioned as a possibility in the one 
variable case (�2.2), where it is a mathematical curiosity, but in 
the bivariate case it can occur in practice. That is, we show that 
there exists a continuous F(x, y) not satisfying (1). Suppose �' is 
a continuous random variable with distribution function F(x), 
and  = . Then F(x, y) = F(z) where z is the smaller of x 
and y. Suppose (1) to be possible. Fixing y in (1) and allowing x 
to vary in any interval not containing y we see that since F(x, y) 
is constant, f(x, y) must be zero. Hencef(x, y) = 0 everywhere, 
except possibly on x = y. But whatever value f(x, y) takes on 
that line cannot affect the integral, hence the integral must 
vanish, contradicting (1). This anomaly need not worry us in 
this book (in practice it will only occur if the two variables are 
functionally related). 
We leave the reader to verify that any joint distribution 
function has the properties: 
F(x+h, y+k)-F(x, y+k)-F(x+h, y)+F(x, y) > 0,} 
for h, k > 0, and (11) 
lim F(x, y) = lim F(x, y) = O, lim F(x, y) = 1. 
Any function satisfying (l l) is called a joint (or bivariate) 
distribution function. 
Conditional distributions 
The conditional densities are defined by analogy with the 
discrete case: the idea being that they should have similar 
properties to the discrete probabilities�(s Jr), etc. Their practical 
3.2] THE CONTINUOUS CASE 121 
use is exactly the same as in the discrete case, namely to compare 
the distributions of one variable for different values of the other. 
A direct definition in terms of conditional probabilities is not 
possible because the equivalent of Pt., the probability that the 
random variable takes a given value, is zero and hence it cannot 
be used as the denominator in p(slr ) = p,./pr.. So the condi- 
tional density is defined as f(x, y)/fl(x) = f2(Y I x) and shown to 
have properties analogous to p(s I r), of which (7) is the basic one. 
The extension of Bayes's theorem in (8) and (9) enables the 
arguments of � 1.6 to be extended to cases where the hypotheses 
form a continuous family and so are not enumerable. This will 
be dealt with in chapters 5-8 but we can already indicate an 
example of the extension. In discussing the Poisson process the 
probabilities usually contain the parameter A, the rate of occur- 
rence of incidents, and any probability is strictly conditional on 
a fixed value of A. , is part of the constant conditioning event, 
usually omitted. For example, p,(t), theorem 2.3.3, is, in full, 
the probability of n incidents in (0, t), given a Poisson process of 
parameter A. Given the Poisson process and t as understood we 
could rewrite this as p0[,k). This is a conditional (discrete) 
density for n, given ,. Now A is continuous and may have a 
distribution derived from degrees of belief. In which case it 
becomes a random variable and has a density p(A), say. Then (9) 
says that p(X In) oc p(n I X) p()t) (12) 
and expresses the beliefs about A after a count of n incidents has 
been made in time t. Equation (12) should be compared with 
equation 1.6.1. This problem will be discussed in detail in �7.3. 
The definition of independence has the same motivation as 
before: ifA(xly) does not depend on y then it must equalf(x) 
and hence f(x, y)= A(x)A(y). This final symmetric form is 
taken as the definition corresponding to the idea that the 
conditional distribution of  is not affected by y. 
Expectation 
The definition of expectation of a function of� and y,g(,y) say, 
is obviously fdxfdy.g(x, y)f(x, y) = o[g(�, 
122 ?ROBABZLIr� IIsrRBUrZONS [3.2 
and of conditional expectation 
g(y)f(y[x)dy = = x]. 
Their properties and practical interpretations are as in the dis- 
crete case. The analogy between a bivariate distribution and the 
distribution of mass in the form of a plate for the continuous 
case and point masses in the discrete one, sheds some light on 
the variances and covariances. The variances will be the moments 
of inertia about the co-ordinate axes if the centre of gravity is 
taken at the origin (equivalent to taking the means as zero). 
The covariance will be the mixed moment of inertia with respect 
to these two axes. 
Generating functions 
As in the univariate case (�2.6) the probability generating 
function is not used with continuous random variables but the 
other generating functions are defined in the obvious way. For 
example, the joint characteristic function is 
uF(t, u) = f dx dy.ei<tx+uu) f(x, y) = o[e i<te+uu)] 
and the power-series expansion of its logarithm generates the 
cumulants. 
The bivar'iate normal distribution 
We define a special joint density of considerable importance 
by letting both the conditional and unconditional densities be 
normal. Suppose that  is N(/x, o'), normal with expectation/x 
and variance r. Suppose that the conditional densities of y for 
fixed  are also normal. To define the joint distribution we have 
only. to specify the means and variances of these conditional 
densities. The simplest assumptions are that the regression is 
linear' 
(13) 
and homoscedastic, (14) 
where a, fl and r ' are constants. The joint density is then the 
(ylx) = 
3.2] THE CONTINUOUS CASE 123 
product of the two normal densities; the marginal, N(p, 0.), and 
the conditional N( + x, 0.). Hence 
f(x, y) = (2rr0.cr0-1exp - [' o'- , . (15) 
This may be written in a more symmetrical form by putting 
/t. = o + tip, (16) 
and using this te replace a in (15). After some algebra we obtain 
for f (x, y) the result 
0'2 /_l ' 
where rr = rr'+fl2tr and p = fltrx/tr 2. (18) 
The reason for the two substitutions, (18), will appear below. 
The density (17) is known as the bivariate normal density. It is 
of great importance in education and physical anthropology, to 
mention only two uses. Two measurements on adult males, 
such as height and weight are found to have such a density: 
examination marks in different subjects can often be scaled so 
that the density is normal. It has been derived here in what 
seems to be the most natural way of generalizing the sine 
variable form. 
Since (17) is unaltered by simultaneously interchanging x 
and y,  and , p and t, and  is N(p, ); f must be 
N(, vl). Similarly, since y for  = x is N(+ fix, ), that is 
N[ + (x - ) p/ x, (1 - p)], (19) 
the distribution of  for y = y must be 
+ (y - - (2o) 
so that the regression of  on y is also linear and homoscedastic. 
The regression coefficients are fl = p/w and px/ respec- 
tively. The covariance is fll, by equation 3.1.21, which equals 
Px w by (18). Hence the correlation coefficient (equation 3.1.9) 
is p (hence the notation). The bivafiate noal distribution is 
1 exp I 1 
2mrso.k. 4(1 -p') 2(1 -p') 
x 
(7' 1 o'1o- 2 
124 PROBABILITY DISTRIBUTIONS [3.2 
therefore defined by five parameters, the means, gl and/2, and 
the dispersion matrix (equation 3.1.10), 
( o'. po'.o' (21) 
porto's. ]' 
The quadratic in braces in (17) is a general quadratic and the 
five parameters are those needed to define it, bearing in mind 
that the integral being one imposes a constraint, in particular that 
it be positive semi-definite. For this distribution p is a reason- 
able measure of the association between $ and  and is exten- 
sively used in education. 
It is often convenient to introduce another random variable 
u defined by  = a +  + u. (22) 
Now, for  = x,  is N(+x, ), hence, still for ed x, 
--fix is N(0, ) (2.5). In other words the distribution of 
 -  - fix =  is the same for all x, or  and u are independent. 
Hence the total variation of  is ascribable to two independent 
causes: first, the association with  (the + term) and 
secondly, u. If the variation is measured by means of the 
variance, we have 
() = I = + w, (23) 
equation (18).  is called the residual variance of , allowing 
for $: it is the variation in  that is not ascribable to 's associa- 
tion with $. From (18), w = w(1-p), so the residual vari- 
ance of is a proportion (1 - p) of the total variance of. (The 
same holds true for .) Thus if p = 0 none is ascribable to the 
other, and ff p = 5 1 a of it is and the joint density ceases to 
est. In hct if p = 0 the density, (17), hctorkes and hence 
g and  are independent, and conversely. Thus with normal 
variables, the terms 'uncorrelated' and 'independent' are 
synonymous. The breakdown of the variation into two compo- 
nents is an portant idea and is much used in the technique 
of analysis of variance ( 6.5). 
The joint moment generating function of  and  is the 
obvious generazation of equation 2.6.10, namely 
� (z, w) = ff&dy.f(x, y)e +, 
3.2] THE CONTINUOUS CASE 125 
with f(x, y) given by (15). We know the means of  and .P are 
tq and /2 respectively, so it is more useful to generate the 
moments about the means by considering e -'-'w (P(z, w) (see 
�2.6). It is simple, but tedious, to evaluate the double integral 
by completing the squares in (x-/0 and (y- ), along the lines 
used in the univariate case (equation 2.6.13), to obtain 
exp [-,z-w] (z, w) = exp [(z]+ 2zwp+ w)]. 
The cumulant generating function, In (z, w), is thus 
iZ+ W 1   IW 
and x0 = , g0 = , ru = P (in an obvious notation) 
and all higher cumulants vanish. 
These results may more easily be obtained by using condi- 
tional generating functions as in theorem 3.1.1. We have 
(z, w) 
Since f(y Ix) is normal the integral in square brackets has 
already been evaluated in the univafiate normal case (equation 
2.6.13) and we have 
exp [- z- wt*] *�, w) 
= exp [w ] fexp [(z + wfi) 
This integral is again that for a univariate nomal generating 
function, so using equation 2.6.13 we have 
exp O(z, w) = exp 
which gives the same result on substituting for fl and z 
using (18). 
More than two variables 
All the ideas of these last two sections generalize without any 
difficulty and without any essentially new concepts, at least as 
far as is needed in this book, to the case of any finite number of 
variables. The only point that requires attention is the definition 
of independence. The random variables (, 2., ..., 2) are 
126 PROBABILITY DISTRIBUTIONS [3.2 
independent if their joint density f(xx, x., ..., x,,) is the product 
of their separate densities f(x), that is 
f(x, x2, ..., x,) = fx(xx) f2(x2) ... f(x,). (24) 
The motivation is as usual in terms of conditional densities 
(cf. (25)). The discrete case is similar. The definition should be 
compared with that for independent events (� 1.3)' there it was 
necessary to consider subcollections of events. This is not neces- 
sary with random variables since (24) implies the similar result 
for subcolleCtions by integration of (24) with respect to variables 
not in the subcollection. An alternative definition of independ- 
ence for events can be obtained by introducing random variables 
equal to 1 if A, obtains and 0 if A, obtains (the notation of 
� 1.3): the events are independent iff the random variables are. 
The random variables of an infinite sequence are independent if 
those of every finite set are. 
The general form of (24) in the dependent case is 
f(xx, x, ..., xn) = fx(xx) f.(x. Ix1) fa(xa I xx, x.)... 
f(xn I xx, x, ..., x_x), (25) 
where, for example, fa(xalxx, x) is the conditional density of 
a given x and . Compare the generalized multiplication law, 
theorem 1.4.8. 
The normal distribution also extends but its study is post- 
poned until � 3.5 because additional results are needed. 
The definitions of these last two sections are introduced in 
order to be able to handle several random variables: we are now 
in a position to prove some important results using these ideas. 
From this point onwards the distinction between  and x or 
? and r--the distinction between a random variable and the 
values it takes--will no longer be made. Once the ideas of expec- 
tation, and particularly conditional expectation, have been 
understood the manipulations can most easily be carried out 
without having to consider whether  or x is intended. 
3.3. Linear functions of random variables 
Throughout this section x will denote a random variable; 
a, b, a and b will denote constants. By a linear function of 
3.3] LINEAR FUNCTIONS OF RANDOM VARIABLES 127 
(Xl, x, ..., x,,) is meant a function of the form E aixi+ b' if 
b = 0 it is a homogeneous linear function. All summations are 
from 1 to n. 
Theorem 1. ( a xi + b) =  a(x) + b. 
We give the proof for two variables x, x and consider the 
continuous case with density f(x, x). The left-hand side is, by 
definition, equation 3.1.7, 
.f f dx(ax xx + agx + b) f(x, x), 
wch may be written as the sum of three integrals, the first of 
wch is 
f dxfdxaxlf(x, x)= a(x0. 
The other two follow silarly and the result is proved for n = 2. 
The case of general n follows by induction. Discrete variables 
may be handled similarly, replacing integrations by suations. 
Theorem 2. 
(Zaixi+b) = ( ax,) =  a(xi)+  aia(xi, x). 
i i  ij 
Again consider n: 2 and the continuous case. Other cases 
follow as with theorem 1. The st equality is equation 2.4.4 and 
it remains only to prove the second. Let x'i = xi-(xi), then 
2(x'i): (x'?) and (x'i,x)= (xx). Also by theorem 1 
2 
(Zaixi) = Zai(xi) so 2(Zai Xi) = 2 (Z aixi). Hence 
 (Za, xO = [(a xl + ax) ] 
= g[axi+ 2aaxlx +ax ] 
= a(xi)+ 2ala(xlx)+ al(x). 
by a further use of theorem 1. This proves the result. 
Corollary. If the {x/} are uncorrelated 
(Zax) = Za (xO. 
If they are uncorrelated the covariances are a zero. 
128 PROBABILITY DISTRIBUTIONS [3.3 
Theorem $. If the (x) areuncorrelatedand(xO = t, '(xi) = rr 2, 
for all i; then tf  = n 4 Y xi 
The results are special cases of theorem 1 and the corollary 
to theorem 2 obtained by putting ai = n-L 
Theorem 4. If the {xi} are uncorrelated and have the same 
variance, then the random variables  a xi and 22 b x are uncor- 
related iff aibi = O. 
To prove them uncorrelated we have to show that the co- 
variance is zero. Using the same ideas as in the proof of 
theorem 2, we see that this covariance is 
(Yax'i, Ybx') = [(Zax.) (Zbx'i)] 
=[Zabx'x3]. 
But if i 4: j, P(x x) = 0, and o(x'i 2) = tr ', say, is the same for 
all i, hence the covariance is (Zab)tr2 which proves the result. 
Combination of observations 
The subject treated in this and some later sections (particu- 
larly � 6.6) used to be called' Combination of Observations'. This 
is a study of the way in which random variables can be com- 
bined, starting here with linear combinations, the most widely 
used. The first theorem is almost obvious from the way expecta- 
tion has been defined, and an important .thing to notice is that it 
is true without any conditions on the random variables beyond 
the fact that they have expectations. For example, in the last 
line of the proof of theorem 2 it has been used for the random 
variables '" x' x' and x ' which are functionally related to each 
Xl , 1  
other. The same remark applies to theorem 2 provided that 
the variances exist. In this result we see how the covariance 
enters when calculating variances of linear functions: it is similar 
to the use of mixed moments of inertia in calculating the moment 
of inertia about a general line in the body, in terms of the mixed 
moment and the moments about the axes (the analogues of the 
3.3] LINEAR FUNCTIONS OF RANDOM VARIABLES 129 
variances). The corollary, however, only obtains when the vari- 
ables are uncorrelated, that is when the correlation coefficient 
(or the covariance) between any pair is zero: in particular when 
the variables are independent. Under these conditions the 
corollary states that the variance of a linear function is a 
different linear function of the variances, namely with a replacing 
a�. Notice that this is a result in terms of variances, not in terms 
of standard deviations, and is a good example of the way in 
which variances are used in calculations at the end of which 
a square root is taken to obtain the more readily interpreted 
standard deviation (cf. {}2.4). 
We shall find it useful in chapter 8 and in {} 3.5 to use vector 
and matrix notation, and theorem 2 can be conveniently 
expressed in these terms. Let a denote the column vector with 
elements ax, a:, ..., an and a' its transpose, a row vector with the 
same elements. Let C denote the dispersion matrix of the x's 
(equation 3.1.10). Then 
2(a'x) - a'Ca, 
a quadratic form in the at. 
Arithmetic means 
Theorem 3, although only a special case of the two previous 
theorems, is a famous and important result. It says that the 
expectation of X', usually called the arithmetic mean, or simply 
the mean, of the {x}, is the common expectation of each xi, and 
that the standard deviation of the mean is the common standard 
deviation of each xi divided by root n. The results are true 
under the conditions of uncorrelated random variables each 
with the same expectation and variance. A common circum- 
stance where these conditions obtain is in a random sample of 
size n ({} 1.3) from a large, or infinite, population, where each 
member of the population has associated with it a number. 
A random sample of size n will yield n numbers: xz, for the first 
member of the sample, and so on. Clearly these n numbers, or 
observations, or random variables, will all have the same distri- 
bution and be independent (approximately for a finite popula- 
tion, exactly for an infinite one) because of the random sampling 
I0 PROBABILITY DISTRIBUTIONS [3.3 
(-see also �5.1). Hence, in particular, they will be uncorrelated 
and have the same means and variances, and the theorem caa be 
phrased: 'The mean of a random sample of size n has expecta- 
tion equal to the common expectation and standard deviation 
n-.i that of each observation.' 
It also applies when n repetitions have been made of a single 
measurement of an unknown quantity, 8, say: for example, 
n determinations of the acceleration due to gravity in an 
observatory. If (x)= 0 the measurements are said to be 
unbiased: if not, the difference, (x0 - 0, is called the bias or the 
systematic error. Presumably the determinations have equal 
precision (though it is easy to imagine circumstances when they 
will not because of some improvement in design as the experi- 
ment progresses) which will be reflected in a common variance, 
2(x) = trY': ' is a measure of the random error (cf. � 5.1). The 
total error is a combination of these two errors (compare the 
argument in the last section in connexion with the bivariate 
normal distribution). Finally the determinations will often be 
independent, though again not always: chemists often ignore 
a measurement which deviates too much from the others and 
substitute another one which is in better agreement with them, 
so introducing a correlation. If, however, all these conditions 
obtain, the theorem says that the mean has the same bias as each 
measurement (in particular it is unbiased if they are) and the 
random error, measured by the variance, is reduced by a factor 
of 1 In. Scientists typically use repeated measurements to reduce 
random error; our theorem gives us a measure of how well this 
is done; but systematic error is not, of course, reduced by such 
repetition. The standard deviation is the usual measure of 
random error quoted, t and the factor n4 shows that repetition 
becomes less and less worth while as n increases. For example, 
the error is halved by taking four measurements as against one, 
but sixteen measurements (twelve more) are needed to reduce 
it by a further factor of 2. 
To illustrate and emphasize the fact that theorem 3 only 
obtains for uncorrelated variables, consider an example with 
' A term which used to be used, but is not now in favour, is probable error; 
this is one-half the interquartile range (�2.4). 
3.3] LINEAR FUNCTIONS OF RANDOM VARIABLES 131 
n = 2 where all the conditions of that theorem are satisfied 
except that the correlation between xt and x2 is p. Then 
theorem 1 is still available to show that go(g).=/t but we must 
use theorem 2 in order to obtain the variance: in fact 
2() = �{2(xt) + :(x.) + 2(xx, x:)}, with ax = ao. = �. Con- 
sequently '() = �(1 + p) or2. With p = 0 the result of theorem 3 
obtains: with p = 1 the measurements are positively perfectly 
correlated and they are only as good as a single measurement: 
with p = -1 they are negatively perfectly correlated and the 
value of jc is determined with no random error at all. This final 
result is explained by the fact that xx must be as far above/x as 
x2 is below it in order that p be - 1; that is xx =/t + e, x2 =/c- e, 
so that  =/t exactly. (Compare the comments at the end of this 
section.) If measurements can be obtained with a large negative 
correlation then the mean may be a very precise determination. 
Experimental design 
One of the tasks of a statistician is to measure the random 
phenomena that are the subject of his study, and one measure of 
the randomness is the random error just defined. Theorem 3 
shows how the random error is reduced by repeated determina- 
tions of an unknown quantity. But in addition to this, the 
Statistician has to design an experiment to reduce the random 
error and to make as precise a determination as is possible. The 
following famous example illustrates this design aspect and the 
use of the theorems of this section. Four similar objects 
A, A2, Aa, A are to be weighed on an ordinary two-pan balance 
provided with a set of known weights. The usual method of 
determining the weights of the four objects would be to weigh 
each one separately, using, therefore, four weighings. We show 
that with four weighings each object can be weighed more 
accurately than this. Suppose that a weighing consists of putting 
the object or objects of unknown weight on one or both of the 
pans and adding known weights to the amount xi, say, to one of 
the pans until they balance. Then xl is a random variable. The 
sample space is the space of all possible weighings of the object 
or objects and xi is defined for each. Suppose (xi) is the true 
weight of the unknown(s) and 2(x)= o '2. In the former 
132 PROBABILITY DISTRIBUTIONS [3.3 
assumption we are supposing that there is no bias? and in the 
latter that the precision does not depend on the unknown weight. 
If the separate weighings of each object are made and supposed 
independent, each unknown weight will be determined with no 
systematic error and with standard deviation rr. Consider 
instead the following series of weighings: 
First weighing 
Second weighing 
Third weighing 
Fourth weighing 
Left-hand pan Right-hand pan 
&, Aa Aa, A4 
A, Aa A2, A4 
Ax, Aa, Aa, A None 
Suppose that in the ith weighing weights to the amount xi have 
to be added to the right-hand pan to obtain balance. (In the 
first three weighings the weights may have to be added to the 
left-hand pan to obtain balance, but this can be thought of as 
an addition to the right-hand pan with xi negative.) The x are 
then independent random variables with variances r '. If no 
error were present (o' = 0) the weights 0 of A could be found 
from the equations 
+ = 
= 02+0+x3, 
83+ = 
with solutions 
(1) 
(2) 
Now suppose  4:0 and the right-hand sides of these equations 
are used to determine the weights of the objects. (Why this 
should be done will be clarified in {}6.6.) Then theorems 1 and 2 
show that each determination is made with no systematic error 
and with standard deviation �r. Hence by weighing the objects 
' If there is bias, or systematic error, it may sometimes be removed by making 
a second weighing with the known and unknown weights interchanged in the 
pans. Then d'(xx) = x+b, $(x2) = x-b and so $(�) = x, in an obvious notation. 
3.3] LINEAR FUNCTIONS OF RANDOM VARIABLES 133 
together in these four weighings instead of separately in four 
weighings the standard deviation has been halved. Another way 
of halving the standard deviation would be to weigh each object 
separately four times, sixteen weighings in all. The design pro- 
posed here uses only a quarter of this effort and is said to be four 
times as efficient as that using four separate weighings. 
This little experiment also illustrates another idea of some 
practical consequence. If there are several related things to be 
investigated it is usually better, if possible, to combine them in 
one experiment rather than to perform separate experiments. 
Here it is better to use all four objects in each experiment 
(weighing) than to use them singly. Another application of the 
same idea arises when it is required to determine the values of 
certain variables, e.g. temperature, pressure, humidity, etc., 
which maximize the yield of a product: it is better to vary the 
variables together in a systematic way, rather than to vary one 
factor at a time. 
Finally, in connexion with this experiment, notice that 
theorem 4, which applies to uncorrelated variables of equal 
variance, such as the x in (2), shows that the  in the same 
equations are uncorrelated. If it was possible to suppose the t 
normally distributed---and, as will be seen later ({3 3.6) this might 
be very reasonable--then they would be independent. Thus this 
experiment retains the feature of the ' one-at-a-time' method of 
making independent determinations. This is a desirable feature 
since if the determinations were, for example, positively 
correlated then one over-determination might mean that they 
were all over-determined. The condition for lack of correlation 
in theorem 4 is the same as the condition for the vectors 
(a, a2, ..., as), (b, b2, ..., b) to be orthogonal. We shall find it 
useful to think of the vectors associated with linear forms 
(�8.3); by analogy with these, the determinations of (2) are said 
to be orthogonal and the experiment is called an orthogonal 
exleriment. This example will be discussed again in �6.6. 
Correlation coefficient 
It is now possible to prove that the correlation coefficient 
(equation 3.1.9) never exceeds one in modulus. Let x and y be 
134 PROBABILITY DISTRIBUTIONS [3.3 
two random variables with correlation p and 2(x) > O, and 
consider the variance of ax+y, which must be non-negative. 
By theorem 2, 
(ax + y) = a:(x) + 2a(x, y) + '(y). 
Considered as a function of a this is a quadratic which tends to 
+ as lal -  and must have no distinct real roots, since if it 
did the variance would be negative for values of a between the 
roots. The condition for this is 
(x, y) < (x) 2(y), 
which is equivalent to ]p] < 1. p = + 1 iff there is an a0 with 
..2(aox+y ) = 0, so that aox+y = c, where c is a constant: that 
is, x and y are linearly related. 
The results of this section for means and variances extend 
without difficulty of principle to the higher moments, but the 
results are not so often required. 
3.4. Approximate means and variances 
Theorem 1. If x is a random variable with $(x) =/t, (x) = 0'. 2, 
and y = (x) then, for sufficiently small rr, and well-behaved  
(Y) '"- q3(/O +�0"(/0, (1) 
and (y) -- '(/0  o ''. (2) 
Expand �(x) in a Taylor series about # as far as the term? 
in (x-/O': 
y = (x) = �)+(x-/) �'(/0+�(x-#)  
+ O[(x-j0a]. (3) 
Now if o' is small, by Chebychev's inequality (theorem 2.4.3), 
x will depart only a little from/.t except on rare occasions and 
therefore (x-/) will typically be small. The final term will there- 
fore be neglected. The result (1) then follows on taking expecta- 
tions of both sides of (3) using theorem 3.3.1 on the right-hand 
side and (x-/O = 0, [(x-/0 ] = rr '. 
'{' We write O [g(z)], read 'order of g(z)', for a function f(z) which is such that 
If(z)l < Kg(z) for some constant K and all z sufficiently near to some value, 
here zero. 
3.4] APPROXIMATE MEANS AND VARIANCES 135 
To prove (2), rewrite ($) as 
y - 95() - �o''0" (/.c) 
= (x-/0 '(/0 +�[(x-Y'- '1 "()+ O[(x-)3], 
and square both sides, retaining only the terms of order (x-)  
on the right-hand side. On taking expectations. the rift-hand 
side is �'()y:, to the approximation used, and the left-hand 
side is, by (1), (y), to the same order. 
Theorem 2. If x and y are random variables with g(x) = , 
(y) = v,(x) = ,(y) = r  and p(x,y) = p, and z = (x,y) 
then, for sufficiently small  and r, and well-behaved  
(z)  (p, ) +  a + pr O + r  
' ax  ax ay ' (4) 
a (z)     ( ) 
[ax] + 2pr ax  + r ' (5) 
where all the partial derentials are evaluated at x = , y = u. 
The theorem is a direct generalization to two variables of the 
single variable case of theorem 1, and it is proved in exactly the 
same way using, in lieu of (3), the two-variable form of Taylor's 
theorem, 
�(x, y) = �(, ) + (x- )  + (y - ) ay 
a 2 
+ k(x- )  + (x- ) (Y - ) ax ay 
+ (y- ) a (5) 
ay2 , 
where the higher-order terms haw been omitted and th partial 
differentials am evaluated at x = , y = . 
Comments on the results 
The results of this section, like those of the last, belong to the 
field of 'Combination of observations' and were well known 
long before the modern theory of probability and statistics was 
developed. They differ from the results of the last section in that 
they are only approximate, instead of exact, but on the other 
hand they apply to a wide class of functions besides linear ones. 
136 PROBABILITY DISTRIBUTIONS [3.4 
The approximation is useful for relatively small standard de- 
viations and the results are mainly of value when the measure- 
ments are fairly precise. For example, the surveyor uses them, 
and so does the physicist; in the biological sciences where the 
variation is larger more refined analysis is often needed. Theorem 
1 is the single-variable form and we begin by making some re- 
marks about the proof. The Taylor series could be extended to 
more terms and then the higher moments would enter into (1) 
and (2), but these are seldom useful: indeed even the second term 
i0 (1), o'- (?), can often be ignored, as indeed it is effectively in 
the proof of (2). Notice that with that term retained the expecta- 
tion of  is not quite  evaluated at the expectation of x, but the 
term represents a correction, which is usually small. In the 
proof we have omitted to state any .conditions on (x), but 
obviously some are needed; first, to make the Taylor series 
expansion about x --/t possible, which requires conditions on  
in the neighbourhood of x --/t; and secondly, to avoid ano- 
malies of behaviour away from/t which, although of very small 
probability, can be of importance. As an example of the latter 
consider the function (x) = x-;this could cause trouble near 
the origin even if the probability of values near the origin was 
small since when they occur (x) is large. We have not attempted 
to state such conditions but the person using the results should 
be aware of the possible pitfalls in the uncritical use of thein. 
No new points arise in the extension to two variables in theorem 2 
and the extension to any number is immediate. We might, how- 
ever, look at another 'proof' which has at least mnemonic value 
and differs only in details from that given: it employs the notion 
of differentials, 3x, small increments in x. We have 
If both sides are squared and expectations taken, treating all the 
differentials as deviations from means, (5) immediately follows. 
Example 1. The logarithmic tra,sformation. Let x be a positive 
random variable and y = lnx. Then from (1), 
'0")- lnjt-�rr�# , (7) 
and -(y) ---= o-// . (8) 
3.4] APPROXIMATE MEANS AND VARIANCES 137 
These are more conveniently expressed in terms of 
= = 
the coefficient of variation of x: then 
(y)  ln/z_�A., .(y) ,2. (9) 
As has already been mentioned (2.4) (x) is often constant 
over a series of experiments; in this case the logarithm will have 
constant variance which is convenient for many purposes 
(compare, for example, 6.1, 6.4). The result is also useful in 
certain applications involving formulae which are multiplicative 
because the logarithmic transformation makes them additive. 
For example, one method of determining the viscosity, , of 
a fluid is to measure the pressure drop P along a tube of 
length l and radius a when the fluid flows tough at rate Q; 
the relevant formula is 
 = n(aP)/8lQ. 
If P, a, I and Q are measured independently it follows from (8), 
on taking logarithms and using the exact formula for the vari- 
ance of a linear function (corollary, theorem 3.3.2), that 
(V)  (P) + 16(a) + (1) + :(Q). 
If the precisions with which the four quantities hP, a, l and Q 
are measured are known, then this result enables the precision 
of the determination of viscosity to be calculated. Notice that 
because of the factor 16 in front of g(a) it is most portant 
that the tube used be of uniform radius and that this radius be 
measured accurately: it would be foolish to measure the other 
quantities carefully and yet use a poor quality tube. 
We saw in 2.4 that the coefficient of variation of a P(n, ) 
variable was n4, for all . It follows that if we have a set of 
random variables with P-distributions having a common value 
of n, then their logarithms will have approximately, for large n, 
a common standard deviation. This wi prove useful in later 
applications ( 7.3). 
Example 2. The square-root transformation. Suppose that 
experiments are being carried out to investigate the density of 
blood corpuscles in the human body. Part of the experental 
138 PROBABILITY DISTRIBUTIONS [3.4 
technique may consist of the preparation of a slide and a count 
of the number of corpuscles in the field of view of the micro- 
scope. By the theory of the Poisson process the count may be 
expected to have a Poisson distribution and, since the variance 
of a Poisson distribution is equal to its mean, it will follow that 
if some factor increases the mean number of corpuscles it will 
also increase the variance. Consequently the experimenter will 
have counts of different precisions which can make the infer- 
ences a little awkward. One way out of the difficulty might be to 
transform the counts to obtain new values whose accuracies are 
constant whatever shift of mean takes place. The problem then 
is: if x is P(/O can we find y = �(x) with a variance not depen- 
dent on/, ? This can be done approximately by use of (2). If 
2(y,) = c o- we have co- ----- �'(j,)2/ since '(x) =/,, or, ignoring 
the approximation, 
whence 
d c 
(/t) = 2c//t, 
ignoring a possible constant. Takirig c = - for convenience, we 
2 
have �(x)= x/x and the square-root transformation of 
yields an approximately constant variance c 2 -- �. The expecta- 
tion of /x is, by (1), x/jt-///t. Notice that the correction term 
(�(ro-3"(?) = --/x/tO becomes less important as/t -+ oo. Similar 
remarks would apply to any higher terms that could be added 
to (2) and hence the approximation gets better as #-> oo. Near 
/t = 0 the variance can be made more nearly constant by using 
d(x +--), or 4x + x/(x + 1), instead of /x. An application is given 
in �7.3. 
Example 3. The iJmerse-sine transformation. Suppose x is 
B(n, p) and consider the same problem as in example 2 with 
fixed n and varying p, and try to find a transformation yielding 
a variance independent ofp. If o-(y) = c 2 (possibly a function 
of n) we have c  ----- �'(np)npq since (x) = np and "(x) = npq. 
By an argument similar to that above we easily obtain with 
c = 1/2/n, that 95(x) = sin-X/(x/n). This is called the inverse- 
sine transformation and gives approximately constant variance. 
c  = 1/4n. (Notice that y is measured in radians, from the solu- 
3.4] APPROXIMATE MEANS AND VARIANCES 139 
tion of the differential equation.) The approximation improves 
as n - oo: for small n the transformations 
sin-d [(x + )/(n + )] 
�(sin-'d[x/(n+ 1)] + sin4d[(x + 1)/(n + 1)]} 
or 
are better. 
3.5. Exact methods 
Theorem 1. If x is a continuous random variable with density 
f(x), and if y = 3(x) is a strictly monotonic differentiable function 
of x with continuous derivative, then the density of y exists and is 
given by g(y) = f(x) dx/dy . (1) 
Suppose  is strictly increasing. Then the event y < t, for any 
real t, is the same as the event x < s, where s is the unique value 
such that O(s) = t. Hence these two events have the same prob- 
ability and the distribution function of y is 
p(y < t) = p(x  s) = f(u)du = f(u)dv, 
where, in the final integral, the substitution v = (u) has been 
made. Hence the distribution function of y can be written as an 
integral and, since du/dv > 0, the integrand, the density, is as 
stated. The continuity of the derivative ensures that the change 
of variable in the integral is valid. 
If � is strictly decreasing we have similarly 
fi 
p(y < t) = p(x > s)= f(u)du = - f(u) d v , 
and since du/dv < 0 the result follows. 
The conditions on O(x) ensure that to each value of y there is 
at most one x with y = O(x). This is necessary in order to pass 
from p(y < t)to p(x..5< s)or p(x > s). 
If we next consider the joint density of two random variables, 
x and y, and consider two functions w = 5(x, y) and z = (x, y) 
whose joint density is required, we assume for the same reasons 
that the transformation is 1-1: that is, to each w, z there exists 
a unique pair x, y such that w = 5(x, y), z = fr(x, y). Satis- 
140 PROBABILITY DISTRIBUTIONS [3.5 
factory conditions for the subsequent change of variable are that 
the Jacobian of the transformation exists and that the partial 
differentials are continuous. We state the bivariate case: the 
general case of n random variables is similar. The proof is a 
straightforward extension of the one variable case. 
Theorem 2. If x, y are coltinuous random variables with joint 
densiO, f(x, y) and if w= 5(x, y), z = )(x, y) is a 1-1 trans- 
formation fi'om (x, y) to (w, z) whose Jacobian, 
� ' 
exists with all tile partial differentials continuous, then the joint 
densiO,' of w and z exists and is git.,en by 
g(w, z) = f(x, y) J-L (2) 
Theorem 3. If the joint density of two random variables x and y 
is f(x, y) and z = x + y, then tile probability densiO' of z exists 
and is given by 
h(z) = f(x, z- x)dx. (3) 
For any real t, 
p(z < t)= p(x+y < t)= ff. dxdyf(x, y). 
Changing the variable y in the integral to z = x +y we obtain 
p(z < t)=ft_ dz f _ dx f(x, z- x). 
oo o 
The distribution function is expressible as an integral and the 
result follows. 
Corollary. If x and y are independent, so that f(x, y) = f(x)g(y), 
say, then 
h(z)= f; f(x)g(z-x)dx. (4) 
co 
The equivalents of theorems 1 and 2 are without significant 
content in the discrete case but theorem 3 is useful, a summation 
replacing the integration. For example, in the corollary, if the 
3.5] EXACT METHODS 141 
densities are {&} and {qi} for x and y respectively, then the 
density {ri) of z = x + y is 
ri =  P'qi-j. (5) 
Theorem 4. If x and y are independent random variables with 
characteristic functions Fx(t ) and Fv(t ) respectively, then z = x + y 
has characteristic function given by 
F(t) = XFx(t) xFv(t ). 
(6) 
uz(t ) = g(eit*), (for the definition see {}2.6), 
= 1 e it(z+u)) 
= dxdyeit(+v)f(x)g(y), in the notation of the corollary, 
= eitZf(x)dxf e aug(y)dy, as required. 
The discrete case follows similarly. 
The logarithm of F(t) is therefore additive when independent 
random variables are summed, and this is a reason for intro- 
ducing the cumulant generating function ({}2.6). 
Functions of random variables 
The results of the last two sections enable the means and 
variances of a function of random variables to be obtained 
either exactly (linear functions in {}3.3) or approximately ({}3.4) 
in terms of the means and dispersion matrices of the random 
variables. Often these provide sufficient knowledge of the distri- 
bution of the function, for example if the distribution is known 
to be normal, but there are situations in which more knowledge, 
for example the density, is required. Also there are certain exact 
results on combination of observations that are useful. It is to 
these that we turn in this section. The reader may like to be 
reminded before studying the proofs that a density is a function 
which when suitably integrated (or summed) gives a probability, 
both in the univariate and multivariate cases. It is often useful 
to have a geometrical picture in mind; for example, in the 
bivariate case, to consider the integration of the density over 
regions in the plane. 
142 VROBABI.IT� DISTRIBUTIONS 
Theorem 1 is most easily remembered in the form 
g(y) dy = f(x) dx, 
[3.5 
using positive differentials, and many writers include the differ- 
ential element when referring to a density (of a continuous 
random variable). For example, (2rr)-e- x2 is a density, N(0, 1), 
considered as a function of x, but not as a function of x ' (see 
below), so it would be written (2r)-e-x2dx, to indicate this. 
The proof of the theorem (and of theorem 2) involves merely 
a change of variable in an integral and this change introduces 
the differential element or the Jacobian. The restrictions placed 
on the function are the same as those placed on the Jacobian in 
order that the usual formula for the change of variable be valid. 
The proof of theorem 1 shows the need for these restrictions 
since, in the general case, the event y < t would correspond to 
some quite complicated event in terms of x and not to the 
simple event x < s. Even if y were increasing, but not strictly 
increasing, the result could fail and the density not exist: thus if 
qS(x) = 0 for 0 < x < 1 thenp(y = O)is at leastff(x)dxwhich 
may well be positive, and hence the distribution of y will have 
a discontinuity at the origin. Nevertheless, the case of general 
�(x) can be dealt with by theorem 1: the method of doing this 
may best be explained by an example. 
Example 1. The square of a normal variable. Let x be N(0, o '2) 
and consider the distribution of y = x '. The function �(x) = x  
does not obey the conditions of the theorem over the whole 
range of x, but it does so over the ranges x > 0, and x < 0, 
separately. So suppose x > 0 first. Then the contribution to the 
density of y is, remembering dy/dx = 2x = 2y', from (1) 
(2rrr2)- e- /2 �y-. (7) 
There is a similar contribution from x < 0 which is the same 
as (7) because Id/&l --- 2 lxl = 2y, and the density for x is 
symmetric about x---0. Hence the final density of y (for 
y > 0, necessarily) is twice (7). This may be put into a recog- 
nizable form by writing X = 1/2 2. Then 
g(y) = e-XVAy-l/drr, (8) 
3.5] �XACT METHODS 143 
and comparison with equation 2.3.7 shows that y = x ' is 
I'(�, 1/2rr2), a gamma variable with parameter 1/2tr 2 and 
index' �. Notice that the mean of the normal distribution is 
zero, but that the variance is arbitrary. 
Example 2. The log-normal distribution. Suppose that y is 
a positive random variable whose logarithm is normally distri- 
buted: what is its density ? Let x = In y and x be N(/t, trY'). 
Then dy/dx = y, and y = e � is strictly increasing, so that 
(1) gives 
1 { 1 (lny_/t)2} 
g(y) - x/(2rr)tryeXp -- � 
The density is zero at y = 0, rises to a maximum at y = e/-'' 
(the mode) and tends to zero as y tends to infinity. The easiest 
way to find the moments is to find those of e  directly from the 
normal density. For example (equation 2.6.13). 
1 f e r e4 (-)/'2dx = exp {�r(2/t + tr'r)}. 
/4 - 4(27r) 
We shall see later (theorem 3.6'. 1) that the normal distribution 
arises in considering the sum of a large number of independent 
and identically distributed random variables. It follows that the 
log-normal distribution can arise in dealing with the product of 
a large number of similar random variables. For example, the 
size of incomes might have a log-normal distribution (�2.4). If 
one has a sum of money out at a fixed rate of interest, then in a 
given period of time it is multiplied by a quantity: hence the 
total sum of money is the product of a number of variables. (It 
might be even more relevant to the distribution of capital.) 
Shrfilarly, the size of particles in a powder often has a log- 
normal distribution. Let X be the size of a particle which is 
being ground. The .grinding will produce a particle of size x X, 
say; a second grinding will produce from the latter particle one 
of size ( X), and so on. If the assumption is made that the 
grinding proportions  do not depend on the size of the particle 
or the index i, then the final size is the product of independent 
and identically distributed random variables. 
'1' It was shown at the end of �2.5 that (-�)! = /n. 
144 PROBABILITY DISTRIBUTIONS [3.5 
Ex;pectations 
Theorem 1 also shows that two definitions of expectation 
given previously are consistent. In �2.2 the expectation of x 
was defined as f ,xf(x)dx, and that of 0(x) as f O(x)f(x)dx. 
But the first definition says that the expectation of y = 95(x) 
is J'yg(y)dy and hence we have two definitions of R(y), one in 
terms of the density of y, the other in terms of the density of x. 
If O(x) satisfies the conditions of the theorem then this shows 
that the two definitions are equivalent. The general case follows 
by dividing the range of x up into parts within which O(x) does 
satisfy the conditions, as in example 1. The second form for the 
expectation is particularly useful since it does not require the 
evaluation of the density of q. An instance of its use is the 
passage from the first to the second line in the proof of theorem 4. 
Theorem 3 could have been used to write down the expectation 
in terms of h(z), but this definition avoids using that theorem 
and is more direct. Similar remarks apply in the discrete case, 
but then there is no differential element to complicate the 
picture. " 
Costruction of random samples 
An immediate corollary of theorem 1 has a special use. If 
�(x) is put equal to F(x), the distribution function of the random 
variable x, and if F(x) obeys the conditions of the theorem, y-- 
which necessarily lies between 0 and 1 has in that interval 
density g(y) = 1. This follows since dy/dx = f(x). The distri- 
bution with density equal to (b-a) - in the interval (a, b) 
with a < b, and otherwise zero, is called the uniform distri- 
bution in (a, b). In words the corollary says that the distri- 
bution function of a random variable has a uniform distribution 
in the interval (0, 1)--subject to the conditions on the distribu- 
tion function just stated. The special use of this result is to 
obtain random samples from any distribution. Tables are avail- 
able of random sampling numbers; for example, Kendall and 
Babington Smith (1954). These give sequences of the digits 0 to 9 
arranged in random order, that is arranged so that the digits 
occur equally often, and after any sequence, say 97231, of any 
3.$] EXACT METHODS 145 
length, any digit is as likely to occur as any other. (For detailed 
discussion of the practical difficulties here, refer to the tables.) 
If these digits are taken in groups of n and a decimal po!nt put 
in front of the group, the numbers so formed are approximately, 
a random sample from a uniform distribution in (0, 1) exactly, 
they are grouped into intervals of width 10-'* (�2.4). Con- 
sequently, treating one of the numbers as y of the theorem, the 
valuest F-(y) form a random sample from the distribution 
function F(x). Normally a table of F(x) can be used backwards 
(i.e. from F(x) read x) in order to obtain F-(y). Random 
samples from the standardized normal distribution (I)(x) have 
been produced in this way by Wold (1954). We use the device 
in connexion with the exponential distribution in �4.1. If F(x) 
does not obey the conditions for application of the corollary, 
minor modifications to the method enable it to continue to be 
used. 
Sums of random variables 
The corollary to theorem 3 is more important than the 
theorem itself. If f(x) and g(x) are any two functions the 
integral in (4) is called the convolution of f(x) and g(x) and is 
extensively studied in many branches of mathematics. We illu- 
strate its application to the Poisson distribution, using, of course, 
the discrete form (5). If x is P(/0, Y is P(v) and they are indepen- 
dent, then the density of x+y is, by (5), 
i 
] e-/'/d e-vi-/(i-j)! j!. 
j=0 
The range of summation is only from 0 to i since if x +y = i 
then neither x nor y can exceed i. This may be rewritten 
(e-</'+>/i!)j= � #iv i-, 
and the sum is equal to (/ + v) i by the binomial theorem. Hence 
the density of x +y is Poisson with mean/ + v. Or the sum of 
two independent Poisson variables is Poisson. This result is 
denotes the function inverse to F. That is, F-X[F(x)] = x. 
146 PROBABILITY DISTRIBUTIONS [3.5 
obvious from the results on a Poisson process (�2.3). Let x be 
the number of incidents in (0, t) and y the number in (t, t + u), 
with At =/,/u = v, where 3. is the parameter of the Poisson 
process. Then  and y are Poisson variables with means  and v 
(theorem 2.3.3) and, by the definition of the process, are in- 
dependent. But x +y is the number of incidents in (0, t + ) and 
is therefore, by the same theorem, P( + v). The reader may like 
to prove directly by (4) and also by using known properties of 
a Poisson process that the sum of two independent F-variables 
with the same parameter has also a F-distribution with that 
parameter and index equal to the sum of the indices. 
The main tools for handling the convolution of two functions 
are the Laplace and Fourier transforms, so in probability we use 
the generating function or the characteristic function. Theorem 4 
shows the reason for the success of this tool: with summation of 
independent random variables the characteristic functions corn 
bine much more easily, namely by multiplication, than do the 
density functions in (4). Hence in dealing with sums of 
independent random variables the characteristic function is an 
portant and almost indispensableStool. We illustrate with the 
normal distribution. The characteristic function of an N(, aa) 
variable is (equation 2.6.13 with z = it) 
exp [it-t]. 
Hence if x and y are independent and respectively N(g, ) and 
N(, ) it follows from (6) that the characteristic function of 
x+y is the product of the separate characteristic functions, 
namely 
exp [/(1 + g) t   
- + 
But this is immediately recognizable as the characteristic func- 
tion of an N( + , ] + [) variable. Since, as we explained in 
2.6, the characteristic function truly characterizes the distribu- 
tion (there are not two distributions with the same characteristic 
function) the sum of two independent normal variables is also 
normal. Notice how simple this proof is and compare it with 
the tedious algebra that the use of (4) would involve. Notice 
that the mean and variance of x+y agree with our previous 
results in  3.3. The result extends to the sum of any number of 
3.5] EXACT METHODS 147 
independent normal variables, and also their mean, which is 
merely a multiple, n% of the sum and is therefore also normal 
(�2.5). 
It does no harm to. emphasize again that theorem 4 applies 
only to independent variables. However, the example of the 
normal distribution does not require this restriction: since, we 
need it later we state the result. 
Theorem $. If x and y have a joint normal density then x + y is 
also normal. 
We use the notation of �3.2. Consider the joint density of 
x+y and, say, x. This can be found by theorem 2 from the joint 
density of x and y with w = x +y and z = x. The Jacobian is 
unity and it is-clear that the general quadratic in x and y in 
braces in the normal density (equation 3.2.17) remains quadratic 
in w and z. Hence w and z have a joint normal density and 
the marginal distribution of w is normal. The parameters of the 
normal density of x + y are most easily found from theorems 3.3.1 
and 3.3.2 to be 
(x+ y) = tq +t2, 2(x+ y) = ++2po'rr2: 
alternatively they may be derived by obtaining the quadratic 
just mentioned in w and z and comparing with equation 3.2.17 
and the known mean and variance of x in that distribution. 
Since if x is normal so is aT, for a constant a, it follows that any 
linear function aT+ by is normal if x and y jointly are. The 
result and its proof extend to any number of multivariate normal 
variables. 
Multivariate normal distribution 
In chapter 8 we shall require the general multivariate normal 
density for n variables and we introduce and discuss it at this 
point to illustrate methods of handling several random variables. 
Consider random variables xt, x., ..., x, with densities defined 
as follows: 
x is N(O, o'}), 
for fixed x, x., ..., xi_ 
(1 
< i < n).} 
(9) 
148 PROBABILITY DISTRIBUTIONS [3.5 
In words, each random variable is normally distributed for 
fixed values of the previous variables, about a mean which is a 
homogeneous linear function of the previous variables, with 
constant variance. By equation 3.2.25 the joint density of the 
x's is i 1 exp - [0.- +  
0.3'1 0'2 � � ' 0., 0.2 
. (lO) 
fls is only used when j < i: define fli = - 1 and rio' = 0 for 
j > i. Also let YEs = fl.';/0.i for all i, j. Then (10) can be rewritten 
1  x. (11) 
 1 exp - Yo . 
Change to random variables 
zi = - Z = - Z 
(12) 
The Jacobian of the transformation (see theorem 3.5.2) is the 
modulus of the determinant offthe matrix I' with elements 7o'- 
But y;. = 0 for j > i (F is said to be lower triangular) so that 
this determinant is the product of the diagonal elements, 
namely 1-I y = (-),*110..-x. Hence the joint density of the zi is 
i 
simply (27r)- exp [- Zz]. 
1 1 2 
The joint density factorizes into terms containing only one of 
the z's, and, by the argument of �3.1, the z's are independent 
and clearly N(0, 1) variables. Thus (12) gives a set of indepen- 
dent standardized variables which are, of course, easy to handle. 
& is simply the deviation of xi from its regression Y flox., 
suitably standardized. 
From (12) the xi can be written as linear functions of the z;.: 
x i = _ 5;Ti'z ' 
where {y'} are the elements of r -. Hence, by theorem 3.3.2, 
3.5] .XACT M,XUOt)S 149 
and the total variation of xi has been expressed as the sum of 
a number of separate variations due to each z. This generalizes 
equation 3.2.23. 
We may rewrite (11) as 
1 '* 
(2r0-'"(-)'I,I'[exp [ i,i__lxiaijxj., (13) 
where aij. = ZTlciTtcj and Irl is the determinant of r. If A is. 
the (symmetric) matrix with elements ao, then 
A = r'r, (14) 
where a prime denotes transpose. We now obtain a simple 
interpretation for A. 
From (9) 
o(xx) = 0 and 
i--1 
(xil Xl, x, ..., xi_0 = Z/i;%'. 
It follows by successive use of this last result that 
i-1 
(xO -- . (x l x, x, ..., x_O = Z ?i. ,(x.) = 0 
j=l 
(using equation 3.1.15 and theorem 3.3.1). Hence from (12) and 
theorem 3.3.1 again, 
) 
?(Zi, Z]) = '(ZiZj) = 0  7,iXl, jmXm 
l=1 
=  TilTjmClrn, 
where qm = (XtX) = ff(Xt, X,,,). Since the zi are independent 
N(0, 1) this result may be written in matrix notation as 
I = rcr', 
where I is the unit matrix and C is the matrix of elements Ctm. 
But r is non-singular (we found its determinant above as a 
product of inverses of standard deviations), so that 
c = r-(r')- = (r'r)-x = A-. 
(15) 
Hence A is the inverse of the dispersion matrix of the x's. 
150 PROBABILITY DISTRIBUTIONS [3.$ 
Also ]C[ = + r-, from (15) and hence, taking the positive 
sign for the square root, (13) may be written 
(2r) -" C-kexp - Z xic i'x. , 
z.i,j=l I 
(16) 
where c ii are the elements of C -x -- A. We shall later (� 8.3) find 
it useful to pass from (16), in terms of the dispersion matrix, to 
the regression form (10). 
If xi is replaced by xi-pi then we have the general multi- 
variate normal density 
(2)41c1- exp - Z (xi-pi)ci(xj-p) (17) 
i, j = 1 
with dispersion matrix, C, as before and .(Xi) -- Pi' The regres- 
sions corresponding to (9) will be 
i--1 
[(Xi--/Zi) l Xl, X2, "', Xi--1] = Z 
j=l 
i--1 
that is (Xi[ X1, X2, .. ', Xi:l) = Oi 
i-1 
where 
j=l 
3.6. Limit theorems 
Theorem 1. (Central Limit Theorem.) If {x,} is a sequence of 
independent random variables each having the same distribution 
of mean p and variance o ', then the sequence of distribution 
functions of xi-np (o'Jn) converges to the distribution 
function of an N(O, 1) variable,' that is to $(x). 
The proof is outlined below. 
A sequence 0',} of random variables is said to converge in 
probability (or converge weakly) to a constant c if, given any 
e > 0, tim p(ly-cl > e): 0. (1) 
Theorem 2. (Weak law of large numbers.) If {x,} is as in theorem 1, 
then 2 = n -  x converges weakly to p. 
i=1 
3.6] t. IMIT THEORY, MS 151 
By theorem 3.3.3 d() =/, "() - a/n, and hence by the 
corollary to theorem 2.4.3 (Chebychev's inequality), for any c > 0 
p(lg-ll > c/4n)  c -. 
Rewriting this with e = e)n 
Since the right-hand side tends to zero with n, so does the left. 
A sequence {y} of random variables is said to converge 
strongly to a constant c if 
p( lim y = c) = 1. (2) 
Theoretn 3. (Strong law of large numbers.) If {x} is a sequence 
of independent random variables with a common distribution then 
a necessary and suffiient condition for  to converge strongly to 
a value  is that 4(x) exists and is equal to . 
This result is discussed below. 
Limits of distribution functions 
It is often useful to be able to approximate to one distribution 
by another which is more convenient to handle. We have already 
met one example in �2.5 where the binomial distribution was 
approximated to by the normal distribution. The method used 
by a mathematician to discuss approximations is to consider 
a sequence of expressions which tend to a limiting value: each 
expression is an approximation to the limit (or vice versa), the 
later ones in the sequence being typically better than the earlier 
ones. A familiar example is an expansion of a function in an 
infinite series: any finite number of terms of the series provide 
an approximation to the function. This was the method used in 
de Moivre's theorem just referred to: here the limit is an approxi- 
mation to the members of the sequence..In order to use such 
ideas in probability we have to say what is meant by a sequence 
of distributions converging to a limiting distribution. In this 
book we shall only have occasion to consider the case of a uni- 
variate random variable and the definition is most easily and 
usefully expressed in terms of the distribution function which is 
a probability, rather than in terms of the density which is not. 
152 PROBABILITY DISTRIBUTIONS [3.6 
Let F,,(t) be a sequence of distribution functions and F(t) 
another distribution function which is a continuous function 
of t: then the obvious definition of convergence of distributions 
is to demand that F,,.(t) -+ F(t) as n -> oo for all t, and this is the 
definition always used. If F(t) is not continuous it rather sur- 
prisingly turns out that this definition is unsatisfactory, but in 
this book we need only the continuous. F(t) so the difficulty is 
ignored. This definition has already been used in �2.5, without 
a formal explanation, for the case where F(t)--(t), the 
standardized normal distribution function (which is continuous). 
Now one way of establishing limit theorems for distributions 
is by direct calculation of the distribution functions; but this is 
usually tedious and a much more powerful method is to use 
characteristic functions. The following result is of considerable 
use. 
Theorem 4. A necessary and sufficient condition that a seque7ce 
of distribution fimctions {F,,(t)} with corresponding characteristic 
functions {O,(t)} tend to a limiLF(t), for all t, is that O,(t) tends 
to a limit O(t) which is continuous at t = O. qS(t) is then the 
characteristic fimction corresponding to F(t). 
The theorem is true for any F(t) but only continuous F(t) will 
be used here. The theorem replaces convergence of distribution 
functions by convergence of characteristic functions. Now if 
a sequence of distribution functions tends to a limit, it is easy to 
see whether the limit is a distribution function or not (equations 
2.2.1 and 2). But, in general, it is not easy to see whether 
a function is a characteristic function. Consequently, if we 
could prove that a sequence of characteristic functions tended 
to a limit we should not know whether the limit was a charac- 
teristic function. The condition of the theorem that the limit be 
continuous at the origin is easily verified and ensures not only 
that the limit is a characteristic function but that it is the 
characteristic function corresponding to the limiting distribu- 
tion function. in many situations the limiting behaviour of the 
characteristic functions is easier to establish than that of the 
distribution functions directly, and the result is very powerful. 
The proof is beyond the level of this book and will have to be 
3.6] LIMIT THEOREMS 153 
left, just as the proof that the characteristic function truly 
characterizes the distribution has had to be omitted. An 
interested reader with enough mathematics can find proofs in 
Cramer (1946) or Loire (1960). 
Central Limit Theorem 
The main use of theorem 4 is to prove the classical and 
important central limit theorem, theorem 1. The theorem is 
stated in terms of distribution functions; the proof uses charac- 
teristic functions. Furthermore, as we are dealing with sums of 
independent random variables we can use theorem 3.5.4 which 
is more conveniently expressed in logarithms of characteristic 
functions, or cumulant generating functions. Now since xr has 
finite variance o -2 it follows from equation 2.6.9 that its cumulant 
generating function (with z = it, to ensure that it exists) is 
ln(exp [itx,,]} = Iit-�o't z + R(t), 
where R(t)/t 2 - 0 as t -> 0. (3) 
Hence ln{exp [it(x,.-)]} = -�o'2t 2 + R(t), 
on subtracting jtit from each side, and 
In  {exp.[it(xr-/)/tr /n]} = -�t2/n + R(t/rr 
on writing t/train in place of t. The left-hand side is the cumulant 
generating function of (xr-tt)/%/n and hence by theorem 3.5.4 
the cumulant generating function of Y, (x-tO/%/n is the sum of 
the separate functions, that is 
n[-�tyn + R(t//n)]. (4) 
Now because of (3), nR(t/rr/n)--> 0 as n--> co, so (4) tends to 
-�F which is certainly continuous at the origin and so is 
a cumulant generating function by theorem 4. In fact, by 
equation 2.6.13, it is the cumulant generating function of a 
standardized normal distribution, N(0, 1). This, and the unique- 
ness of the cumulant generating function, proves the result. 
The result is truly remarkable because it says that whatever 
distribution the x, have in common their sum, suitably stan- 
154 PROBABILITY DISTRIBUTIONS [3.6 
dardized, tends to have a normal distribution, only provided the 
variance exists. We have already met an example: in the simple 
random walk (�2.5) x = + 1 with probability p and -1 with 
probability q = 1 -p; Z x,. is the position after n steps of the 
walk, and was shown, corollary to theorem 2.5.2, to have a 
limiting normal distribution. The Central Limit Theorem shows 
that the same limiting normal distribution will hold for any 
random walk provided only that the steps have a distribution, 
discrete or continuous, with finite variance. Consequently in 
many additive processes without barriers it is reasonable to take 
the distribution of position after a fair number of steps as 
normal. The proof given in � 2.5 of the limiting behaviour of the 
simple random walk extends without serious difficulty to the 
general situation, though the proof just given is easier. The 
fundamental difference equation 2.5.3 becomes in the general 
discrete case 
p(sln ) =  p(s-rln-1)p, 
where {p,.} is the common distribution of the steps u, in equation 
2.5.1. In the continuous case 
where jx) is the density of u,,. By arguments similar to those 
used in �2.5 it is possible to pass in the limit from these more 
complicated equations to the diffusion equation 2.5.7. We omit 
the details. 
Theorem 1 proves that a Poisson variable, P(tO, tends to 
normality as j6 -3 : precisely, that the distribution function of 
(x-/.O/x/J tends to (I)(x) as/x -> oo when x is P(/). This is because 
if xi is ?(1), Z xi is P(n) (�3.5). Similarly, a P-variable, P(n,A), 
tends to normality as n-+ c for fixed A, because the sum of 
independent P-variables with a common A is a F-variable (� 3.5). 
The Central Limit Theorem can be generalized beyond the 
form given here. It is not necessary that the x have a common 
distribution, the distributions can be different provided no one 
3.6] tMXT TH.OR�MS 155 
x, dominates the rest. For example, if the variance were 
undefined, because the defining integral or sum diverged, then, 
the variable would be rather dominant. It is not even essential 
that the x be independent, although any dependence must not 
be so strong that one or a few of the x dominate. Essentially the 
Central Limit Theorem holds provided the summation is a true 
mixture of a lot of distributions of finite variance in which no 
component of the mixture is much more important than any 
other. Thus it is often used to justify saying that errors of 
measurement (�3.3) are normally distributed. If this were so 
then the results of � 3.3 on means and variances would be of even 
more value than they are without normality because a normal 
distribution is completely described by its mean and variance. 
The argument is that the final error of measurement is the result 
of many minor errors in the experiment, none of which is itself 
of importance (if it were the experiment would be re-designed) 
and therefore the final measurement should be normal. But it is 
difficult to see why the minor errors are additive. Such empirical 
evidence as one has suggests some departure from normality, but 
there are many practical situations in which normal distributions 
appear to occur; thus in anthropometry men's heights have a 
normal distribution, though whether this is because a man's 
height is the sum of a number of contributions from his 
an:estors is not clear. 
One particular situation in which errors of measurement are 
certainly not normally distributed, is where they are due to 
rounding-off errors. Suppose a true value/ is measured to the 
nearest unit giving a value x. Then x-/t has a distribution con- 
fined to the interval (-�, + �) and there is usually no obvious 
reason for thinking that any one value in this interval is more 
likely than any other. Consequently it is usually assumed that 
the density is constant in the interval. That is, rounding-off 
errors have a uniform distribution (� 3.5) in (-�, �) in the units 
of measurement. Obviously the distribution is far from normal. 
The Central Limit Theorem may be expressed in the form of 
a result about the mean  = n -x 22 xi of a number of random 
variables by saying that ( -tO/(cr//n) is approximately normally 
156 PROBABILITY DISTRIBUTIONS [3.6 
distributed. The standardizing factors, tt and o'//n, are of course 
the mean and standard deviation of . The reduction of random 
errors by repeated measurement was discussed in �3.3: the 
Central Limit Theorem shows that the mean of the measure- 
ments will not only have a smaller random error than any single 
measurement but will also have an approximately normal distri- 
bution. For the individual measurements will usually be inde- 
pendent and have a common distribution the assumptions of 
theorem 1--and only the existence of a variance is needed for 
the normal limit. Rounding-off errors provide an example. In 
statistics (that is in inference problems) normality is a most con- 
venient assumption and a statistician often takes advantage of 
this property of the mean of repeated measurements. 
Weak convergence 
Theorem 2 is of more theoretical interest. The definition of 
weak convergence is an attempt to put into precise form the 
limit notation, 'lim', that was used in chapter 1 as a basis for 
the probability axioms. In words (1) says that however small 
a departure from c is considered, the random variable y will, 
for large n, almost always be contained within it. It does not 
say that y, tends to c; all it says is that y is usually rather 
near c. We often write plim y = c (probability-limit) to dis- 
tinguish it from the mathematical limit. The sequence of trials 
considered in � 1.1 was interpreted in � 1.3 as a random sequence 
of trials with constant probability of success. If x, = 1 or 0 
according as the nth trial results in a success or a failure, the x 
satisfy the conditions of the law,  is the success ratio, m/n, and 
(x,0 = p =/(x,-- 1). Hence the law says that plim (m/n) = p, 
/,..- oo 
and is an expression proved within our mathematics corre- 
sponding to 'lim' (m/n) = p observed in the real world. Thus 
the weak law is a confirmation that our mathematics is a good 
description of random phenomena because it contains within it 
a result in such good agreement with practice. Had plim (m/n) 
not been p it would have been necessary to amend the axioms. 
3.6] LIMIT THEOREMS 157 
Ergodicity 
The law does have some practical consequences. In the 
language of � 3.3, it says that if repeated measurements are made 
with no systematic error 'of an unknown/, then their mean will 
tend, in the sense of weak convergence, to/z. In other words you 
will get as near as you wish to the right answer if you go on long 
enough. Another consequence of the law, and generalizations 
of it, is a principle that we all use, often without recognizing that 
it is a result of some depth: this is the ergodic principle. In its 
simple form here it is the statement that the two means, it and 
plim , are the same.. Hence the mean can be found by taking 
each sample point or elementary event, a, finding the value of xx 
there, and averaging over all a, so obtaining tt: or one can take 
a single sample point and find xx, x, xa, ..., for this a, and the 
average of these will be plim . Provided the x's obey certain 
conditions the two means will be equal. Ergodic theorems are 
concerned with conditions for this to be so and the law here is 
a very simple case. The average over the sample space is often 
called a sl)atial mean: that over {x} is called a temporal mean 
since n can be thought of as a measure of time. An example of 
the use of the ergodic principle arises with the Poisson process. 
Let x, be the number of incidents in the interval (n-1, n): 
clearly the conditions of the law obtain and d�(xi) = ,k. Then/ 
may be found either by observing many Poisson processes (all 
with the same value of ,k) in the interval (0, 1) so obtaining 
g(xx), or by observing a single process over a long period of 
time (0, n) when the average number of incidents per unit time 
is  which tends (in the sense of converges weakly) to ,k. Sto- 
chastic processes for which the two means are equal are called 
ergodic processes. Examples will be studied in ��4.5, 4.6. 
Notice that the practical justification for expectation used in 
�2.1 in connexion with games of chance uses the ergodic 
principle. Another example is given in �4.2. 
Strong convergence 
A more useful ergodic result is the strong law of large numbers 
(theorem 3). A sequence of random variables is said to converge 
158 PROBABILITY DISTRIBUTIONS [3.6 
strongly to a constant c if' ahnost all' realizations of the sequence 
converge to c in the ordinary mathematical sense of convergence; 
where by 'almost all' is meant with probability one. It can be 
proved that strong convergence implies weak convergence but 
not conversely, so the nomenclature is reasonable. The strong 
law, when looked at as an ergodie result, says that the two means, 
/ and lim Z xi/n, with probability one, are the same and, 
moreover, because the condition stated is necessary and suffi- 
cient, the existence of either mean implies the existence of the 
other. The probability content of this result is only a qualifying 
one (namely 'with probability one') and permits the identifica- 
tion of # and lim  in almost all cases. This fact and the use of 
an ordinary mathematical limit makes the strong law more 
useful .than the weak one. Also the existence of a simple con- 
verse, that if lim : exists, almost always, (x) exists and is/e, is 
of practical value. (A corresponding converse for the weak law 
is false.) Important applications of the strong law are given in 
��4.2 and 4.J. Unfortunately the proof of the strong law 
involves some manipulations which are outside the scope of this 
book and we have to leave it. A proof is given in Love (1960). 
Notice that the result makes no mention of the existence of 
2(x). The weak law can also be stated without assuming a vari- 
ance to exist but the proof given here, which is firmly based on 
variance considerations, is no longer available. Theorem 4 can 
be used to provide a proof. 
Poisson limit of binomial 
An alternative proof of the Poisson limit result (�2.3) that 
a B(n, p) variable tends, as n  0% p--3 0 with np= lt, to a P(/0 
variable, is provided by theorem 4. The characteristic function 
of a B(n, p) variable is obviously (peit+ q)' and considering the 
limit of this as n-> oo under the conditions stated we have 
lim 1 + (e it- 1) = exp [tt(e it- 1)] 
by the well-known result that lim (1 + [x/n])  = e x. The right- 
hand side is continuous at t = 0 and is recognizable as the 
characteristic function of P(/0 (equation 2.6.12, with z = it). 
3.6] LIMIT XI-IV. ORV. MS 159 
Cauchy distribution 
We end this chapter with a word of warning. Theorems 1 and 2 
are not necessarily true. without the restrictions on {x,}: norm- 
ality is not always the end-product of a limiting operation in 
probability theory. To illustrate we produce the standard 
skeleton in the statistician's cupboard: the Cauchy distribution. 
This is a continuous distribution with density, for all x, 
f(x) = (rr(1 + x2)} -. (5) 
(The substitution x = tan0 shows that the integral of(5) is one.) 
The integral for the mean does not converge absolutely and 
hence neither does that for the variance. The characteristic func- 
tion is e -Itl, a result which is easily obtained by complex-Variable 
methods. Hence if the {x,} of theorems 1 or 2 have Cauchy 
distributions (with no mean nor variance) the sum Z xl has 
characteristic function e -rim and, on substituting tin for t, we 
see that the mean, Z x,l/n, has characteristic function e -Itl, the 
original Cauchy distribution. Hence the mean of measure- 
ments with a Cauchy distribution has the same distribution as 
any single measurement. Thus if the experimenter's measure- 
ments had a Cauchy distribution and if he took the average of 
them he would be in the same position as if he had taken just 
one and thrown the rest away. The resolution of this apparent 
paradox is obtained by taking some other function of the 
measurements in place of the average. For example, the median 
has a distribution which, as n-> o% tends to normality with a 
variance which tends to zero. 
Suggestions for further reading 
The suggestions listed in chapter 2 are also appropriate for 
this chapter. Tables of random sampling numbers have been 
provided by Kendall and Babington Smith (195'4). They have 
been converted, as described in �3.5, to provide tables of ran- 
dom samples from a standardized normal distribution, Wold 
(1954). Similar collections are given by the Rand Corporation 
160 ?ROBABI.IT� DISTRIBUTIONS [3.6 
(1955). The special topic of limit theorems is considered in 
detail.by Gnedenko and Kolmogorov (1954). The multivariate 
normal distribution is the basis of almost all statistical work 
involving several random variables. An excellent modern book 
is Anderson (1958), which is primarily concerned with the 
statistical aspects. A delightful and unusual book is that by 
Kac (1959). 
Exercises 
1. Suppose that 'points' occur in a Poisson process of parameter A, so 
that the number, X, of points in a unit interval has a Poisson distribution 
of mean A. Suppose, further, that at each point, there is one 'individual' 
with probability 0 and two individuals with probability 1 -0, the numbers 
of individuals associated with different points being mutually independent. 
Let Y be the number of individuals in a unit interval. By considering the 
15roperties of Y conditionally on X, or otherwise, obtain the mean, 
variance and probability generating function of Y. (Lond. M.Sc.) 
2. In n mutually independent trials, where n is even, there is a probability 
of a 'success' of 0x in each of the first �n trials and a probability of a 
success 0f 02 in each of the remaining trials. 
Prove that the mean and variance of the total number of successes are 
respectively �n(O + 02) and �n(O + 02) '   
- n(O + 0o.). Hence show that, 
unless 0 = 0., the variance of the number of successes is less than it would 
be in a binomial distribution with the sanhe number of trials and the same 
mean number of successes. (Lond. B.Sc.) 
3. A game between two opponents A and B is in five steps, the winner of 
a step scoring one point. Each step is equally likely to be won by either 
player and the outcomes of different steps are mutually independent. 
Prove that the probability that one or other player is ahead throughout 
the game is 3/8. 
What are the mean and variance of the difference, at the end of the game, 
between the numbers of points scored by A and by B? (Lond. B.Sc.) 
4. In a series of mutually independent trials, the possible outcomes on 
any one trial are 'success' and 'failure'. By introducing a random vari- 
able Zi for the ith trial, equal to 1 if the ith trial is a success and 0 if the ith 
trial is a failure, or otherwise, prove that the mean and variance of X,, the 
number of successes in n trials, are 
(x) = nO., 2(Xn) = nO. (1 - 0.) - z(0i- 0.)2. 
Here 0i is the probability of a success in the ith trial and 0. = ZOdn. 
What are the values ofp(X, = 0) andp(X = 1)? (Lond. B.Sc.) 
5. Incidents are occurring in a Poisson process at the rate of one per unit 
of time. Each incident is either of type A with probability p or type B with 
probability q = 1-�: these being independent for the different incidents. 
EXERCISES 161 
Show that the following two events are equivalent: 
(i) at least r out of the first n incidents are of type ,4; 
(ii) the rth incident of ,type ,4 occurs before the (n-r+ 1)st incident of 
type B. 
Hence show that if ? is a B(n, p) variable then 
where t and  are independent random variables having distributions 
which are respectively I'(n- r + 1, q) and I'(r, p). 
6. n couples procreate independently with no limits on family size. 
Births are single and independent and, for the ith couple, the probability 
of a boy is pi. The sex ratio, $, is (mean .number of all the boys)/(mean 
number of all the children). Show that if all couples: 
(i) do not practice birth control, $ = Y.p#n; 
(ii) stop procreating on the birth of a boy, S = n/Y.(1/pi); 
(iii) stop procreating on the birth of a girl, $ = 1 -n/:E(1/q); 
(iv) stop procreating when they have children of both sexes, 
S = [Z(1/q) - Zp]/[Z(1/pq) - n]. 
Comment on possible inequalities among these ratios. 
7. A certain kind of nuclear particle splits into 0, 1, or 2 new particles 
with probabilities 1/4, 1/2, 1/4 respectively, and then dies. The individual 
particles act independently of each other. Given a particle, let X, Xa and 
Xa denote the number of particles in the first, second and third 'genera- 
tions' respectively. 
Find: 
(i) p(x2 > 0); 
(ii) p(Xx = I[X2 = 1); 
(iii) p(Xa = 0). 
8. A process of incidents starting from t = 0 is such that the probability 
of an incident in (t, t + St) is A, St, where n is the number of incidents in 
(0, t), but is otherwise independent of the time of occurrence of the 
incidents in (0, t). Find the expected time from t = 0 up to the nth 
incident. 
9. A game consists of a number of independent turns at each of which 
three, and only three, mutually exclusive events can occur as follows: 
(i) the game terminates without addition to the score; 
(ii) the game continues without addition to the score; 
(iii) the game continues with the addition of one point to the score. 
If a player has a constant probability of encountering these events in 
each turn (but a different probability for each event), show that the 
probability of his scoring N points in one game is 
m  
(1 + m) +' 
where m is his average score per game. 
162 PROBABILITY DISTRIBUTIONS 
Deduce that the probability of a player with average mx scoring more 
points in one game than a player with average mz is 
/7l 1 
1 + m + 
10. Each of N+ 1 boxes contains N counters. The boxes are numbered 
i = 0, 1, 2, ..., N; box i has i red counters and (N-i) green counters well 
mixed. Box k is arbitrarily chosen by an investigator, and from it he makes 
N independent drawings of a counter with replacement obtaining a red 
counter r times. He then makes n drawings without re�1acement from box 
number r, where n is a fixed number < N, and obtains s red counters. Find 
the frequency distribution of s under repetitions of the sampling with 
fixed N, k and n. Discuss the manner in which the mean value of s depends 
on k. (Aberdeen Dip.) 
11. Obtain the regression equations ofy on x for the bivariate probability 
distribution where p(x=r, y=s), r and  integers, is the coefficient of 
urv  in 
exp [a(u- 1)+ b(v- 1)+ c(u- 1) (v- 1)]. 
(Aberdeen Dip.) 
12. The densities h, hz, ... of different species of nocturnal insects in the 
neighbourhood of a light-trap are supposed to be observations of a 
random variable h which has a moment generating function of the form 
(e at) = {f(t)}% 
where a is a constant, cz > O. The number caught of the ith species is 
supposed to be a Poisson variable with mean h. If r is the number caught 
of a randomly chosen species find the probability generating function of r. 
What form does this take, conditional on r > 1 ? Obtain the limiting form 
of this conditional probability generating function as z-> O. Hence, or 
otherwise, obtain the distribution of frequency of individuals among 
species caught in the trap when the probability density function of X is 
X "-x e -x 
> 0), 
and the numOer of species present in the vicinity of the trap is very large 
compared with the number of different species represented in the trap. 
(Loud. Dip.) 
13. Producer gas from a certain plant has calorific value varying erratically 
in a normal distribution of mean 160 Btu per cu.ft and standard deviation 
28 Btu per cu.ft. It is desired that the calorific value shall only rarely fall 
below 110 Btu per cu.ft. Find the proportion of values actually below this 
limit. 
A new flow of gas is formed by mixing two similar streams, the calorific 
values of which vary independently in normal distributions with the above 
mean and standard deviation. The calorific value of the combined stream 
EXERCISES 163 
at any point is the average of the corresponding calorific values in the 
separate streams. Find the proportion of values in the new flow below 
110 Btu per cu.ft. (Camb. N.S.) 
14. At one stage in the manufacture of an article a piston of circular 
cross-section has to fit into a similarly shaped cylinder. The distributions of 
diameters of pistons and cylinders are known to be normal with parameters' 
Piston diameters' mean 10.42 cm, standard deviation 0.03 cm. 
Cylinder diameters: mean 10.52 cm, standard deviation 0.04 cm. 
If the pistons and cylinders are selected at random for assembly, what 
proportion of pistons will not fit into the cylinders ? What is the chance 
that in 100 pairs, selected at random, all the pistons will fit? 
(Wales Math.) 
15. The variates yx, Y2, have a bivariate normal distribution with means 
zero, variances o-, cr and covariance poir.. Individuals are selected at 
random subject to the single constraint 
y > xtra. 
For this selected portion of the population find' (i) g(Y0, (ii) $(y:), 
(iii) (Y0, (iv) 2(y2) , (v) (yz, y2), in terms of x, z, p, where 
1 e_. and p = e-i dr. 
z = 4(2) oo 4(2r) 
(Aberdeen Dip.) 
16. Obtain the regression equations of y on x for the bivariate probability 
distribution 
f(x, y)dxdy = yexp [-y/(1 + x)]dxdy 
(1 + x)  
for x, y > 0. (Aberdeen Dip.) 
17. In a certain investigation the frequency of accidents per unit time for 
a given individual follows a Poisson distribution with expectation m, but 
the value of m varies from one worker to another in a distribution with 
frequency function 
__ mA-1 e-am 
' 
where c� and ,t are constants. Show that in a random sample of workers 
from this population the frequency of 0, 1, 2, ... accidents per unit time 
would be represented by the terms in an expansion of the negative binomial 
(q-p)-, where q-p -- 1. Express p in terms of z and ,t. (Camb. Trip.) 
18. In a sequence of independent trials, a certain event E has always the 
same chance p of occurring (0 < p < 1). Let r be the number of the trial 
at which E first occurs. Find the probability distribution of r, and show 
that the mean and variance are respectively 
1 and 1-p 
p p � 
164 PROBABILITY DISTRIBUTIONS 
A large population consists of equal nmnbers of individuals of c different 
types. Individuals are drawn at random one by one until at least one 
individual of each type has been found, whereupon sampling ceases. 
Show that the mean number of individuals in the sample is 
fl 1 1 
c +.+�+ ... + !} 
and the variance of the number is 
c s 
(Camb. N.S.) 
are not necessarily 
19. The random variables Xx, X, ..., X,(which 
independent) are such that each takes only the Values 0 or 1. The prob- 
ability that Xi = 1 isp and the probability that Xi = 1, Xj = 1 simultane- 
ously isp. Calculate the expectation and variance of X and the covariance 
of X and Xj. If n Y = 5; X, show that the variance of Y is 
(& - + (&- &)/n, 
where nSx = Zp and �n(n-1)$2 = 5; 5; p. 
i=l j=2 
Whe n the variables are independent show that the variance of Y can be 
expressed entirely in terms of n Sx and V, where n V = 
i=l 
Deduce the variance of the number of successes in n independent trials 
when the probability of success per trial is p. (Camb. N.S.) 
20. If x and y are independent, find the mean and variance of 
axy + bx + cy + d 
in terms of the means and variances of x and y, where a, b, c and d are 
constants. 
The length x and breadth y of manufactured rectangular plates are 
found to form two independent series of measurements with means 16 and 
25 cm and standard deviations 1 and 2 cm respectively. Assuming that 
the area of the plates has a normal distribution, find what proportion of 
the plates will have an area greater than 480 cm 2. (Camb. N.S.) 
21. If x and y are independent show that 
.:(xy) = (x) :Cr) + [g(x)l ' (y) + [g(y)]: :(x). 
22. Solid right circular metal cylinders of height h and radius r are 
accepted on testing after manufacture provided that their volumes do not 
exceed 57,500 c.c. The dimensions h and r are distributed independently 
with the same standard deviation p about the respective mean values 
� 20 and 30 cm. Find the greatest tolerable value for p if the frequency of 
rejection is not to exceed 2� %, it being assumed that the logarithm of the 
volume is distributed approximately normally. (Camb. N.S.) 
EXERCISES 165 
23. It is required to estimate the mean percentage yield of a certain ore. 
To do this, r separate specimens of ore are taken at random, and s indepen- 
dent laboratory determinations are made on each specimen. It is known 
that the variance of the true percentage yield of different specimens is o', 
whilst each laboratory determination is, in addition, subject to an 
independent experimental error of variance . 
Find the variance r of the estimated mean percentage yield obtained 
by averaging the rs determinations. 
If it takes time T to collect a specimen and To to make a determination, 
find the values of r and s which minimize the time necessary to attain 
a given value of o -2. (Camb. N.S.) 
24. The number, n, of particles recorded by a Geiger counter in an interval 
of time T when placed near a weak source of radiation has a Poisson 
distribution with mean 3`T, where 3` measures the strength of the source. 
Show that (n/T) = 3` and find 2(n/T). 
The source of radiation is only available in the presence of an independent 
noise radiation of constant strength 
a second method is used where the number, n, of particles is recorded for 
an interval T with only the noise present, and then the number n2 for an 
interval T, with both noise and source present. Show that 
(n2/T2- n/TO = 
and find 2(n2/T.-n/TO. 
Show that, in order to make the two variances equal, if the noise and 
source are found to be about the same strength and T = T,., then it 
requires the counter to be used for about six times as long when the noise 
is present, as would be needed if the noise were absent and the first method 
could be used. Can the factor six be reduced in these circumstances by 
allowing T and T. to be unequal ? (Camb. N.S.) 
25. The distance r from the centre of a plane target to the point where a 
shot falls has a probability distribution of the form 
__1 e_r,l 
where  is initially unknown. In order to estimate the probability P that 
a shot will fall within a fixed distance a of the centre of the target, n shots 
are fired and the distances r, r2, ..., r, of their points of fall from the centre 
are recorded. P is then estimated as 
P = l_e'l., ', 
where =1  r. 
2n 
Show that, if n is large, P has mean approximately equal to P and variance 
approximately equal to 
a � _al a. 
4nor  
Can you suggest any alternative method by which P might be estimated 
after the n shots have been fired ? (Camb. N.S.) 
166 PROBABILITY DISTRIBUTIONS 
26. The number of insects killed, r, when n insects are exposed to a dose 
of an insecticide, is distributed in a binon-dal distribution with parameters 
n and p. The following quantity y is defined in terms of r and n: 
2r+ 1 
y=ln 
2n-2r+ 1' 
By writing r = np+ r and expanding y as a Taylor series in ascending 
powers of 8r, or otherwise, show that if n is large the distribution of y has 
approximately mean In {p/(1 -p)) and variance 1/{np(1 - p)), where terms 
of order n -2 have been neglected. 
The chance p that any insect is killed depends on the dose, according to 
a relation of the form 
In P = a+flx, 
1-p 
where x is the logarithm of the dose, and  and fl are unown constants. 
For the purpose of estimating  and fl, n insects are tested independently 
at each of the two doses for which x = 0 and 1 respectively. The numbers 
of insects killed are found to be respectively ro and r. If the corresponding 
values of y are denoted by Y0 and Yx, then Yo and Y-Yo are taken as 
estimates of a and fl respectively. Find expressions for the variances and 
the covariance of these two estimates, in terms of a. and fl, using the above 
approximate expression for the variance of y. (Camb. N.S.) 
27. In attempting to construct an equilateral triangle of Unit side corre- 
lated errors each having zero mean are made in each of the three sides 
x, x, x. The error in each side has variance v and there is a covariance 
(-pv) between each pair of errors, p > -. Show that the area of the 
triangle is distributed with variance given approximately by v(1- 2p)/4. 
(Camb. N.S.) 
28. The random variable r has a negative binomial distribution, that is, 
where n and p are parameters of the distribution. Obtain a transformation 
f(r/n) of r/n such that the variance of the transformed variable is approxi- 
mately independent of p. (Camb. N.S.) 
29. In a certain family of distributions encountered in field entomology 
a variate x is distributed with mean m and variance (m+Am ) where 
 and  are the same for all distributions of the family and  is small. It is 
desired to apply a functional transformationf (x) which will yield a variate 
y whose variance V is approximately independent of m. Determine 
appropriate forms for f(x) in the cases (i)  > 0, (ii)  = 0. 
(Camb. N.S.) 
30. x is a Poisson variable with expected value g. y is equal to (x+ a)  
where a is a non-negative quantity. Show that: 
(i) (y) = b(+ a)  [- + {(b- 1) - 2a} g- + O(g-a)], 
(ii) 4[A)] = (3b- 2) - + O(-"). 
167 
Using these formulae, suggest values of b and a to be used to produce 
a variable y with variance which changes with g as little as possible 
(relative to its magnitude). What further information would be needed if 
the aim were to make /[flx(y)] as near as possible to zero? [fix =///.] 
(Lond. Dip.) 
31. The height h of a vertical tower whose base is at a horizontal distance 
500 m from the point of observation is determined by measuring E the 
angle of elevation of the top of the tower. If the measurement of E is 
distributed with standard deviation 0.1 � about the mean value 3'6 �, find 
approximations to the mean and standard deviation of the value obtained 
for h. 
32. x has probability density 
1 
n- x" e% 
for x > 0, 
(Camb. N.S.) 
and zero otherwise. Show that x/x has a standard deviation which, to a 
first approximation, does not depend on n, and determine its value. 
(Camb. N.S.) 
33. The co-ordinates x, y of a point whose true position is P are measured 
  respectively, the estimated position being P'. Show 
with variances %, % 
' + try, whether or 
that the mean of the square of the radial error PP' is % 
not the errors in x and y are independent. 
A landmark at P, whose co-ordinates x, y are unknown, is observed by 
radar from two known points, P, P2; the distances PPx and PP2 being 
measured independently with standard deviation rr. If r is small compared 
with PP and PP, show that the root mean square deviation of the-radial 
error in the estimated position of P is approximately d2rrcosec0, where 
0 is the angle PPP. (It may be assumed that P is known to be on one 
side of PtP, and that 0 is not nearly 180�.) (Camb. N.S.) 
34. The height, h, of a hill' above sea-level is estimated by two observers 
at sea-level independently measuring its angular elevation from two points 
at a known distance, s, apart on the same bearing from the summit. Find 
the approximate variance in h corresponding to small errors in the 
measurements of the angles. If one observer is known to be more accurate 
than the other, which should be placed nearer the hill in order to minimize 
the variance of h ? (Wales Math.) 
35. A sample x, x, ..., x, of independent observations is drawn from 
a population in which x is distributed normally with zero mean value and 
standard deviation tr. Find the mean and variance of Ix I and xL 
Deduce that 
has mean value  and variance V = (�tr- 1)o''/n, and that s =  (x,/n) 
k=l 
has mean value or"and variance 2cr4/n. (Camb. N.S.) 
168 PROBABILITY DISTRIBUTIONS 
36. Neutrinos are emitted from an atomic pile independently and at 
random at an average rate of one per unit time. If x is the interval between 
the first and the second and y is the interval between the second and the 
third, find the joint probability density of u and v, where u = d(xy) and 
v = d(y/x). Find the probability density of L, and express that of u in terms 
of K0(2u), where 
Ko(z) is fe-c,,,hoao. (Camb. N.S.) 
37. Two resistors are each to be constructed by connecting in series ten 
coils of wire chosen at random from a large collection of coils in which the 
electrical resistance is a normal variate with a standard deviation of 
0.1 ohm. Find the probability that the completed resistors will differ in 
resistance by more than 1 ohm. (Camb. N.S.) 
38. If x and y are two correlated normal variables whose joint probability 
distribution is given by 
1 1 (x  - 2pxy + yZ) dx dy, 
dF = 2rro.2/(1 _p) exp F 2o'(1-p) 
show that the transformed variates 
u = (x +y)/42, v = (- x + y)//2, 
are uncorrelated. Hence, or otherwise, show that any curve in the x, y 
plane .on which the probability density is constant is an ellipse with 
eccentricity /{2p/(1 + p)}. 
What is the probability that a lair of values (x, y) chosen at random 
will be represented by a point inside the ellipse of constant probability 
density with area A ? (Camb. N.S.) 
39. The variables x and y are distributed independently each according 
to N(0, 1). Show that the joint distribution of X = x ' and Y = y is 
__1 e_Cx+,)X_ Y-dXdY (0  X < c, 0  Y < c). 
2r 
Making the transformation X = U, Y = UV, show that the joint 
distribution of U and V is 
1 
2-- e-kV(x+v)V-dUdV (0  U  0% 0  V  c). 
Deduce that the ratio V = Y/X is distributed as 
1 dV 
(0  V < c). (Camb. N.S.) 
rr (I + V)4V 
40. If xx, x, ..., x are independent N&, o ' variables show that 'the 
variables dn' = (x + x + ... + x,)//n, 
yx = (x- x2)/d2, 
yg = (xx + x- 2x)/d6, 
y,_ = (x + x. + ... - (n - 1) x,)/4[n(n- 1)], 
are also independently and normally distributed with variance o'. 
x�cs�s 169 
Prove that 
Z(x,-/4 = + Zy, 
and hence show that . and Z(xi-,)  are independently distributed 
according to N(/x, o'2/n) and r(�(n-1), 1/2rr ) respectively. 
41. Show that if Xx, x, ..., x, have a multivariate normal distribution 
with dispersion matrix C then the random variables 
Yi = 
also have a multivariate normal distribution with dispersion matrix T'CT, 
where T is the matrix of elements 
In particular show that if the x's are independent and T is orthogonal 
the n the y's are independent. 
42. If xx, x2, ..., xn are independently each distributed as N(0, rr ') show 
that Z x has a I'(�n, 1/2r ) distribution. 
43. The random variables Xx, X., ..., X, are independently normally distri- 
buted with zero mean and unit variance. 
Prove that the density ofZ = X + X-X. - X]is �e -. 
Obtain the cumulants of 
U = Z jX . (Lond. M.Sc.) 
44. Let Xx, X. .... , Xn be independently normally distributed with zero mean 
and unit variance and let Y = X + X + ... + X. Obtain the probability 
density function, mean and variance of log Y. (Lond. M.Sc.) 
45. The random variables Xx, X, ..., X, are independently distributed with 
probability density function 
e � 
(l+e) i (-oo < x < ). 
The random variable X is the ith largest of Xx, ..., -Y, when arranged in 
ascending order of magnitude. Prove that the moment generating function 
of X,), (e'X{>), is equal to 
r(i+s) r(n-i-s+ i) 
r(i) r(n- i+ 1) ' 
Hence, or otherwise, show that for i-1 > n-i 
i-x 1 
$(X(i)) = Y (Lond. M.Sc.) 
r=n-i+l ' 
46. The bivariate random variable x =- (xx, x) has probability density 
function 
p(x) = Ke-lO (-oo < x < 0% -oo < x < oo), 
with Q = (x- ) A(x'- ['), 
170 PROBABILITY DISTRIBUTIONS 
where . -- (/xx,/x2) is a vector of constants, A is a symmetric positive 
definite 2 x 2 matrix and K is a constant. Find the characteristic function 
of x and hence or otherwise evaluate K and A in terms of the second-order 
moments ofx. Prove that �Q is exponentially distributed. If 
is a sample of n random and independent observations of x and if R is the 
largest of the n corresponding values of �Q find the characteristic function 
of R and hence or otherwise show 
1 1 r  
{R} = 1++ ... +-, 2{R} = (Lond. Dip.) 
n -' 
47. The random variables Xx, Xg, Xa are independently distributed with 
probability density function 
A e -^ (x > 0), 
0 (x < 0). 
Show that their range w has density 
2,e-^�(1-e -) (w > 0), 
0 (w < 0). 
Hence show that the ratio of the mean range to the standard deviation of 
the X's, which may be taken.without proof to be l/A, is 3/2. 
(,Lond. B.Sc.) 
48. X and Y are normally and independently distributed with zero mean 
and tinit variance, and 
Z = pX+/(l--p ) Y. 
Show that the joint density of X and Z is a bivariate normal distribution 
with correlation coefficient p. Hence explain how, given an ordinary table 
of random digits, you would construct a random sample of observations 
from the bivariate normal distribution with zero means, unit standard 
deviations and correlation coefficient 0.6. (Lond. B.Sc.) 
49. A random variable X is equally likely to assume any value in the 
interval 0 to 0 and cannot be outside this interval. A sample of n indepen- 
dent values of X are available, of which Xa) is the lowest and X(n) the 
highest. Show that the joint probability density function of Xa) and 
X(. is 
f(xx, xD = n(n-1) (x-xx)-/O  (0 < xx < x, < 0). 
Hence, or otherwise, show that if W = Xt,)- Xa) is the sample range, 
its density is 
0,_  1- (0 < w < 0). (Lond. B.Sc.) 
50. Metal bars have flaws distributed randomly along their length at rate 
A, i.e. the probability that there is a flaw between (x, x+ 8x), where x is 
very small, is h Sx independently of the positions of other flaws. Prove 
that the probability that a rod of length l contains no flaws is e -t. 
EXERCISES 171 
Conditionally on there being no flaws, the strength of a rod is distributed 
with mean/t0 and variance tr0 . Conditionally on there being one or more' 
flaws, the strength is distributed with mean/q and variance cr. Prove that 
the mean and variance of strength are respectively 
/to e - +/t(1 - e -;u) 
and tr} e - + ty(l - e -xz) + (/q -/to) 2 e-aZ(1 - e-At). 
(Lond. B.Sc.) 
Show that if x and x2 are independently and uniformly distributed 
51. 
over the interval a to b, then the probability density function of u = x + 
is given by 
fu(u) = 0 for u< 2aoru> 2b 
u- 2a 
- for 2a< u < a+b 
(b - a) 2 
2b- u 
= for a+b< u< 2b. 
(b- a) 2 
52. The length ,,lB has an exponential distribution with parameter �. 
Let O be the mid-point of ,4B and let C be the intersection of a randomly 
drawn line from O with the semicircle on/lB with centre O. Show that 
if D is the projection of C on ,4B, then ,4D and DB are independently 
distributed with C-distributions, and that if we put 
z = + (AD).t with probability -t2, 
= -(AD) with probability �, 
then z has a standardized normal distribution. 
53. Show that the minimum of k independent exponential random 'vari- 
ables with parameter ,t. is itself exponential with parameter k,. 
54. Let T, T .... be the winning times recorded in successive years for 
a certain athletic event. T is the 'first record' iF T is the smallest of 
Tx, ..., T and T t is the next-smallest. Assuming that the r.v.'s T are 
independently and identically distributed and p(T = T) -- 0 for i 4: j, 
show that 
(i) p(k .>-> ko) = 1/(k0-1), 
(ii) g(k) is infinite. 
55. A random variable has distribution function F(x). Show that the 
largest of n independent observations has distribution function F"(x), and 
hence derive also the density function (if this exists). 
Three independent observations are taken when the density is 
- exp (-Ixl) for all x. 
What is the expected value of the largest observation in this case? 
56. A pair of random variables is said to have a circular distribution if 
their joint probability density f(x, y) depends only on x2+y ". Show that 
the joint characteristic function �(t, u) of such a pair depends only on 
t+u '-. 
172 PROBABILITY DISTRIBUTIONS 
Hence, or otherwise, show that, if a pair of independent random 
variables has a circular distribution, then they must be norlnally distri- 
buted with zero means and equal variances. (Camb. Trip.) 
57. The random variables x, x2, ..., x, have a multivariate normal distri- 
bution with zero means and dispersion matrix V. If x is the row- 
vector (x, x2, ..., xn), prove that two linear forms a'x and b'x are in- 
dependent iff a'Vb = 0. (Camb. Trip.) 
58. The variables x, x, xa are each N(0, 1) and independent. Show that 
r = (x + xo  + 2 x/r are independently distributed, and that u is 
xa)r and u = 
equally likely to lie anywhere in the interval - 1  u  1. (Camb. N.S.) 
59. The random variables Xx, X, ... have mean zero, equal finite variance 
 and the correlation coefficient between  and X+ is p (for all i) and 
zero for all other pairs of variables. State and prove the weak law of large 
numbers for (Xx + ... + X)/n. (Lond. Dip.) 
60. Let x, x, ..., x be independent random variables each assuming the 
values 0, 1, 2, ..., a-1 with probabilities 1/a. Let s = x+ ... +x. 
Show that the probability generating function of s is 
T 
- 
and hence that 
p(s, = j) = a . , 
ro J- ar 
where only finitely many terms in the sum are different from zero. 
61. Let Z (j = 0, 1, 2, ...)be a sequence of independent random variables 
which take only the values 0 and 1. Let the probability that Zs takes the 
value 1 be Ps. If Z ps verges, show that there is probability 1 that 
0 
 Z diverges. What happens when Z p converges ? 
(Camb. 
62. A certain te of plant lives for precisely one year. Each autunm it 
produces seeds, the plants from which produce seed in the following 
autumn. 
If F,(x) is the probability generating function for the number of rth 
generation descendants of a given plant, show that 
= F,(F.(x)) 
for any integers r > 0, s > 0. 
Let G,(x) be the probability generating function for the total number of 
descendants of a given plant of at most the rth generation, excluding the 
original plant. Show that 
W(x) = F(x), 
and G,+(x) = F(xW,(x)} 
for any integer $  1. 
EXERCISES 173 
Let the expectation and variance of the number of first-generation 
descendants be k and v, respectively. Show that the expectation of the 
total number of descendants of a given plant is finite if and only if k < 1, 
and that then the variance is v/(1- k) a. (Camb. Trip.) 
63. If an animal has a chance p of being female and q of being male 
(where p+q = 1), independent of other animals in the litter, find the 
probability of being able to make at least one mating of a male and a 
female from a litter of s animals. If, for s > 1, the probability of getting 
a litter of size s is proportional to the sth term of the Poisson series, prove 
that the proportion of litters from which matings can be made is 
(1 - e -�m) (1 - e-a")/(1 - e-"9, 
where m is the mean litter size. 
174 
4 
STOCHASTIC 
PROCESSES 
The definitions and theorems of the first three chapters are here 
applied to the study of processes developing in time according 
to probabilistic laws. Two such stochastic processes have already 
been introduced: the Poisson process (�2.3) and the Random 
Walk (�2.5); and the results for these are basic in the study of 
the more elaborate processes of this chapter. In the first three 
sections particular processes are discussed and serve to introduce 
several important ideas. In the fourth section a branch of theory 
is developed and applied to a special type of process in the 
remaining two sections. The material of this chapter is not used 
in the remainder of the book. Readers interested in statistics 
may proceed directly to chapter 5. 
4.1. Immigration-emigration process 
It is convenient to prove here a result, the sufficiency part of 
which we shall need in this section. The necessity part will be 
used in �4.3. 
Theorem 1. If x is a positive random variable with p(x > t) > 0 
for all t, then the necessary and sufficient condition that 
p(x 4 t+ulx > t) 
does not depend on t,for any positive u, is that x has an exponential 
distribution. 
The conditional probability may be written in terms of 
S(t) = p(x > t), 
p(x < t+ulx > t)=p(t < x < t+u)=p(x > t)-p(x > t+u) 
p(x > t) p(x > t) 
= (G(t)- G(t + u)}/(t). 
This is to depend only on u, so we may write it H(u), say. Then 
G(t)-G(t + u) = G(t) H(u). 
4.1] IMMIGRATION--EMIGRATION PROCESS 175 
If t = 0, G(0) = 1, since the random variable is positive. Hence 
1-G(u) = H(u) and, eliminating HO0, 
G(t)-G(t +u) = G(t) [1- G(u)], 
or G(t + u) = G(t) G(u), 
whence G(t) = e -Kt for some x > 0 (cf. equation 2.3.1). Since 
G(t) is one minus the distribution function of x, the result is 
proved. 
Consider a Poisson process of rate/l in which the incidents 
are arrivals of particles in a region. A particle stays in the region 
for a time t, which is a random variable with an exponential 
distribution of parameter to, E(K). The times of stay for different 
particles are independent and independent of the incoming 
Poisson process. We wish to study the distribution of the 
number of particles in the region and how it changes with time. 
If x is the time of stay in the region of a particle, the probability 
studied in theorem 1 is the probability that the particle will leave 
in (t, t + u) given that it was there at time t. Since x is E(K), the 
sufficiency part of the theorem shows that this probability does 
not depend on t. In other words, the chance that it will leave in 
an interval of length u does not depend on how long it has been 
there. The theorem allows us to complete the specification of 
the immigration-emigration process by supposing that at the 
start, t = 0, there were N particles in the region--it is not 
necessary to say how long these N particles had been there. 
The argument used to derive the required distribution of the 
number in the region is based on relating the number at time t 
(thought of as 'now') with the number at t-8t (thought of as 
the immediate 'past') where at is small and ultimately tends to 
zero (cf. example 2.6.3). We saw in �2.3.that the Poisson process 
had the property that the probability of. an incident in any 
interval of length at was/1 at, and of more than one incident was 
small, technically o(at), irrespective of the behaviour prior to 
the interval. Theorem 1 with u = at shows that the probability 
of a departure of a given particle in any interval of length at is 
tc &, and therefore of more than one departure is small, irrespec- 
tive of the behaviour prior to the interval. These two facts enable 
the situation at t to be simply related to that at t-at. 
176 STOCHASTIC 'ROC.SS.S [4.1 
If there are n particles in the region the probability that an 
unspecified one of them will leave in 8t is, by the binomial 
distribution and the independence of the particles, 
(t;) x6t(1-xSt) '*- = nxt, 
ignoring terms that are o(3t), as we will throughout the rest of 
the argument. 
If there are n particles in the region at time t, then the position 
at time t-3t could have been: 
(i) (n-1) in the region and one arrived in (t-&, t): the 
arrival is an event of probability ,3t (if n = 0 this possibility 
can be ignored). 
(ii) (n + 1) in the region and one left in (t- 3t, t): the departure 
is an event of probability (n + 1)x St by the argument at the 
top of the page. 
(iii) n in the region and none left nor arrived in (t-3t, t): the 
latter event has probability 1 - , t - nx St, since the probabilities 
must add to one. All other possibilities have probabilities 0(8 0 
which can be ignored. Hence. if 
/(t) = p(n in region at tin in region at t = 0) 
the generalized addition law gives 
p,,(t) = p,_t(t-St) ASt +p,,+x(t-St) (n+ 1) tc0t 
+p,,(t-at) (1-Aat-n,cat). (1) 
This holds for n > 0: if n = 0 it is still true provided p_(t- 
is treated as zero. Subtract p,,(t-at) from both sides of (1) so 
that the right-hand side contains only terms of order St, divide 
throughout by 8t and let 8t -> 0: the result is 
dp,,(t)/dt = p,_(t)+x(n+ 1)p,,+t(t)-(X+nx)p,,(t). (2) 
This equation is most easily solved by using the probability 
generating function ({}2.6) of n for fixed t, namely 
oo 
II(x, t) = Y p,,(t)x'* 
(cf. example 2.6.3). A differentiation of (3) gives 
alI(x, O/Ox = 7E np,,(t)x '*-, 
(3) 
(4) 
4.1] IMMIGRATION-EMIGRATION PROCESS 177 
so that if (2) is multiplied by x  and summed over all n the 
result is 
an/or = ;t(x- 1)n-K(x- 1)an/Ox. (5) 
This is a partial differential equation of a standard type and may 
be solved by the usual methods, but a simpler solution is 
provided by the substitutions of 
and 
for t and x. Then 
0ii 
0t 
011 
and - 
s = (x- 1)e -Kt} 
z = ;tx/K 
Oil Ox 0II Oz 
OI-I Os OH Oz 
Os ax az Ox 
- c(x- Ue- -[ 
_ e-: tOil Jr A Oil I 
as 
(6) 
(7) 
(8) 
The form of (I) must be determined by the boundary conditions 
at t = 0, when we know there were Nparticles, so thatp2v(0) = 1 
and II(x, 0) = x v. Substituting t = 0 and this result in (8) gives 
x v = e xx/ (I)(x- 1), 
hence, with y = x- 1, q)(y) = (1 +y)e -m+v)l and finally 
II(x, t) = {l +(x--1)e-Kt}2V exp {(x--1) (1--e-K9}. 
(9) 
It is convenient to denote the number of particles in the region 
at time t by n(t), so that n(0) = N; and the result just proved 
can be expressed as 
Theorem 2. In an immigration-emigration process the distribu- 
tion of n(t), given n(O) = N, has probability generating function 
given by (9). 
Since a probability generating function characterizes a distri- 
bution, this result solves the problem of determining the 
distribution of the number at any time instant, and any features 
'II(x, t) = e ax/K O{(x- 1)e-t}. 
so that (5) becomes simply II = OII/Oz of which the solution is 
obviously II(s, z) = e*q)(s), where (I) is an arbitrary function. 
Consequently, in the original arguments, t and x, 
178 STOCHASTIC PROCESSES [4.1 
of the distribution such as means and variances can be found 
(see below). The joint distribution at several time points is also 
discussed below. 
Consider next th behaviour of (9) as t-> c, that is a long 
time from the start. Since tc > 0, lim II(x, t) = II(x), say, 
exists and 
H(x)= exp {-Xx(x- 1)}, (10) 
which is (equation 2.6.11), the probability generating function 
of a Poisson distribution of parameter //x, P(,/c). The same 
distribution can also be produced as a non-limiting result. Sup- 
pose n(0) has the distribution corresponding to (10), that is 
P(/l/x). Then (9) is the probability generating function of n(t) for 
fixed n(0) = N and theorem 3.1.1 shows that the unconditional 
probability generating function of n(t) is 
51 {1 + (x-1)e-t}Sexp { (x-1)(1-e-t)} e-X/(,/x)N/N! 
N 
=exp{(x-1)(1 e-Kt)7}t  7c(x- 
= exp {(x-1)}, 
which is (10) again. We therefore have 
Theorem $. In an immigration-emigration process the probability 
distribution of n(t) tends, as t -+ co, to P(//c), irrespective of the 
initial conditions. If the distribution of n(O) is P(//x) then so is 
the unconditional distribution of n(t) for all t. 
For any stochastic process, {n(t)}, a distribution of n(t) which 
does not change with t is called a stationary, or equilibrium 
distribution. Here P(,/x) is such a distribution. It can be found 
directly, assuming it to exist, without calculating the conditional 
distribution (9), by allowing t to tend to infinity in (2). If 
lim p(t) = p 
exists it must satisfy 
()t+n,r)pn = ,pn_x +x(n+ 1)pn+, (11) 
which may be solved in a variety of ways: perhaps the best is by 
4.1] IMMIGRATION-EMIGRATION PROCESS 179 
generating functions again, which leads to (5) with all/at = O, 
that is to 'AH = tcdH/dx (12) 
with (10) as the obvious solution with boundary condition 
n(1) = 1. 
The exponential distribution 
Theorem 1 has many uses besides the specific one made here. 
Consider a process of incidents, that is a process with the same 
sample space as a' Poisson. process (�2.3), with probabilities 
defined as follows: the intervals between successive incidents are 
independent random variables with a common exponential 
distribution of parameter x. Then theorem 1 says that the prob- 
ability of an incident in any interval (t, t+ 8 0 is tcSt+o(St), 
independent of how long it was since the last incident occurred. 
Furthermore, since the intervals between earlier incidents are 
also independent of the interval between incidents in which 
t occurs, the probability of an incident in (t, t + 8 0 is independent 
of whatever incidents took place prior to t. Hence the process so 
described is a Poisson process. Theorem 1 therefore provides 
another means of defining a Poisson process and is a sort of 
converse to theorem 2.3.2. 
Examples of immigration-emigration processes 
The immigration-emigration process was first studied in con- 
nexion with telephone engineering by Erlang (see Brockmeyer 
et alii 1948). The necessary change of language is that the regi_'on 
is a telephone exchange, the particles are subscribers and staying 
in the region means making a call. The model assumes that the 
demands for service form a Poisson process, which is reasonable, 
that the durations of calls have an exponential distribution, 
which is often unreasonable, and that the exchange can cope 
with any number of calls. The final assumption is clearly not 
true and the effect of delays due to the exchange being saturated 
will be considered under queueing processes (��4.2, 4.3). Other 
applications are: (i) The motion of particles in a region, in the 
language we have used, though many particles move in a way 
that contradicts the exponential stay assumption. (ii) The size 
180 STOCHASTIC PROCESSES [4.1 
of a population of animals, where the possible changes are 
arrivals of new animals (immigration) and their departure (by 
emigration or death). A further factor may be births, causing 
new arrivals, but these would presumably increase in rate the 
larger n(t) was, whereas the arrivals in our model come at a 
constant rate. The process can be generalized to a 'birth- 
death-immigration' process by adding extra terms to (1). 
(iii) The thickness and strength of yarns. In this application the 
former time variable is spatial, being the distance along the 
thread, the arrival is the left-hand end-point of a fibre, the 
departure is the right-hand end-point. The number of particles 
in a region is the number of fibres in a cross-section of the thread. 
The fibres occur at random along the thread length and have 
an exponential distribution of length: both quite reasonable 
assumptions for some fibres, such as jute. 
Use of the generalized addition law 
There are some details in the derivation o (1) that are worth 
attention. The generalized addition law (theorem 1.4.4) is used 
with all probabilities conditional on the event n(0) -- N: in full 
it is 
p[n(t) = n[n(0) = N] 
= Y,p[n(t) = n[n(t-St) = s and n(0) = N] 
$=0 
xp[n(t-St) = sin(0 ) = NI, (13) 
since the events 'n(t-8t) = s' for different s are exclusive and 
exhaustive. Now, because of theorem 1, and the independence 
of the different particles, the behaviour of the process in the 
interval (t-St, t) depends only on n(t-8 0, the number present 
at the beginning of the interval. Hence 
p[n(t) = nln(t-Ot ) = s and n(0) = N] 
= p[n(t) = nln(t-8t) = s], 
(14) 
and all these probabilities are o(at) except when s = n- 1, n or 
n + 1. When  = n-1, the transition can take place by one 
particle arriving and none leaving. The arrival has probability 
,Ot. The probability of no departure for any one particle is 
e -t= 1-cSt to this order, and hence for (n-1) particles 
4.1] IMMIGRATION-EMIGRATION PROCESS 181 
(1-xSt)- = 1-x(n-1)St to this order. These probabilities 
are independent so this transition has probability 
,k&t{1--K(11-- DOt} = 
to this order. Notice the way in which one event of probability 
of order Ot (here ,10t) effectively means that the other events 
(departures) need not be considered. The transition can also 
take place by two arriving and one leaving but, as is easily seen, 
this is o(St). When s = n + 1 the only transition that matters is 
one departure and no arrivals. A departure has probability 
(n + 1) cOt, by the independence of the particles, and hence the 
arrival probability (in fact 1-ROt) need not be considered. 
With s = n the major probability is of no arrivals or departures, 
namely (1-,k&t) (1-nxOt) = 1-AOt-nxSt. Hence (1) follows 
to order St. The passage from (1) to (2) is carried out by col- 
lecting together terms of like order and then passing to the limit 
as at-> 0. The resulting differential-difference equation is then 
turned into a partial difference equation by the use of generating 
functions. These procedures are of wide applicability. 
Use of the probability generating function 
From (9) it is possible to calculate any desired feature of the 
distribution: for example, expansion in a power series in x will 
give the probabilities p(n(t) = n ln(0) = N). If x = e z a similar 
expansion in terms of z yields the moments about the origin 
(equation 2.6.4). The same expansion of ln lI(e z, t) gives the 
cumulants (equation 2.6.7). For example, let us evaluate the 
coefficient of z in the last expansion: that is, tq, the mean, 
obtained by differentiating In II(e , t) once with respect to z and 
putting z = 0. Now 
so 
or {n(t) l n(O)} = (,k/g) (1 -e -Ke) + e -Kt n(O), 
and the regression of n(t) on n(0) is linear with 
coefficient e -t (�3.1). A slight rewriting of (16) as 
lnlI(e5 t) = Nln{1 +(e *- 1)e-'e} + (A/c) (e - 1) (1-e-t), 
{01nlI(e *, t)/Oz}z=o = Ne-e+(A/tc) (1-e-t), (15) 
(16) 
regression 
e-Ke{n(O) - A/x} + 
182 STOCHASTIC PROCESSES [4.1 
shows that if n(0) > A/x: that is, if the number at the beginning 
exceeds the expected number as t -> co (the mean of the limiting 
Poisson distribution), then the expected number at t exceeds ,/tc. 
In words: an above-average number at the beginning leads one 
to expect an excess above average at any later time. The effect 
diminishes sharply with time due to the exponential factor e -'it. 
Limiting distribution 
The limiting distribution as t -> co is important. It means that 
if the process is considered a long way from the start the distri- 
bution of n(t) will be of the simple Poisson form instead of the 
complicated form in (9) and, moreover, will not depend on the 
conditions at the start. It is not the number in the region that 
tends to a limit, indeed it fluctuates up and down, but the 
distribution of the'number. The proof requires the use of 
theorem 3.6.4 to show that the limit of the distribution is 
implied by the limit of the generating function: we have only 
to put x = e it in (9) to apply that result. 
It is natural to ask what happens if the process starts in the 
limiting situation. In analogy with limits of iterative sequences 
one would expect it to stay there; for example, in the usual 
numerical process for finding the square root of a number c, 
where a sequence {a,} is defined by a,, = �(a,_x + c/a,_O, with an 
arbitrary start a0, and lima,, = /c; .,'a0 = /c then an = /c 
for all n. The calculations show that this is true here, if the 
process starts with P(,/x) it remains at this distribution. This 
means that in processes with this property it is often possible to 
ignore any 'start', because it is the same as any other point of 
time, and think of the processes for all time. The distribution at 
any time will be Poisson, and the conditional distribution at any 
two points of time separated by an interval of length t will be 
given by (9). Such processes are called stationary and will be 
formally defined below. Notic e that the stationarity refers to 
the distributions of the process at different time points, and not 
to the values of the process itself. In fig. 4.1.1 (a-c) we show 
graphs of n(t) against t obtained in samples from processes 
with different values of g. and to. They were obtained by taking 
4.1] IMMIGRATION-EMIGRATION PROCESS 183 
the intervals between arrivals to be random samples from an 
exponential distribution with parameter//, and the times of stay 
of each particle to be the same with parameter x, in the manner 
o 
o I 
m 
3- 
2- 
1- 
O, 
0 
12 
11 
10 
9 
8 
7 
6 
5 
4 
3 
2 
1 
0 
2 3 4 
i I 
I ff ! 
5 6 7 8 9 10 
(a) 
II I i I i 
i I 
I 
I! I I I 
I 2 3 4 
I I I 
I I I I I 
5 6 7 8 9 
(b) 
i 
II 
I 
lO 
I i I 
I I 
I 
-, p...I 
, i ,'l, 
.I I I I.....I 
I 
I"1 n In Pin 
I I II II Im 
i  i 
I I II II 
II 
m 
I I I I I I I I I I t 
0 2 4 6 8 10 12 14 16 18 20 
(C) 
Fig. 4A.1 (a-c). Realizations of immigration-emigration processes. 
described in �3.5. With the arrivals and departures so recorded 
and a random sample from P(A/K) to start the process, the 
numbers in the region at each point of time can be found. Such 
graphs are called sample paths or realizations of the process. 
184 STOCHASTIC PROCESSES [4.1 
Often it is enough to consider the stationary behaviour of 
a process and then the distributions may be obtained directly, 
as in (11) above, by ignoring the dependence on time in the 
fundamental equations of the process. However, this argument, 
unlike the full one, does not prove the existence of the limit; it 
merely finds the limit, assuming it to exist. In the case of certain 
Markov chains we shall see that if the stationary distribution 
exists, then it is the lirnit (theorem 4.5.2). Of course, not all 
processes exhibit stationary behaviour. For example, neither 
the Poisson nor Random Walk processes do. In the former the 
number of incidents up to time t continually increases. In the 
latter the variance at least increases without limit so that drifts 
farther and farther from the starting-point become possible. In 
fact if p q= � the mean steadily increases (p > �) or decreases 
(p < -}). This will be further discussed in example 4.4.2. 
Joint distributions 
The joint distribution of n(0) and n(t) is often of interest in. 
the stationary case, when they refer to any two counts distant 
t apart. The joint probability generating function is easily 
obtained from (9) and the Poisson density by using theorem 
3.1.2. We have, if x is the variable corresponding to n(0), and 
y to n(t), the result 
e-X/ n(y, t) 
N=0 
= exp {(y-1) (1 -e-t)} e -x/K 
[5 x ']7 
x Z -- {l +(y-1)e -'t 
=0 
=exp [ {(x-1)+ (y-1)+ (x-1)(y- 
This is the probability generating function of a biariate Poisson 
distribution. From (1 ?) probabilities and moments may be calcu- 
lated as with (9) but the results are not usually simpl. e 
covariance of n(0) and n(t) may easily be found by exploiting the 
fact that the regression of n(O on n(0) is linear with regression 
coeffident e -t, (16). Then the covariance is (equation 3.1.21) 
4.1] IMMIGRATION--EMIGRATION PROCESS 
e-t(A/x) since the variance of n(0) is A/x. The correlation 
between n(0) and n(t) is e -'t, and is called the autocorrelation 
fimction, p(t), of the process. Notice that at t = 0 it is necessarily 
1 and as t increases it diminishes exponentially fast. By use of a 
bivariate form of the limit theorem 3.6.4 it is possible to show 
that as R/x, the expected number of particles in the region, tends 
to infinity, the bivariate Poisson distribution tends to the 
bivariate normal distribution. (In fi3.6 we remarked on the 
corresponding univariate result that the ordinary P(3) distribu- 
tion tended to normality as / .) Consequently, if the 
expected number of particles in a region is large we can say that 
the joint distribution of n(0) and n(t) is approximately bivariate 
normal with means R/x and dispersion matrix 
/x e-/ 
Re-t/x h/x )' (18) 
and consequently the autocorrelation p(t) = e -xt is a good guide 
to the association between n(0) and n(t). Occasionally the joint 
distribution of n(tx), n(t), ..., n(t) in the stationary case is 
required. This is easily obtained and we illustrate with k = 3. 
We have, with tx < t < ta, for the joint density of n(tO, in an 
obvious, abbreviated notation, 
p(n, n, ha) = p(na I n, n) p(n, n) 
= p(o 
= p(na ]n) p(n In0 p(nO. (19) 
The final line follows since the development of the process in the 
interval (t, ta) depends only on n(t) = n and is independent of 
n(t0 = n. This is the Markov property to be discussed in 4.5. 
Since the two conditional distributions  (19) are known from 
(9)--for example, p(na [ n) is obtained with N = n and t = ta- t 
because, due to the stationarity, the origin of time does not 
matter--and p(n0 is Poisson, the joint distribution of the three 
variables is known. A practically useful approbation for 
large X/g is that n(tO, n(t), ..., n(t) are multivariate normal 
with means A/g, variances A/g and the correlation between n(t) 
and n(t) equal to 
e-t-t' = P( l b - ). 
186 STOCHASTIC ,ROCWSSES [4.1 
Stationarity 
We can now give a formal definition of stationarity. Suppose 
that each point of sample space has associated with it a function 
x(t) defined for each t belonging to some set T. That is, each 
elementary event determines a realization, as described above. 
Suppose, further, that for any finite number, n, of values of t, 
tx < t2 < ... < t the joint distribution of x(q), x(t2), ..., x(t,,) is 
defined: thus they form a set of random variables. x(.) is then 
said to be a stochastic process, and it is temporally homogeneous 
if the joint distribution just described, conditional on x(tO, 
depends only on t2-tx, ta-t2, ..., t,-t_x and not on tx. 
A temporally homogeneous process is stationary if the distribu- 
tion of x(t) does not depend on t. T is nearly always either the 
real line, as in this section, or the set of integers, as with the 
random walk. In the latter case we usually write x, instead of 
x(n). All the processes studied in this book are temporally 
homogeneous. This property means that given the value of the 
process at any point of time, tx, then tx may be taken as the 
origin: the future developmeht of the process will not be affected. 
This property clearly obtains for the random walk: given that it 
is at the origin, for example, it does not matter when in time it is 
there, the future development is the same. This would not be 
true, if, for example, the probability of moving to the right at 
the nth step depended on n. Stationarity demands, in addition, 
that the distribution is the same at all points of time. This is not 
true of the random walk, but is true of the immigration- 
emigration process provided the distribution at any one point 
of time is P(A/x). For a stationary process the origin of time is 
completely irrelevant. Many stationary processes exhibit an 
ergodic property (� 3.6). That is, their behaviour may be studied, 
either by considering several realizations at a fixed point of time, 
or by considering a single realization over many points of time, 
with equivalent results. The property will be used 'in later 
sections of this chapter. The term stochastic process is also 
used for the whole sample space and not merely for certain 
random variables associated with it. For example, in the 
next section we study a queueing process for which several 
4.1] IMMIGRATION--EMIGRATION PROCESS 187 
random variables, x(t), are defined: thus, the queue size and 
the waiting-times. 
4.2. Simple queueing process 
Consider a Poisson process of rate A in which the incidents are 
arrivals of' customers' at a' server'. If, when a customer arrives, 
the server is 'free' then he immediately serves the customer for 
a period s called the customer's service-time. If, on the contrary, 
the server is 'busy' with another customer, the customers join 
a queue in order of their times of arrival and as soon as the 
server finishes with one customer he attends to the customer at 
the head of the queue. This 'discipline' in the behaviour of the 
queue is called 'first come, first served'. The service-times are 
independent random variables with a common exponential dis- 
tribution with parameter x, and are independent of the Poisson 
arrival process. This is a simple queueing process with a single 
server. 
Denote by p(t) the probability that at time t there are 
n customers in the queue (including the one being served-). 
This is conditional on the initial conditions at t = 0, the start, 
but we shall only find the limiting stationary distribution as 
t  ca for which, as explained in the previous section, these are 
not relevant. Then the probability that a customer will join the 
queue in an interval of length & is ,3t + o(&), because of the 
Poisson process of arrivals; the probability that a customer will 
leave the queue is cSt + o(&), if n > 0, and is otherwise zero, 
because of the exponential distribution of service-time (theorem 
4.1.1)' and these probabilities are independent of any events that 
concern only the process before the commencement of the small 
interval. Consequently we can write down, using the same 
techniques as were used to obtain equation 4.1.1, for n > 0, 
p,,(t) = p,_(t-t) ASt +p,+(t-St) xSt 
+p,(t-at) (1-,tOt-teSt) (1) 
and, for n = 0, 
p0(t).= pz(t-&)tct+po(t-&)(1-A&). (2) 
p This convention that the queue includes the customer being served will be 
adhered to. 
188 STOCX-IASTXC VXOC.SS.S 
These give, on passage to the limit, Jt--> 0, 
dp,(t)/dt =/1p,,_(t) + xp.,+(t) - (A + to) p,(t), 
forn > 0, and 
dpo(t)/dt = xp(t)- ,tpo(t ). 
(3) 
(4) 
Assuming lim p(t) = p,, to exist, the left-hand sides of the 
equations can be put equal to zero and the argument t omitted 
from the right. Addition of the equations for n = 0, 1, ..., r- 1 
gives xp,. = ;tp.,._, or p = (,k/x)p,._ and 
P = (A/x)  P0. (5) 
This can only be a probability distribution ifp = ,1Ix < 1, when 
P0 must be (1 -p), in order that Zp = 1. Hence a limit can only 
exist if p < 1. It is possible to show that if p < 1 the limit does 
exist and hence we have 
Theoretn 1. A simple queueing process with p < 1 has a stationary 
distribution of queue size given by (5) with Po = 1 -p. 
This distribution is the geometric distribution with para- 
meter p, which we write G(p)  (equation 2.1.10). p is called the 
traffic intensity. Since the mean of an exponential distribution 
of parameter x is x 4 (theorem 2.3.6 with n = 1) the traffic 
intensity is the ratio of the mean service time, x -, to the mean 
of the intervals between arrivals, l -. The mean of G(p) is 
p/(1 - p) (equation 2.1.11), the average size of queue, including 
the customer being served. If he is excluded the average size is 
clearly 
Z (r- 1)pt = (1-p)p2Z(r- 1)p r-2 
= p�(1-p). (6) 
The probability that the server is free is P0 - 1-p. 
Notice that p is the probability that r people are in the queue 
in the stationary distribution. Consider instead the probability 
that when a customer arrives he will find r people in the queue: 
that is p(queue size r at t I arrival in (t, t + 8t)). It is not immedi- 
ately obvious that this is still p, the unconditional probability. 
To see that it is, we need only remark that the event, A, of an 
arrival is independent of the event, B, that the queue size is r, 
4.2] SIMPLE QUEUEINO PROCESS 189 
because the latter depends on arrivals prior to t, and A is 
independent of these arrivals by the definition of a Poisson 
process. The independence of events A and B means 
p(B I A ) = p(.e) 
and hence the conditional probability is p,.. With this remark it is 
easy to find the distribution of queueing-time of a customer' 
that is, the time q between arrival and completion of service. 
Letf(q) be the density of q andf(q r) the density of q conditional 
on r customers being in the queue when the customer arrives. 
Then by the remark and a discrete variable' form of equation 
3.2.7 0, 
f(q) -- 25 f(q l r)P,.. (7) 
Butf(qlr ) is easily found' the customer has to queue during the 
remaining service-time of the customer being served when he 
arrives and during r other complete service-times (including his 
own). By theorem 4.1.1 the remaining service-time still has an 
exponential distribution of parameter x. By theorem 2.3.5 the 
sum of (r + 1) independent service-times has a F(r + 1, to) distri- 
bution, so f(qlr) has that density. Finally, inserting the explicit 
form for the F-density, 
f(q) =  e-qxr+qrp(1-p)/r! 
'=0 
= to(1 -p) e-m-)% (8) 
an exponential distribution of parameter x(1-p). Hence 
Theorem 2. The distribution of queueing-time in a simple queueing 
process is exponential with parameter x(1-p). 
Examples of simple queueing processes 
The simple queueing process was also first studied by Erlang 
in telephone engineering. In the language appropriate to that 
application, the difference between this process and the immi- 
gration-emigration process of the last section is that, in the 
' We are here 'discussing certain properties of the joint distribution of a 
continuous random variable, q, and a discrete one, r. Compare the proof of 
theorem 2.3.3. 
190 STOCHASTIC }'aOCV. SS�S [4.2 
latter, requests for a connexion were supposed always met im- 
mediately, whereas in this process there is supposed only one 
line at the exchange and the callers wait in order of arrival for 
their connexion. The extension to the case of n > 1 lines at the 
exchange presents no difficulties beyond complexity of algebra. 
But queues occur in many other situations: aircraft waiting to 
land at an airport, ships waiting to enter a port, machines 
waiting to be repaired, patients waiting to see a doctor, and 
many others. The simple queueing process discussed here makes 
assumptions that may well not be satisfied in some applications. 
For example, aircraft run to schedules and would not arrive in 
a Poisson process; the theory based' on the exponential service- 
time distribution is unlikely to be useful when unloading ships. 
Nevertheless, the theory has found a wide range of applications. 
Existence of a stationary distribution 
The method of deriving the basic equations (1) and (2), is the 
same as before (�4.1). Their general solution is complicated so 
we pass instead directly to the stationary case where the equa- 
tions are almost trivial. Contrary to the immigration-emigration 
process these equations do not always have a probability solu- 
tion, that is a solution with Pr > 0 and Zp,. = 1. The geometric 
series only converges when A/to < 1. Then the solution is as 
stated. We do not prove that the limit is attained, nor do we 
investigate the case of p > 1. The practical situation with p > 1 
is that very large queues build up and p(t)-> 0 as t-> c for 
each n. Thus the value p = 1 is critical, the behaviour on one 
side of it being quite different from the other side. In the 
language to be developed in ��4.4 and 4.5 in connexion with 
slightly different processes the state 'queue size n' is transient if 
p > 1, null if p = 1, and ergodic ff p < 1. The interpretation 
of p, the traff�c intensity (usually measured in units called 
erlangs), given above as 
mean service-time 
mean inter-arrival time 
shows why p -- 1 is critical. If p > 1 then in an average service- 
time (the time wkich one customer takes to be attended to) more 
4.2] SIMPLE QUEUEING PROCESS 191 
than one customer will arrive: the server cannot cope with the 
demands and large queues will build up. On the other hand, if 
p < 1 fewer than one customer will arrive and the server will 
have some leisure, known as slack periods. The probability of 
his being slack is 1-p, when the queue size is zero, the most 
probable size of queue. The expected queue size is p/(1-p) 
which increases sharply as p--> 1. Hospital authorities appear 
to work with p very near 1 in order that the doctor never be 
kept waiting (P0 = 1-p). This causes large queues since the 
mean is/9/(1-p). Any reasonable system should keep p away 
from 1 even though the server will have some slack periods. 
Queueing-time 
From the customer's point of view the important thing is the 
queueing-time. How long is it going to take him to get through 
the system ? The answer, equation (8), is encouraging in that the 
shorter times are the more frequent because of the exponential 
distribution. The expected queueing-time is {c(1-p)}- also 
increasing sharply as p approaches 1. The waiting-time, w, 
defined as the time between arrival and being served, is some- 
time more important women choosing a dress do not mind 
a long service time but they do not like to be kept waiting and 
is interesting because the distribution function is a mixture of 
discrete and continuous parts (�2.2). The probability of finding 
the server free on arrival is, by the remark above, P0 -- 1 -p. 
So the probability that w = 0 is 1 -p. If the server is not free 
and r ( > 0) customers are in the queue, then the customer will 
have to wait through r service-times and by the same argument 
that produced (8) the distribution will have density for w > 0 
top(1 - p) e-m-p >�. (9) 
The distribution function of w is therefore 
F(w) = o (w < 0); } 
F(w) = (1 - p) + p(1 - e -m-p)) (w > 0); (lO) 
with a discontinuity, equal to (1-p), at w = O. The expected 
waiting-time is p/c(1 - p). 
192 STOCHASTIC PROCESSES [4.2 
Ergodicity 
The probability that the server is free (in the stationary distri- 
bution) is P0 -- 1 - p. This means that if the process is started at 
t = 0 with any number of customers present, then, a long time, t, 
after the start, the probability that the server will be free is 1 -p; 
or, in practical terms, if the process is started up a large number 
of times the frequency of times the server will be found free at t 
is about 1 -p. But the probability has another practical interpre- 
tation in terms of a single realization; namely, over a long time 
interval of length t the amount of time that the server will be 
free will be about (1 -p)t. We shall not prove this result, but it 
is of considerable importance and is another example of an 
ergodic theorem (� 3.6). The point is discussed in connexion with 
recurrent events in �4.4. The first interpretation is.a spatial 
average and the second a temporal average. Similar temporal 
interpretations are available for the other probabilities. 
Busy periods 
The ergodic principle can Cften be used to find probabilities 
or expectations. The slack periods of the server have already 
been mentioned: these alternate in time with busy periods during 
which the server is continuously occupied. Now the probability 
distribution of the length of slack period is clearly E(A), because 
of the Poisson process of arrivals; and in particular the expected 
length of a slack period is A-L Now consider a single realization 
with its alternation of busy and slack periods of lengths 
b, s, b., s., .... By the strong law of large numberst (theorem 
3.6.3 an ergodic result), 
lim sin = A-L 
By the ergodic result just mentioned, 
 & = po/(1-Po) = (1-p)/p. 
Hence m(b/n) =p/[(1-p)A]=(x-X) - 
? All the results in the rest of this paragraph require the qualification ' 
probability one'. 
with 
4.2] sm,t.E QUEUEINO PROCESS 193 
and by a final ergodic result, the converse of the strong law, 
o(b) = (to-h)-:, the expected length of a busy period. Notice 
that it tends to infinity as p--> 1 for fixed x. More elaborate 
methods are needed to find the density of the busy period 
distribution. The expected number served in a busy period is 
discussed in {}4.3. 
4.3. Queueing process with Poisson input and general service 
distribution 
Consider a stochastic process defined as in the last section 
except that the service times are independent random variables 
with a common distribution, independent of the Poisson arrival 
process. The simple queueing process is the special case where 
the distribution of service-times is 
Consider the probability that a departing customer leaves 
behind him a queue ofj customers, conditional on the event that 
the previous customer left behind him a queue of i customers: 
here i and j are non-negative and since the change from i to j 
depends only on the Poisson arrivals in between the two 
customers' departures, the probability will not depend on 
the particular customer (nor on t) and may simply be denoted 
by Po. We derive an expression for Po in terms of known 
quantities. Consider firstp0j. The customer leavingj behind him 
must have arrived and found the server free, since the previous 
customer left him so, and hence thesej must have arrived during 
this customer's service-time. Consequently 
Po = p(jcustomers arrive during one customer's service-time) 
= Op(j customers arrivelservice-time is x)f(x)dx, (1) 
wheref (x) is the given density of service-times. (If the distribu- 
tion is discrete a summation, 5;, replaces the integration in (1), 
and Pr replacesf(x).) This is again a consequence of the general- 
ized addition law in its integral form (equation 3.2.7). The 
probability of j given x is P(/x) (theorem 2.3.3), so that 
Po =  e-XX(hx) f(x)dx/j! = rt, say. 
(2) 
!. 'STO CI-IASTI'C PROCESSES [4.3 
Similarly, when i 4: 0, Pij = P(J-i+ 1 customers arrive during 
one customer's service-time) since when i (> 0) customers-are 
left behind (i- 1) are still there when the next customer leaves, 
so j-(i-1) must have arrived to bring the number up to j. 
Hence, if i 4= 0, 
Po = r0-i+ ff J >i-l; otherwisepo = 0. (3) 
Now let p(s) be the probability that the customer number s 
leaves a queue of n behind him when he leaves; the customers 
being supposed numbered in order of their arrival and this 
probability, unlike Po', being unconditional. The process may be 
supl0sed to start with no one in the queue, but since we shall 
only find the stationar9 distribution, the initial conditions do not 
matter. To find the equilibrium value of pS), p, = lim p), we 
$--> 
proceqd using the same-method as in ��4.1 and 4.2, except that 
instead of relating the state of the process now, at time t, with 
the state in the past, at time t - St, we relate the state now, as the 
sth customer leaves, with the state in the past when the (s- 1)st 
customer left. By the original form of the generalized addition 
law o 
p?) = x'. ,.-x)n.. (j >.>. 0), (4) 
=0 
and hence in equilibrium, where the dependence on s is omitted, 
P = ZPiP.o' = (Po+PO%'+P,.%-x+ ... +P+xrro. (5) 
This difference equation is more complicated than the trivial one 
for the simple queue and is most easily solved using probability 
generating functions. Introduce two of these, noting that the rr's 
form a probabihty distribution, 
P(x) = 52 pjx and H(x) = 52 %x ', (6) 
0 0 
multiply equation (5) by x and sum over j ?rom zero to infinity. 
The result is 
P(x) = II(x) [P0 +Px +p.x +pax" + ...l 
= [p0(x- 1)+P(x)] n(x)/x, 
whence P(x) II(x) (x- 1)_ 
= 2 (.5 /0. (7) 
4.3] QUEUEING PROCESS WITH POISSON INPUT 195 
Now II(x) is known; in fact from (2) 
= e-XV(Ay)if(y)dy.x/j! 
j=0d0 
- [E (Xxy7/j!]dy 
= f eaV{x-)f(y)dy = [A(x-1)], (8) 
where (z) is the moment generating function (equation 2.6.10) 
of the service-time distribution. Consequently P(x) is known 
apart from the value of P0. But P(x) must be a probabiliW 
generating function and so lira P(x) = 1. The limit of th right- 
hand side of (7) can be found by differentiating the numerator 
and denominator and then considering the limit of the ratio of 
these: this is the same as the original limit. Carrying this out 
we obtain 
lim II'(x) (x- 1) + 
xx 1 - II'(x) II(X)p0, 
and from (8) n(1) = q(0) = 1 and H'(1) = ,t$'(0) = t/tr 
where, as in �4.2, ,:- is the mean of the service-time distribution 
(see equation 2.6.4). Consequently, returning to (7), with 
p = ,t/c 
1 
1- 
 _ppo 
and 
For this to be possible we must have p < 1. 
Po = (l-p). 
(9) 
Hence we have 
Theorem 1. In a queueing process with Poisson input of rate , 
and independent service times having a common distribution with 
moment generating function (z), mean tc - and variance P', the 
equilibrium distribution of the size of queue left by a departing 
customer has, if p = A/to < 1, probability generating function 
px  = P(x) (x- 1) [A(x- 1)] (1-p). (10) 
o = 
In particular Po = 1- p, and the expected queue size is 
{p(2- p) + A2rr2}/2(1 - p). (11) 
196 STOCHASTIC PROCESSES [4.3 
Equation (11) follows on evaluating P'(1): this is most easily 
done by writing (7) in the form 
{x- n(x)) = n(x) (x- 1)p0, 
differentiating twice and putting x = 1. From (8) 
n"(1) = ;20"(0) = ;2(s ) 
(equation 2.6.4), and do(s ) = o''+tc -' (theorem 2.4.1), s being 
the service-time. 
The distribution of queueing-time can now be found. If h(q) 
is its density and p(n I q) is the probability that a departing 
customer leaves behind him a queue of n customers, conditional 
on his queueing-time having been q, then 
p, = f p(nlq) h(q)dq. (12) 
But p(n [q) is the probability that n customers arrive in a time q, 
since all n customers must have arrived whilst the customer just 
departing was queueing: hence it is P(;tq) and the corresponding 
probability generating function is e xtx-> (equation 2.6.11). 
Consequently, if (12) is multiplied by x'* and the equations 
summed over n, we have (compare the argument leading to (8)) 
Theorem 2. In a queueing process of Theorem 1 and p < 1, rbq(z), 
the moment generating function of the queueing-time, is given 
by P(x) = rbq[A(x- 1)]. (13) 
In particular the expected queueing-time is 
(q) = p(2-p)+,ko '' 
2,k(1 -p) ' (14) 
The last result follows on differentiating (13) with respect to x, 
putting x = 1 and using (11). 
The distribution of waiting-time, w, can be found by remarking 
that q = w + s, where w and s are independent: hence 
a,(z) = w�) (z) (15) 
by theorem 3.5.4. In particular o(q) = (w)+ d�(s), so that 
p + - 
oqw) - 2-(1 -' (16) 
4.3] QUEUEING PROCESS WITH POISSON INPUT 197 
Discussion of the proof of theorem 1 
The theory of the simple queueing process is obviously not 
adequate for many applications, and the commonest reason for 
this is that in many situations the service-time distribution is not 
exponential. The theory of the present section holds for any 
distribution, but retains the Poisson input and the queue disci- 
pline of 'first come, first served'. Important special cases were 
discussed by Erlang but the general theory here is due to 
Kendall (1951). The argument used is different from that for the 
simple queue and it is most important to understand why that 
argument fails here. 
Let us follow through the argument of �4.2, retaining the 
same notation but replacing the exponential distribution by a 
We first write down an equation for p.(t) of the 
general one. 
form 
p(t) = Z p,(t-St)p(nlm, 80, (17) 
where p(n[m, $t) is the probability of n at time t conditional on 
m at time t-8t (and only the terms rn - n-1, n and n + 1 are 
not o(St)). This equation is still true in the general situation of 
this section. The next stage in the argument is to insert the 
values of p(n I m, t). Now as before p(nln- 1, (t) = l t + o((t) 
because of the Poisson process of arrivals; but we meet a diffi- 
culty when we come to p(nln+ 1, t). This, apart from terms 
o(t), is the probability that someone will leave the system, 
given that the queue is of size (n + 1). But this is not given us 
directly in the specification of the process. When the service- 
time distribution was exponential we used theorem 4.1.1 to show 
that it was Kt+o(St), irrespective of how long the customer 
had been with the server. Let us see what happens with a 
service-time distribution of general density. The necessity-part 
of theorem 4.1.1 shows that it is only with the exponential 
distribution of service-time that the probability of a departure 
does not depend on how long the customer has been at the 
service point. With any distribution other than exponential 
the probability of a departure in an interval of length t is 
K(to)St+o(St), where to is the length of service already com- 
198 SXOC}IASXIC PROC�SS�S [4.3 
pieted. So what the specification provides is the probability that 
a customer will leave the system, given that he has been with the 
server for a time to; whereas what we want for (17) is the prob- 
ability conditional on the number in the queue. This could be 
found, by using the generalized addition law, in terms of the 
probability r,(t0lt), that, at time t with (n+l) in the queue, 
the customer being served had been with the server for a time 
to: as 
p(n n+ 1,&) -- ' tC(to)Strr(to]t)dto+O(St), (18) 
but rtn(t o I t) is also unknown. Hence this approach fails. Notice 
that it fails, not because (17) is false, but because certain of the 
terms in it are not known. 
The argument used in this section avoids the difficulty by 
considering only the time points when a customer leaves the 
system. Admittedly not quite the same information is obtained; 
the probability distribution of queue size is only found at these 
time points; but this makes little difference in practice. At least 
it enables the distribution 6f queueing-time to be obtained 
(theorem 2). When the queue size is considered at these time 
points the obvious thing to do is to relate one customer's 
departure with the departure of the previous customer, using the 
same type of equation based on the generalized addition law. 
The result is (4) and the awkward �(n I m, St) of (17) are replaced 
by the Po' which can be evaluated as shown in terms of known 
quantities, the %.. But notice, and again this is important, that 
this evaluation is only possible because of the Poisson input to 
the queue. The Poisson process is peculiar in that the probability 
of an arrival does not depend on any knowledge of earlier 
arrivals (see the definition in �2.3). With another input process 
the probability would depend on earlier arrivals and therefore 
the probability, in (1), that j customers arrive in an interval of 
time x, might'depend on the fact that we knew something about 
earlier arrivals; namely, that their pattern was such that the 
customer being served now, arrived to find the server free. Thus 
(1) would still be valid but the conditional probability occurring 
in it would be unknown. We could not use theorem 2.3.3 and 
4.3]' QUEUEING pRO"CESS WITH POISSON INPUT 199 
pass to equation (2). In summary then: the Poisson input and 
exponential service of the simple queue enable certain conditional 
probabilities to be written down and the generalized addition 
law used; when the service-time distribution is general a restric- 
tion to departure points of customers enables a modified form of 
argument to be used but the conditional probabilities need a 
Poisson input before they can be calculated. The problem with 
a more general input will not be discussed in this book. It can, 
however, be reduced to a random walk (��4.5, 4.6). 
Solution of equations for generating functions 
The solution of equation (5) using generating functions is 
a good example of the power of this tool. Notice that II(x) is 
a probability generating function, that is 52 rrj -- 52 Poj = 1. 
The difficulty encountered in (7) of one number, P0, being 
unknown is common. It can sometimes be met by using the 
supplementary result P(1)= 1, as here, but oft0n a more 
sophisticated argument is necessary. IfP(x) is to be a probability 
generating function of a non-negative random' variable it must 
be analytic in the region 
convergent power series. 
as it is here, and if S(Xo) 
that R(xo, P0).= 0; for 
Ix I < 1 because it is given there by a 
Often P(x) is of the form R(x, po)/S(x), 
= 0 with Ix0] < 1 then it must follow 
otherwise the power series for P(x) 
would diverge and P(x) would not be analytic. R(x0, P0) = 0 
gives an equation for Po. If there are several unknowns P0, Pt, ..., 
then S(x) = 0 may have several roots x0, x, ..., each yielding 
an equation for the unknowns. Typically the number of roots 
is. enough to provide unique solutions for the unknowns. 
Notice that even when (10) has been obtained it is not obvious 
that P(x) is a probability generating function. To show that it is 
we have to show that P(x) is a power series with non-negative 
oefficients. This can'be done and.it can be shown that the 
limits lim p) are eq aal to the coefficients {p,} when p < 1, but 
8---- O 
we omit the proof. When p > 1 the situation is as in the simple 
queue and p) tends to zero for all n and large queues tend to 
build up. 
200 STOCHASTIC PROCESSES [4.3 
Ergodicity 
The traffic intensity, the ratio of expected service-time to 
expected interval between arrivals, still plays the critical role in 
determining the stability of the queueing system and p = 1 is the 
critical value. Also P0 is still equal to 1-p, but now P0 means 
the probability that a departing customer begins a slack period 
and not, as in �4.2, the probability that the server is free. This 
we saw, by an application of ergodic results, was the proportion 
of the server's time that was free. However, an ergodic argu- 
ment shows that this proportion is stillpo = 1 - p: the argument 
is as follows. The process from the server's point of view consists 
of a number of slack periods of lengths sx, s2, ..., mixed with 
' s' . Then by the 
a number of service periods of lengths s, ., ... 
strong law of large numbers (theorem 3.6.3) 
lim (E s'/n') = tc -, 
the mean service-time.' Also, ignoring a small number in the 
queue,  s. +  &, where n is the number of slack periods up to 
=1 i=l 
the time customer number n' leaves, is the time taken for n' 
customers to arrive. Hence 
lim s'i st n' = A -1, 
'n'---m \i= 1 ' = 
by another application of the strong law, where X -x is the mean 
interval between arrivals. Hence 
and finally 
= l-p: 
the expression in braces is the proportion of time that the server 
is idle. Another application of the ergodic principle shows that 
the unconditional probability of finding the server free is 1 -p. 
'[' This, and similar results, require the qualification, 'with probability one'. 
4.3] QUEUEINO PROCESS WITH POISSON INPUT 201 
Notice that the arguments of this paragraph nowhere use the 
Poissonian nature of the input, only that the mean interval 
between arrivals is h -x. Hence the proportion of time the server 
is idle is 1-p whatever be the distribution of these intervals or 
of the service-times, provided the independence assumptions are 
retained, though even these might be relaxed. 
Whilst using the ergodic principle a further result might be 
noted. We have just seen that 
lim si/n' = X --1-- K --1 
and by a direct application of the strong law 
lim ( si/n) =  - 
since (cf.  4.2) the slack periods have an exponential distribution 
(the Poisson input is needed here). Combining these results 
lim (n'/n) = (1-p)-L 
But n'/n is the ratio of the number, n', of customers seed in 
n busy periods (the numbers of busy periods and slack periods 
are equal). Hence the average number of customers served in a 
busy period is (1 _p)-x. The argument of 4.2 still applies to 
show that the expected length of a busy period is l/x(1 -p). 
Expected values 
We have seen that the server's average free time, 1 -p, is not 
affected by the distribution of service-time except through the 
mean. Equation (11) shows that this is not true of the expected 
queue size which depends on the variance, o '2, of the distribution. 
For a given traffic intensity, the expected queue size is least when 
rr = 0, that is when each customer takes the same time, tc -x, to 
be served. With both , and x fixed the same remark holds for the 
expected queueing-time, equation (14), and the expected waiting- 
time, equation (16). Hence if the service-time distribution can 
be controlled it is best to make the time the same for each 
customer. The expected queue-size is reduced from p/(1-p) in 
the exponential case ({}4.2) to p(2-p)/2(1-p) and the expected 
202 STOCHASTIC PROCESSES [4.3 
queu�ing-time from 1/x(1 -p) to (2- p)/2c(1 -p). The case r -- 0 
has been studied by Erlang. Notice that in calculating (11) it 
was necessary to differentiate twice. This is because the value of 
P'(1) is indeterminate from a single differentiation, just as P(1) 
was indeterminate from (7), and we had to differentiate to find P0. 
Queueing-time 
The argument used to obtain the distribution of queueing-time 
is different from that used in �4.2. Instead of the arrivals of 
customers, the departures have been used. Also instead of dis- 
cussing the joint distribution of n, the number in the queue and 
q, the queueing-time, through f(qln), the other conditional 
probability p(nlq ) has been used (cf. equation 4.2.7 with 
equation (12)). The earlier argument again fails because theorem 
4.1.1 cannot be applied when the service-time distribution is not 
exponential, the servicing-time remaining of the customer being 
served will have a distribution dependent on how long his service 
has already lasted. 
Erlang distributions 
There is a class of distributions of service-time which is of 
special interest. Suppose that service consists of a number, n, 
of, possibly imaginary, consecutive stages, the time of stay in 
each stage having an E0ci) distribution, independent of the times 
of stay in the other stages. The moment generating function of 
an E(x 0 distribution is, for z < :, 
t< eZXe-xdx = tc/(c-z) = (1-z/c) - (19) 
so the moment generating function of the service-time distribu- 
tion is the product of n factors like (19) (theorem 3.5.4), that is 
O(z) = H (1-z/K�)-L 
i--1 
(20) 
Such a distribution is called an Erlang distribution. In particular, 
if all the tc are equal, to x say, then the distribution is' I'(n, to) 
(theorem 2.3.5). Another way of describing the service-time 
when the distribution is Erlang is to suppose that service is not 
4.3] QUEUEING PROCESS WITH POISSON INPUT 203 
complete until n types of incident have occurred; the ith type 
occurring in a Poisson process of rate Ki, this Poisson process 
starting immediately the (i- 1)st type of incident has occurred. 
If (z) is given by (20) then, from (10), 
(x-1)(1-p) 
V(x) = 
x H [1-pi(x- 1)]- 1 
(1 -p) 
(21) 
for suitable constants, �, which can be obtained in terms of the 
p = ,k/x. Since the probability generating function of G(O) 
(equation 2.1.10) is clearly (1-O)/(1-Ox), the probability 
generating function of queue size, (21), is' that of the sum of 
n independent geometric distributions, G(�). From (13) it 
follows that the moment generating function of the queueing- 
time is, with z = ,(x-1), 
%�) = (1-p) = 
for suitable fli, which is again that of an Erlang distribution. 
With n and the parameters, tc, free to be chosen, several distribu- 
tions can be described to an adequate approximation by an 
Erlang distribution. 
Non-random arrivals 
Corresponding to the theory of this section there is a closely 
similar theory for the case where the service-time distribution is 
E(tc), but the input process is one in which the intervals between 
successive arrivals are independently distributed according to 
some common distribution. It is only necessary to consider the 
queue size when a customer arrives instead of when he leaves. 
Results similar to theorems 1 and 2 can then be obtained. This 
may be useful if the customers arrive regularly, as they might if 
they were given appointments with a fixed interval between 
appointments and they all arrived on time. 
4.4. Renewal theory 
Consider a sequence of trials at each of which an event E may, 
or may not, occur. It will be convenient to suppose that the 
204 STOCHASTIC 'ROC.SS.S [4.4 
sequence begins with a trial, number zero, at which E neces- 
sarily occurs. A probability measure may be defined on the 
sequence of trials by giving the probability that E occurs at any 
trial conditional on the results of the previous trials. Suppose 
that this probability has the property that, if En. is the event that 
E occurs at the nth trial and A, is any event concerning the 
occurrence of E at trials previous to the nth, then, for m > 0, 
p(E,+,,,[E,A,) = p(E+,n[E.) (1) 
and p(E+,n ]E,) = p(EmlEo) = p(Em). (2) 
Equation (1) says that, if E occurs at the nth trial, then the 
development of the process after the nth trial is independent of 
what happened before that trial. Equation (2) says that this 
future development obeys the same probability laws as at the 
beginning of the process, when E necessarily occurred. Collo- 
quially: whenever E occurs the process starts afresh, like new. 
Such an event E is called a recurrent event. We are interested in 
how often E occurs in the sequence apart from the zero trial. 
Let p(E,,) = p,,. The p.'s do not form a probability distribu- 
tion, but, iff is the probability that E occurs for the first time 
at the nth trial, then the f's form a convergent series since 
 f.,, is the probability that E occurs at all in the sequence. 
Let 22 f, = f If f = 1 the event E is called persistent and the 
n=l 
sequence {f,} is a probability distribution. Iff < 1 the event E 
is called transient. A transient event has probability one of 
occurring only a finite number of times. For the probability of 
occurring exactly once is f(1-f), since the probability that it 
will occur is f, the probability that it will not occur again is 1 -f, 
and these are independent by (1). Similarly, the probability of 
CID 
occurring exactly n times isfi(1 -f), and finally 22f(1 -f) = 1. 
0 
A persistent event will certainly occur infinitely often. 
It will agree with the language we are using and be mathe- 
matically convenient to suppose P0 = 1, f0 = 0. To avoid tire- 
some complexities we shall suppose that the greatest common 
divisor of all n such thatf, > 0 is 1. If it is d( > 1) then E can 
4.4] RENEWAL THEORY 205 
only occur at trials whose numbers are multiples of d and by 
considering the subsequence of those trials we are reduced to 
the case d = 1. d is called the period: if d - 1 the event E is 
called aperiodic. 
One way in which the sequence can develop so that E occurs 
at the nth trial, is that E occurs for the first time at the ruth trial 
(1  m < n) and then at the nth trial. The probability of this is 
fmp(E,,[E occurs for first time at ruth trial) 
= f, np(E[Em-xl2-2 ... 
= fp(EIE,2, by (1), 
= fmP,,-, by (2). 
For different m these ways are exclusive and exhaust the possi- 
bilities, so, by the addition law and the convention about Po 
and fo, 
P, = Z fmPn-m (for n > 0). (3) 
The right-hand side is the convolution of the two sequences 
{f), {p,,} (cf. equation 3.5.5) and this observation suggests the 
use of generating functions. Let 
P(z) = E pn:F, n, f(z) '-' fn Zn, (4) 
n=0 n=0 
The first certainly converges for Izl < 1 since p < 1, the 
second for [z I < 1, and f = F(1). Since (3) holds for n > 0, if 
we multiply it by z'* and sum over n, we obtain on the left-hand 
side P(z) without the first term (n = 0), and on the right the 
product P(z)F(z) (cf. theorem 3.5.4). Hence 
= (5) 
Theorem 1. A necessary and sufficient condition that E be 
transient is that Y, p,, converges: if Y p = p then 
n=O -0 
f = (p- 1)/p. 
For anyNand0 < z < 1 
N 
Z pz n < P(z) < 
----0 
(6) 
206 STOCHASTIC PROCESSES [4.4 
where the last quantity may be infinite. Allowing z to tend to 1, 
keeping N fixed, 
2 p, < lim [1 - F(z)] - < 52 
n=0 z-->l n=0 
by (5). If the limit exists it is (1 -f)- and the left-hand inequality 
shows that the series must converge. If the series converges the 
two outer expressions are equal and hence the limit exists and 
has the same value. Hence the theorem is proved with 
p = (1-f)-, which gives (6). 
The sum  nf =/, say, is, for a persistent event, the mean 
of the probability density {fn} and is the expectation of the 
number of trials up to and including that at which E first occurs; 
and is therefore (by (2)) the expectation of the number of trials 
between successive occurrences of E. It may be +c. If/ = oo 
the recurrent event is called null. If/ < co it is called ergodic. 
# is called the mean recurrence time of E. 
Theorem 2. If E is a_persistent, a�eriodic, recurrent event then 
lim ]o,, =/-x. (7) 
T---->- ct 
(If# = +, the limit is zero.) 
There are two things to prove: first, that the limit exists; 
secondly, that it is/-. The first part, the existence theorem, is 
given separately at the end of this section. We here assume the 
limit exists, when it is easy to see what it is. 
Let F,, = 52 f, so that (1-F,) is the distribution function 
corresponding to {f} and 
= 52 (8) 
=0 
by theorem 2.1.2. Then f, = F,_x-F,, and (3) may be written 
p : (Fo - FOp_ + (Fx - F)p_,. +... + (F_ - F)po. 
Taking all the negative terms on the right over to the left and 
remembering that E is persistent, so that F0 = 1, we have 
Fop, + Fp_ +... + F,,po 
= Fop_ + Fp_,. +... + F,,-xpo (n > 0). 
4.4] RENEWAL THEORY 207 
But if the left-hand side is G, say, the right-hand side is G,_,. 
Hence G.,, cannot depend on n, so is equal to the value, FoPo - 1, 
when n = 1. Consequently, for all n, 
G, = Fop, + Fxp_ +... + Fp o = 1. (9) 
It follows that for any N and n > N 
Fop + Fp_ + ... + Fp_  1. 
Now, assuming the limit to exist, allow n to tend to infinity 
keeping N fixed. Then, only a finite number of terms being 
involved, 
 Pn  Fi (10) 
nm =0 
for all N. By (8), if   , this proves the result. 
We need only consider the case  < . It is then possible, for 
any6 > 0, to find N such that  F < e, and, with the fact 
=N+i 
that pn  l, obtain the result from (9) that 
Fop + Fp_ +... + FNp-N + 6  1. 
Again assume the limit to exist, allow n to tend to infinity 
keeping N fixed, and we obtain 
limpn  (l-e) F . (ll) 
(8), (10) and (1 l) establish the result since e is arbitrary. 
Recurrent events 
In previous sections the case of independent trials with constant 
probability of success has been considered. The results of the 
present section apply to trials without either of these restrictions. 
The assumption of independence is replaced by a weaker one in 
which it is merely assumed that whenever E occurs, the past and 
future trials are independent (equation (1)). The assumption of 
constant probability of success is weakened to make the prob- 
abilities revert to their original values whenever E occurs 
(equation (2)). Both characteristics of the earlier case are there- 
fore preserved, but in much weakened forms. In particular, 
nothing is said about the development of the trials when E does 
208 STOCHASTIC PROCESSES [4.4 
not occur. Furthermore, the assumptions might be appropriate 
when considering trials, each of which results in the values of 
one or several random variables. Provided only an event E can 
be defined in terms of the random variables satisfying (1) and (2) 
then the theorems may be applied. 
Example 1. Industrial renewal theory. Consider a piece of 
industrial equipment liable to failure. The trials are the separate 
occasions on which it is used, and if, on one of these, it fails, it 
is replaced by a new piece. Let E be the event of failure. Since 
a new piece is used whenever E occurs it will be reasonable to 
assume its performance independent of the other pieces that 
have been used, and (1) obtains. If the pieces are taken randomly 
from a stock they will have similar probability characteristics, 
and (2) obtains. (The process is assumed to begin with a new 
piece of equipment.) 
Here �, is the probability that a failure will occur on the nth 
occasion that the equipment is used' f is the probability that 
a new piece will fail on the nth occasion that it is used. 1 -f is 
the probability that the piece ill last for ever. Iff = 1 replace- 
ment is eventually certain and/t is the average lifetime of the 
piece. For large n, theorem 2 says the chance of a failure on the 
nth occasion that a piece of equipment is used is/t -. 
In this particular example it is often more convenient to 
define the probability structure in terms of ,,, the probability 
that a piece, having been used without failure on (n-1) occa- 
sions will fail on the nth' that is, the probability that a piece of 
known' age' will fail. The reason being that the age will normally 
be known and therefore this probability is the practically relevant 
one. Clearly, iff = 1, 
= p(E. 
= p(tr. ... .. 
n-1 
Conversely f = ,k, II (1 -,ki). (13) 
4.4] RENEWAL THEORY 209 
An important special case is where ,,, is constant, equal to 
say; so that the probability of failure does not depend on the 
age of the piece. From (13) f, = h(1-,k)% so that ultimate 
failure is certain and the distribution of (n-1) is geometric. 
We easily obtain 
F(z) -- hz [1- (1- X) z] -x and P(z) = 1 +,z/(1-z) 
so that p = ,k for all n > 0, as is directly obvious. Conversely, 
if the distribution of (n-1) is geometric then , is constant. 
For many pieces of equipment ,, will, of course, increase 
with n. 
Example 2. Simple random walk. Consider the simple random 
walk (�2.5). This is a sequence of trials with each of which is 
associated the position of the particle, x, so that the outcomes 
of the trials are not independent. Let E be the event that the 
particle returns to the origin. Then E is the event, x = 0. We 
show that E is a recurrent event, but first we notice that E.can 
only occur at trials with even numbers' that is, it has period 2. 
We shall therefore suppose that n is always even and only con- 
sider every other trial. If n = 2m, m will play the role in the 
theory previously occupied by n. If x,, -- 0 the future depends 
on u,,+, z+2, ... (equation 2.5.1), whereas the past depended on 
ux, t2, ..., ,t: the u's are independent, so (1) is satisfied. All the 
u's have the same distribution so (2) is satisfied. Notice that the 
event, xn = 0, is not peculiar' for any integer c the event of 
return to c is similarly a recurrent event. 
From equation 2.5.2, with s = 0, n = 2m, 
pm = (2mm) (pq)% (14) 
and to decide whether E is persistent or not we have to consider 
the convergence of Y'Pm, for which we need the behaviour of (14) 
for large m. By Stirling's formula, 
m! ~ d(2rt)e-mmm+, (15) 
we easily obtain that 
1 
~ (4pq). (16) 
If p 4= �, 4pq < 1 and the series converges faster than the 
geometric series with common ratio less than 1. Hence 
210 STOCnASXXC PROCESS�S [4.4 
converges and, by theorem 1, E is transient. Ifp = �, 4pq = 1 
and the series behaves like Y.m-' which diverges and E is 
persistent. However, then p,,---> O, so that the mean recurrence 
time is infinite. Hence if the walk has a drift (p 4= q) it will 
return to the origin at most a finite number of tines: if it has no 
drift (p = q) then return is certain, and it will return infinitely 
often, but the expected time until the return is infinite. In the 
case of drift (p =b q)f, the probability that it will at any time 
return to the origin can be found using theorem 1: 
I3 = (1 - 
from (14). But since p+q = 1, (1-4pq)- = ]p-q]-. Hence, 
from (6), f = 1- P-ql. 
The case p = � solves the problem mentioned in the introduc- 
tion to chapter 1 of how long one can expect to go on tossing 
a fair penny until the numbers of heads and tails are equal. 
This example can easily be generalized'to higher numbers of 
dimensions. Thus, in two dimensions, if the walk can proceed 
from any point (x, y) with integer co-ordinates to (x + 1, y + 1) 
with equal probabilities of �, so that there is no drift, it is 
equivalent to two independent simple random walks on the 
x- and y-axes, both without drift. It can only return to the 
origin if both the x- and y-co-ordinates are zero, and hence the 
probability of return to the origin is p,, where p, is given 
by (14). Y,p} behaves like Zm -, which still diverges, so that the 
walk is certain to return to the origin, but the recurrence time is 
infinite. In s dimensions we deal with I;p which behaves like 
1;m-b and converges for s > 2. Hence, in dimensions highef 
than two, return to the origin is not certain and that event is 
transient. 
Other events in connexion with the random walk may be 
similarly studied. For example, one is sometimes inker.eft.ted in 
' records'; that is, positions of the walk, x, which are. such that 
x, > x. for all i < n. If E is the event of a record then it. is easy 
to see that it is a recurrent event. Equation (1) follows because, 
if x, is a record, whether or not E occurs at trial (n + m) depends 
4.4] RENEWAL THEORY 211 
only on x+m - x,. Equation (2) follows since the distribution of 
xn+m- xn is the same as that of x- x0 = x. Another example 
concerns 'success' runs. If � is the event of r, say, successive 
steps of + 1 (corresponding to a 'success' at a particular trial 
and the (r-1) previous ones), it is easy to see that this is a 
recurrent event, and one can calculate the frequency with which 
such runs occur. 
Extension to continuous time 
The main applications of renewal theory are to Markov 
processes to be studied in the next section. Meanwhile we make 
a few general comments. The idea of a recurrent event has been 
formulated for sequences, but it extends without difficulty to 
general stochastic processes in continuous time. We shall not 
describe the generalization, but note that the concept has been 
used in the treatment of the queue with Poisson input' in �4.3. 
The development of that process from any instant in time 
depends on the behaviour before that instant because the prob- 
ability of someone leaving the system depends on how long he 
has been with the server. At those instants of time when a 
customer leaves the system, however, the future development 
does not, because of the Poisson input, depend on the past. 
Therefore if the queue starts at t = 0 with j customers in the 
queue and someone just having left, the event E0) of someone 
leaving with j customers behind him is a recurrent event, in the 
sense that the process develops independently of the past accord- 
� ing to the same laws as held at t = 0. These instants were just 
those used in �4.3 and the analysis there is an example of the 
fruitful use of recurrent events to study a process. 
Ergodicity 
Theorem 2 is another example of an ergodic theorem (�3.6). 
Consider a long sequence of trials. The average interval between 
the occurrences of E will be/ so that on the average E will 
occur on one out of every/2 trials. Consequently, over a long 
period of time the proportion of times E occurs is/,-. This, by 
the theorem, is equal to the probability that, at a particular trial, 
a long way distant from the influence of the start, E will occur: 
212 STOCHASTIC PROCESSES [4.4 
that is, the long-run frequency of E at a particular trial in 
repeated sequences. Hence an average over one sequence equals 
the average at a fixed trial over several sequences. 
Distributio, theoo, 
Ill virtue of the central limit theorem (theorem 3.6.1) we call 
say more about the distribution of the number of occurrences 
of E. Let Nt be the number of occurrences of E in the first 
t trials. Let x; be the number of trials after the (i-1)st occur- 
rence up to and including the ith--the lifetime of the ith piece 
in industrial renewal terminology. Then, for fixed n and t, 
N   iff x + x +... + x,,  t. Hence 
P(Nt '0 =P (  xi t). (17) 
x.i =1 
But the x,: are independent with a common distribution. This 
distribution has mean/t. Suppose/t <  and that also the vari- 
ance, , is finite. Then by the central limit theorem, for any 
fixed z, 
'n Li=I 
the distribution function of the normal law. Consequently from 
(17) and (18) lira p(Nt � ) = �(z), (19) 
where (t- ,?.)/%/n = z. 
This last equation gives /n = {-z+(z+4#t)}/2tq on 
solving for x/n which must be positive. Since n and t  , 
z fixed, this gives 
n = t, tc - - zrrt}t - + O(1). 
Substitution of this into (19), to eliminate n, gives 
Jsm P i - -< = 
(20) 
Equation (20) says that Nt is asymptotically normally distri- 
buted with mean t# - and variance cr2t/#, a. Notice that this does 
not prove that for large t the mean and variance of Nt are 
approximately tj - and rr2t/# 3 respectively, though this is true. 
4.4] RENEWAL rUEORe 213 
That the approximate mean is t/, '-x follows from theorem 2. 
For, by considering a variable which is 1 when E occurs and 
t 
0 otherwise, it is clear that .(Nt)= 5Z p,. Hence (Nt/t) 
n=l 
t 
behaves like t - E p, which has limit j-. The proof that the 
*=1 
variance is as stated will not be given. 
If (20) is applied to the industrial renewal process above with 
 =  we have g = -t,  = (1 -)X -2 and hence 
limp ( Nt -/t ) 
= 
which agrees with the fact that, the trials being now independent 
with p., = R, Nt is binomial with mean Rt and variance (1 -X) t, 
and therefore asymptotically normal (corollary to theorem 2.5.2). 
Delayed recurrent events 
A trivial, but useful, extension of renewal teory is possible. 
It is not necessary to suppose that E occurs at a fictitious zero 
trial. We can replace (2) by the weaker condition that 
p(E,,.+,, I E,,) does not depend on n, still calling it p,,,, and let the 
process start in any way we like. E is then called a delayed 
recurrent event. Let this starting condition be defined in terms of 
.f.,;, the probability that E occurs for the first time at the nth trial: 
after E has occurred the process continues to develop according 
to the p's. IfpS,. is the probability that E occurs at the nth trial 
in this new process, then clearly, as beibre 
= fI + + ... 
Since Zf, necessarily converges, to f* say, and p,, tends to a 
limit,' /x -, it follows as in the argument from equation (9) 
onwards in the proof of theorem 2 that lim p = f*j,-L In 
particular if E is certain to occur at least once, f* -- 1, and 
lim p =/,-L Therefore it does not matter for the ergodic 
property of the process how it starts provided only that the 
event E is certain to occur at least once. 
' If E is transient then p,,--> 0 since Z.o, converges (theorem 1). 
214 STOCHASTIC PROCESSES [4.4 
Since {p,,} is 
Jim p, = % 
limp,., = 
from equation (3) 
Existence theorem 
We now prove the existence of the limit stated in theorem 2. 
a bounded sequence it has an upper limit, 
say, and a subsequence (p,,.} such that 
Let s be any integer such that fs > 0. Then 
Because of the convergence of 52 f(= 1-f) the sum in the 
i4:s 
braces may be treated as a sum up to a fixed N plus an arbitrarily 
small quantity (compare the way in which (11) was obtained) 
and hence 
vr  fs lim Pk- + (1 -f) lim p, = f lim Pnk-s + (1 -f) n 
k--m n-- lc-- 
and consequently, since fs 4: .0, lin P,,-s > rr. This implies, 
by the definition of n, that lira Pr, k- -- 
Hence we have proved that if lim p, = n, then lim p_ = 
for any s such that f. > 0. Iffi > 0 we may apply this result 
with s = 1 repeatedly to show that lira p_ = n for all s and 
hence lim p = n, as we had to prove. If  = 0 then we have 
n 
to use a result in elementary number theory that says that any 
sufficiently large number can be written in the form 
where s, ..., Sm are a finite set of numbers such that J > 0, 
because the greatest common divisor of all s with f > 0 is 1 
(aperiodic case). Then lira p,_z = n by repeated applica- 
tions of the result and hence lim p., =  as required, since 
Z cs is arbitrary. 
il 
4.5] MARKOV CHAINS 215 
4.5. Markov chains 
Consider an enumerable number of elements, Ei (i = 0, 1, ...) 
called states; and a sample space, each elementary event of 
which is an infinite sequence (x0, x, x2, ...) of states: that is, 
each % is some Ei. If x is thought of as coming before xv in 
time, then we have a stochastic process which moves from state 
to state: the movement from one state to the next is called 
a transition or a step. A probability distribution over this sample 
space can be defined in terms of the density of x, conditional on 
the states assumed by (Xo, xx, ..., x.,,_ O. The process is said to be 
Markov if, for n > 0, this density depends only on the state 
assumed by x,_x. In symbols: the process is Markov if, when- 
ever A is any event depending only on x0, xx, ..., 
p(x,t = Ejlx._ 1 = gi, A) = ])(xl[ = Ejlx_ 1 = Ei) (1) 
for all i,j. It Follows that a Markov process is defined by (1) and 
p(xo = Ei). The probability in (1) is the transitionprobability of the 
transition from E to Ej.. A Markov process is temporally homo- 
geneous if (1) does not depend on n. In this case the transition 
probability (1) is written p. and we write p(x, = EO = p?). 
p denotes the column vector of elements p}'*) (i = 0, 1, ...) and 
P is the matrix of elements p, called the transition matrix. 4f 
We shall refer to a temporally homogeneous Markov process 
with an enumerable number of states as a Markov chain. If the 
number of states is finite, the chain will be called finite. 
The basic equation for studying Markov chains is easily 
obtained from the generalized addition law (theorem 1.4.4): 
= Z p(x.,,_ = E)p(x = Ealx_x = E) 
i 
or, in matrix notation, 
(2) 
' The order of the suffixes is important. Here Po refers to a transition from 
E to Es. Some authors put the suffixes in the reverse order and p refers to a 
transition from �'i to E. 
216 STOCHASTIC PROCESSES 
Repeated use of this result establishes that 
[4.5 
(3) 
so that the probability distribution, p,, is obtained in terms of 
the known P0, the initial probability distribution, and the known 
transition matrix. The elements of P' will be denoted by 
A further use of the generalized addition law shows that 
p.v = p(x. =  x = ) 
= Z p(x = lx,- = e)p(x_ = ,lx,- = 
and in general that 
p}2 ) = p(x = E ] xo = ). 
Similarly, ,(,o = ), (4) 
: = P(Xm+ EIx., = 
the probability of a transition from E to E in n steps irrespec- 
tive of m. Of course, p? = p. 
Suppose the Markov chain starts in a particular state, say 
,' that is, x0 = E. Then, by considering merely whether or not 
the chain is, after any transition, in state E it is clear by a com- 
parison of (1) with equation 4.4.1 and of (4) with equation 4.4.2 
that the event of being in state E is a recurrent event. Indeed, 
a Markov chain can be defined as a stochastic process on a 
number of events, each of which is recurrent in this sense. 
Extensive use of the results of 4.4 can therefore be made in the 
study of Markov chains, and descriptions of the recurrent event 
of being in state E can be transferred to descriptions of the 
state E itself. In particular, every state can be described as either 
persistent or transient according as the recurrent event of being 
in that state is persistent or transient. Similarly, the state will 
have a period, and if persistent will have a mean recurrence time: 
if j say, is infinite the state will be called mdl, otherwise it is 
ergodie. In theorem 4.4.1 we saw that the character of the event 
is determined by the behaviour of a series' the relevant series 
here is Zp�); E is persistent or transient according as this 
diverges or converges. 
Suppose that E is persistent but the chain starts in another 
state E. Then it is clear that the event of being in E will be 
4.5] MARKOV CHAINS 217 
a delayed recurrent event and, from the remarks in �4.4, the 
ergodie properties of Ei will remain the same provided that the 
event E i is certain to occur at least once. It is therefore natural 
to study whether a chain starting in E;. will reach Ei and vice 
versa. If there exists some m such thatp}? > 0 then we say that 
E. can be reached from Ei because it is possible to pass from El 
to Ej in m steps. If E;. can be reached from E and E from 
E. in some finite number of steps, we say that El and � are 
connected. 
Suppose Ei is persistent and �s can be reached fi'om Ei. Since 
Ei is persistent, if the chain reaches �;. it must be certain to 
return from E;. to Ei so that El and E;. are connected. Hence 
there exists n such that ,9.o =-(.'.;,�:.) then 
., > 0. Now ifc ,., ,.,, 
c > 0, and 
/0(ra-l-n+s) n(m)n(S)n(n) = 
. cp,j) (5) 
since one way of returning to E. in (m + n + s) steps is to pass to 
E s in m, return to E s steps later, and return to Ei in n further 
steps. Similarly, 
p(m+n+s) n(n)n(S) r>(m) --(s) 
(6) 
Equations (5) and (6) show that the series 51 (,o and 7Z p.?) 
T n 
behave alike and therefore E being persistent means that E. is 
also persistent. If Ei is null, -<*)---> 0 and, by (5), pJ) -+ 0, so that 
Pit . 
E. is also null, and conversely, by (6). Furthermore, if E,z has 
period d, then with s = 0 in (5) m + n must be a multiple of d, 
and hence if p.? exceeds zero for s not a multiple of d, again 
by (5), p?++) would exceed zero for m + n + s not a multiple 
of d, which is impossible; therefore Es. also has period d. 
These arguments prove that the states that can be reached 
from any persistent state are all persistent with the same period. 
They thus form a closed set of states: once the chain is in the 
closed set it cannot leave it. Furthermore, Ei being pers, istent, 
the chain will return to E infinitely often: each time it does so 
there is a probability _(m) > 0 that it will pass to E. in m steps. 
The probability that it will never pass from El to E;. in m steps 
is therefore lim (1 ()  
-pi;.) = 0. Hence not only can E s be 
218 STOCHASTIC PROCESSES [4.5 
reached from. Ei; it is certain to be reached; and similarly Ei 
from E.. We therefore have 
Theorem 1. In any Markov chain the states may be divided into 
closed sets of persistent states, all the states of any one closed set 
having the same period and being all null or all ergodic; and 
transient states. From the states of any closed set only states of 
titat set can and will be reached. 
As in �4.4, we henceforth consider only the aperiodic case, 
d = 1. If d > 1 in a closed set it suffices to consider the process 
(Xo, xa, x2a, ...) instead of the original one. 
Before giving the next proof we remark that if Zz is an 
absolutely convergent series (in particular if {z} is a probability 
density) and ]u?)[ < 1, then 
lim - ..on) . 
>Zzi ui Zz lim (7) 
provided either side exists. 
Theorem 2. In a Markov chain containing only one closed 
aperiodic set of persistent states, and no transient states, either 
(a) every state is ergodic and for all P0 
limp?) = p, = ?,?L (8) 
Furthermore Zpi = 1 and p' = p'P, (9) 
where p is the column vector of elements p.forming the stationary 
distribution of the chain. p is the unique sobtrion of (9) with 
5;pi = 1. Or 
(b) every state is null and for all Po 
limp?) = 0 (10) 
and there is no stationary distribution. 
Every state is either null or ergodic by theorem 1. From the 
basic renewal theorem 4.4.2 it follows that limp}?') =/C  
Hence if the chain starts in E, lira p?) = /,7  = p, say. But 
if it starts in E s it is certain to reach E by theorem 1, because 
4.5] MARKOV CHAINS 219 
there is only one closed set, and therefore the ergodic property 
persists and lim ,�,.o = 
-; Pv For generalp �), 
,.(o) 
(equation (3)) and, by the remark (7), 
lira p?) = 51 p? Pi = &. 
This proves (8) and (10). 
Now 
j 
for any finite set J of integers j. Hence allowing n to tend to 
infinitypt > v and therefore& > Z pjp.. But ,-,o , 
/.-, PsP'i v ,9.o < 1 
so Z & < 1 'and hence Z &. < 1' so that on summing the result 
of the last sentence over i and reversing the order of summation 
of the absolutely convergent double series, we have 1 p 
since 51p;. = 1. Consequently the inequality becomes an 
equality and p = 7E p; p;. which is (9). In the null case such 
a stationary distribution (.satisfying (9) with Zpt = 1) cannot 
exist since if p? = p then p?) = p for all i contradicting (10). 
It remains only to prove that in the ergodic case (& > 0) the 
form a distribution and are the unique solutions of (9). We 
know Z, pt converges to a positive (non-zero) sum so that there 
exists one solution, namelypdZp,:, ofzt = Y z s p. with Zz, = 1. 
Also any solution of z. = 51 zsps satisfies z. = X; z .,(.v) and 
allowing n to tend to infinity, using (7), zt = 51 zpt = Pt. 
J 
Hence there is a unique solution, namely t = P, Zz, = ZPz = 1. 
The distribution is stationary since if P0 = P then p = p for 
all n. The process already being temporally homogeneous it will, 
with P0 = P, be stationary (�4.1). This completes the proof. 
We have proved that, if all states are null, a stationary 
distribution does not exist. The same proof establishes the same 
220 S:OC}ASXXC PROCESSES [4.$ 
result if all states are transient. Consequently we have the 
Corollary. If all the states are connected, there exists a 
statioary distribution iff they are all ergodic. 
Theorem 3. A finite Markov chain cannot foreoer stay hz transient 
states, and if there is jttst one closed set then there exists a unique 
stationary distribution. 
If E is transient then, in any realization apart from those in 
a set having zero probability, there exists an n such that the 
process is never in E after the nzth transition. Since the number 
of states is finite, the process is never in a transient state after 
n = max n. transitions. If there is one closed set it is certain to 
enter it. Since -(:'.') = 1, the summation being over the finite 
.t 
number of states in the closed set, Zg = 1 and hence not all 
states can be null. They must therefore be all ergodic and 
theorem 2 (a) applies. 
Examples 
We give some examples of Markov chains. We have already 
met one in the simple random walk (�2.5) and we first consider 
this in various forms. 
(a) No barriers. This is the form considered in {}2.5. The 
states are the integer values on the real line and the Markov 
property (equation (1)) clearly obtains since the transition 
depends only on the u. We saw in � 4.4 that the event of being at 
the origin was a recurrent event which was persistent only when 
p = q and was otherwise transient. The origin has no special 
position in this long-run property and therefore this result 
applies to the event of being in any state. Hence if # = q all 
states are persistent and each is obviously connected to every 
other: there is therefore one closed set. Ifp =t = q all states are 
transient. When # = q we saw (�4.4) that the recurrence time 
was infinite and therefore all states are null. 'Consequently there 
is no stationary distribution. This agrees with the result of �2.5 
where we found that the distribution after a finite number of 
transitions was binomial with variance which increased with 
this number. Notice that the simple walk has period 2. 
(b) Two absorbing barriers. As explained in �2.5 the usual 
application_s_0f_simple random walk theory (games of chance, 
4.5] MARKOV CHAINS 221 
sampling inspection, etc.) have barriers present. We first con- 
sider the case where there are two absorbing barriers--absorbing 
in the sense that when the walk reaches either of thein it remains 
there forever: the walk stops. Specifically let the walk take place 
on the integers 0, 1, 2, ..., N, and let E. denote the state of being 
at integer point i. Then the transition matrix, if the states E0 
and E:v are absorbing, will have the forin 
1 0 0 ......... 0 
qOpO ...... 0 
O qOp O...O 
0 0 q 0 p 0 0 , (11) 
0 ...... OqO.p 
0 ......... O0 1 
where Po (i, J = 0, 1, ..., N) is the probability of transition front 
E to E.. Clearly E0 and E.v form two closed sets of persistent 
states. (A closed set consisting of a single state is often called 
absorbing.) Ei (i 4= 0, N) cannot be persistent for if it were, since 
E0 can be reached from Ez, by theorem 1, E could be reached 
froin E0, which is impossible. They must therefore be transient, 
and by theorem 3 the walk must eventually finish up in either Eo 
or E^7 (the walk must be absorbed in one of the barriers). In the 
next section we shall see what the probability is that it will be 
absorbed in, say, E0. 
(c) Two impenetrable barriers. In some situations the barriers 
(still at E0 and Ev) are impenetrable, in the sense that a step 
beyond them is thwarted and a particle stays at the barrier 
instead, but if the step is towards the other barrier it is taken in 
the normal way. The transition matrix is now 
OqOpO ...... 0 
0 0 q 0 p 0 ... 0 (12) 
0 ......... OqOp 
0 ............ 0 q p/ 
222 STOCHASTIC PROCESSES [4.5 
In this situation it is clear that all states are connected and there- 
fore, by theorem 3, they cannot all be transient so they must be 
ergodic and there exists a stationary distribution. This is easily 
found since it satisfies (9) with P given by (12). The equations 
are (cf. equation 2.5.3) 
and' 
These are 
equations 
equations 
and 1, so 
from the 
iteratively 
Po = Poq+Pq 
Pi = Pi-xP +Pi+xq 
P2v = P2v-P +PvP 
p = po(p/q) . 
(0 < i < N). (13) 
easily solved when p  q either by remarking that the 
for 0 < i < N form a set of second-order difference 
with subsidiary equation x = p + x'q with roots (p/q) 
that Pt = A(p/q) i +B, where A and B can be found 
other two equations and ;Pi = 1: or by solving 
giving p = Po(P/q), P. = Px(P/q), and generally 
Hence, either way, 
()i{ _l_-p/q t (14) 
Pi = 1 -(p/q)V+l' 
The stationary distribution is therefore a truncated geometric 
one with mode atE0ifp <qandatE2vifp >q. Ifp =qall 
states are equally likely: this can be seen either by a limiting 
process, p-> �, applied to (14) or directly by solving (13). 
(d) One absorbing barrier. Let E0 be absorbing but otherwise 
the walk is unrestricted; there are an infinity of states Eo, Ex, .... 
The infinite transition matrix is as (11) without the bounds at 
the right or the bottom. An important way in which an infinite 
chain can differ from a finite one is that it can stay forever in 
transient states. (By theorem 3 this is not possible for a finite 
one.) Here Eo is persistent but all other states are transient by 
the same argument as was used in (b). We prove in the next 
section that if p < q the walk is certain to reach E0' and there 
exists a unique stationary distribution, namely Po = 1, p -- 0, 
i > 1, but that if p > q there is a non-zero probability that the 
walk will forever remain in transient states and so never be 
absorbed. 
(e) One #npenetrable barrier. Let E0 be an impenetrable 
barrier but otherwise the walk is unrestricted; there are an 
4.5] M^RrOV CHAINS 223 
infinity of states E0, Ex, .... The infinite transition matrix is as (12) 
without the bounds at the right or the bottom. Here all states 
are connected so that if one is persistent all are. It is possible 
to distinguish the ergodic case from other possibilities by using 
the corollary to theorem 2 and seeing when a stationary distri- 
bution exists. Such a distribution satisfies the first equation of 
(13) and the second equation for all i > 0. It is easy to see as 
before that the only solution is Pt = A(p/q)i+ B and hence a 
stationary distribution exists iff p < q. Hence when p < q the 
chain is ergodic and the stationary distribution is geometric with 
pi = (q-p) (p/q)*/q. When p > q either all states are null, or all 
transient. We show how these can be distinguished in the next 
section. 
(f) Queueing theory. We have already met a Markov chain in 
the queueing process of �4.3. InStead of considering the process 
in its natural form in continuous time we discussed only the time 
points when a customer leaves the system. The states Ej are the 
states of leaving j customers behind at the end of service 
(j = 0, 1, ...). Equation 4.3.3 gives the transition matrix and 
equation 4.3.4 is equivalent to (2) above. In that section we 
immediately passed in equation 4.3.5 to the equation for the 
stationary distribution, (9) above. It is clear that all states are 
connected. A stationary distribution only exists if p < 1 and 
hence, as in (e), the chain is ergodic (and the limit exists--a fact 
which was not proved in �4.3) ifp < 1. Ifp > 1 all the states 
are either null or transient. As in example (e) we shall see how 
to distinguish these two cases in the next section. 
These examples cover the main types that can occur. It is also 
instructive to have an example of a non-Markov chain. Con- 
sider a retailer selling articles like refrigerators. Let E be the 
state of having i refrigerators in stock (i = 0, 1, ..., N), N being 
the capacity of his stockroom, and consider the stock on succes- 
sive days. The stock is reduced by sales and it might be reason- 
able to suppose that the day-by-day sales are independent so that 
a transition from Es to Ej (j < i) would be independent of the 
stock on previous days and so satisfy the Markov property (1). 
But the stock is increased by deliveries from orders placed 
several days before, and whether an order is placed will usually 
224 S:OCHASTtC PROCESSES [4.$ 
depend on the stock held on the day the order is placed. Hence 
a transition from E to Ej (j > i) may well depend on the states 
assumed before Ei and the Markov property is violated. 
The structure of Markov chains 
As explained in � 4.4 recurrent events form the natural generali- 
zation of independent trials and similarly Markov chains form 
the natural generalization of independent (discrete) random 
variables. They form a stochastic process in the sense of �4.1 
with T the set of non-negative integers. The temporally homo- 
geneous condition is also an obvious extension from the case of 
identically distributed random variables: the transition distribu- 
tions are all identical. It is only in the case of the stationary 
distribution that the actual distributions over the states do not 
change with time. It is often said that equation (2) only obtains 
for Markov chains. This is not so, it is merely a consequence of 
the generalized addition law and is valid without equation (1). 
It is only useful for Markov chains since it is usually only then 
that P, the matrix of elements p(x, = E.[x,_ = Ei), will be 
'known: for a general process P will be difficult to obtain; for 
a Markov process P and P0 completely define the process. 
Theorem 1 describes the structure of Markov chains. There 
are three basic types: (i) all states are transient (by theorem 3 this 
cannot occur with finite chains), (ii) all states are null, (iii) all 
states are ergodic. In case (i) each state is visited only a finite 
number of times and the chain is continually moving into new 
states an example is the unrestricted simple random walk with 
p  q. In case (ii) each state occurs infinitely often but infinitely 
rarely and the chain never reaches a stable situation--an example 
is the same process with p = q, the variance of the distance from 
the origin increasing steadily. In case (iii) each state occurs 
infinitely often and has a finite mean recurrence time. Whatever 
be the initial distribution, the chain settles down to a stationary 
distribution and itself becomes stationary, neither p nor P 
depending on time--an example is the queueing process above 
with p < 1. In practice (iii) is most easily distinguished from 
(i) and (ii) by .theorem 2 and its corollary. That is, by the 
stationary distribution which exists only in that case. This 
4.5] MARKOV C}IAINS 225 
method was used in the queueing process. We shall see how to 
distinguish (i) and (ii) in the next section. From these three basic 
types others can be made; the fundamental, or canonical, 
structure being a number of closed sets of persistent states, each 
of which is either null or ergodic, plus transient states: once in 
one of the closed sets it cannot leave it. An example is the simple 
random walk with two absorbing barriers: there are two closed 
sets each of one state, E0 and EN, and the remaining states are 
transient. Examples of more than one closed set with no 
transient states may be ignored since they are equivalent to 
several separate chains (for each closed set). Notice, in the propf 
of theorem 2, that the basic renewal theorem 4.4.2 establishes 
not only the existence of the limit but its value/� ; although, in 
practice,/, is often most easily found as �-, � being found 
from (9). 
Finite Markov chains 
Finite Markov chains have some special properties, principally 
that null states cannot occur and transient states can only occur 
at the beginning of the process. Interest therefore centres on the 
time taken to leave the transient states (to be discussed in the 
next section) and on the stationary distribution. The computa- 
tion of the latter is particularly interesting. Let us consider a 
finite aperiodic chain with a single closed set and no transient 
states. We have to solve the equation in z 
z'= z'P, (15) 
knowing it to have a unique solution with E z = 1, and there- 
fore, if y in any other solution y = z(Y Y0. Writing (15) in the 
form z'(I-P) --- 0, where I is the unit matrix, we see that our 
results imply that 1 is a characteristic root of P (since z exists) 
and is a simple root (since z is unique). This suggests we con- 
sider the other characteristic roots, As, and characteristic 
vectors, zs, satisfying z;(,tI-P) = 0 with z = z corresponding 
to// -- 1. Now it is a known result in the theory of such roots 
and vectors that the zs span the N-dimensional space of distribu- 
for suitable as. 
226 STOCHASTIC 'aoc�ss.s [4.5 
tions' that is, that any P0 can be written as a linear combination 
of the z's; 
8 
It follows that 
and generally 
Since we know 
Pl = P;P = Z asz;P =  as,k,z; 
$ 8 
! 
p& = 52 asA2. zs. (16) 
8 
lim p} =z' = ' = 
z, we must have az 1 and 
71,-->-O3 
]3,[ < 1 for all s > 1. Equation (16) is a convenient form for 
calculating p involving only the calculation of the a's, z's and 
,k's and then raising the last to the appropriate powers. More- 
over, (16) tells us how rapidly the limit is approached because 
this will depend primarily on the root of second largest modulus. 
If the chain is periodic then there will exist roots with ]2tl = 1 
other than ,t = 1. Thus if it has period 2 there will be a root, 
say//2, with/\.o. = -1; and considering the chain only after an 
even number of transitions we shall have 
! ! 
lira p} = ax zx + a2 z2 
since (,to.) '* = 1. If the chain also has transient states then the 
limiting distribution over all states will be the limiting distribu- 
tion over the states of the closed set with zero added. for the 
transient states. If there are several closed sets there will be a 
limiting distribution for each set and // = 1 will have multi- 
plicity equal to the number of sets. It is instructive to note that 
we here proved purely algebraic results concerning the roots of 
P, by probabilistic methods. 
Applications to genetics 
The genetical example of inbreeding considered in � 1.5 is 
closely related to a Markov chain. In the genetical situation we 
were considering the proportions of a population in three states 
(AA, Aa and aa). Remembering the intimate relationship, dis- 
cussed in � 1.3, between probability and population proportions, 
it is easy to see that the inbreeding example is a Markov chain 
with three states AA, Aa. and aa. The Markov property is 
4.5] MARKOV CHAINS 227 
expressed in the fact that given the parents' genetical structure 
(generation r, say) the offsprings' genetical structure (at the 
(r+ 1)st generation) is independent of all the grandparents, 
greatgrandparents, ... genetical structure (at generations pre- 
vious to the rth). The chain described by equation 1.5.5 had two 
closed sets, AA and aa, and one transient state Aa. Hence the 
matrix had the root ,k = 1 with multiplicity two. The single 
remaining root expresses the rapidity with which the chain leaves 
the transient state. 
Miscellaneous remarks 
It is possible to extend Markovian concepts to continuous 
time processes (such as those of��4.1 and 4.2) and to continuous 
variables. Indeed the queueing process of �4.2 in continuous 
time has the Markov property, whereas that of �4.3 does not 
and, as explained in �4.3, this is the reason for considering 
instead the Markov chain at points where customers leave the 
system. The Markovian property is basic to the study of most 
stochastic processes. 
The results of this section enable us to distinguish ergodic 
states from others by considering the existence of a stationary 
distribution. We have still to find how to distinguish null and 
transient states and to find how long a chain stays in the latter. 
These problems are studied in the next section. 
4.6. Markov chains (continued) 
The study begun in the previous section is continued with the 
same notation. 
Theorem 1. Let Es be a transient state and denote by r i the 
probability that, starting from x o = Es, the chain will forever stay 
in transient states. Then the r satisfy 
where the summation is over allj such that E. is transient. Further- 
more {r�) is the largest solution of (1) bounded by 1. 
It is obvious that the ri satisfy (1). For consider the transition 
from x0 (= E�) to x. The only way the chain can remain in 
228 STOCttASTIC 'ROCV. SSES [4.6 
transient states for ever is to pass to a transient E s, an event of 
probability p, and then starting in E s, remain in transient 
states forever. But by the Markov property this latter prob- 
ability is try. The possibilities, for different j, are exclusive and 
exhaustive, hence (1). 
It remains to prove the final sentence. Let z be any solution 
of (1) bounded by 1: that is with [&l < 1. Let rr > denote the 
probability that, starting from x0 = E, the chain will still be in 
transient states after n transitions. Then, exactly as (1), 
= E 
Also 
(2) 
(3) 
(4) 
z = Y poz. 
A comparison of (4) with (2) shows that, since Iz.[ < 1, 
I&l < rr?) and then by induction, using (3), Izl < tr?o for all n. 
But since the event of being in transient states after n transitions 
implies being in transient slates after (n-.l), 
(theorem 1.4.3). Hence ) tends to a limit which is clearly 
and [&]  . This proves the result. 
Corollary. If (1) has no solutions bounded by I other than 
z = 0 then the chah, cannot stay in transient states for ever. 
This is mediate because z = 0 is the largest solution 
bounded by 1. 
Consider a chain Mth closed sets and transient states. Let 
be the probability that, starting from a transient state E, the 
chain Mll at some time be in the persistent state E. Now if it 
reaches E it is certain (theorem 4.5.1) to reach aH states in the 
closed set to which E belongs. Consequently ps depends, not 
on j, but on i and the closed set. Consider, for the moment, 
a particular closed set C and let p denote the probability, 
starting from E, that the chain Will eventually enter C (and 
therefore stay in C). 
Theorem 2. The p satisfy 
P = Z PP + Z P, (5) 
P o 
4.6] MARKOV CHAINS 229 
where the second summation is over all states E i in C. Further= 
more {p�} is the smallest positive solution of (5). 
Consider the transition from x0 (= Ei) to x. It can either pass 
into C at xx, with probability Y Po, or can pass to another 
transient state and pass from there into C. As in theorem 1 this 
probability is  �o/%- Hence (5) follows. 
I' 
The proof of the final sentence proceeds parallel to the proof 
in theorem 1. If p?) is the probability, starting from E;, of 
reaching C in n transitions or less, then 
and 
P? = PoP? - + 
(6) 
(7) 
If z a positive solution of (5) we clearly have z > 5; Po = 
and hence, by induction using (7), zi > p?). But p?) > p}.-) 
and limp?) = p, whence zi > p. 
Note that if there is only one closed set, (5) immediately 
follows from (1) since ni +pi = 1. Also, any two solutions of(5) 
differ by a solution of (1). 
A chain in which every state can be reached from every other 
is irreducible. From theorem 4.5.1 the states of an irreducible 
chain must either all be transient, null or ergodic. We have seen 
how to distinguish the last case, by the existence of a stationary 
distribution (theorem 4.5.2). The above results can be used to 
distinguish the first case. 
Theorem 3. A necessary and sufficient condition that all the 
states of an irreducible chain be transient is that the equations 
= y, Pi5 % (8) 
5>0 
admit of a non-zero bounded solution. (Note the range of sum- 
mation.) 
The proof uses a commonly useful device. Change the chain 
by making any single state, say E0, absorbing. That is, alter 
so that P00 = 1, P0j = 0 (j > 0). Then if the states of the original 
chain were persistent one would be certain (theorem 4.5.1) to 
230 STOCHASTIC PROCESSES [4.6 
pass into Eo and therefore in the new chain absorption in Eo 
would he certain and the other states would all be transient. 
Conversely if, in the new chain, absorption in E0 is certain one 
must, in the original chain, have been certain to reach E0 from 
any other state and therefore E0, and hence all other states, 
would have been persistent. Hence a necessary and sufficient 
condition that all states of the original chain be transient is that 
it is possible, in the new chain, to stay for ever in transient states 
(that is, states other than E0). But the necessary and sufficient 
condition for the latter is that (1) has a non-zero bounded 
solution. In our case (1) reduces to (8) and the theorem is 
proved. 
Tleorem 4. In a chain containing one or several closed sets and 
transient states, in which it is impossible to stay in transient states 
'for ever, let v be the expected number of transitions, starting in 
a transient state E, before first entering any closed set. Then {%} 
satisfies the equations 
vt -- Z Po vj + 1. (9) 
Furthermore, v t is the minimal positive solution of(9). 
Let r} n) be the probability, starting from Et, that the chain 
reaches a closed set for the first time on the nth transition. Then 
Y-(n) 1 and 25 nr ) vt. (r ) should be carefully distin- 
guished from p?) in equations (6) and (7).) Clearly, using 
arguments similar to those used above, if C denotes the union 
of all closed sets, r? = ]E Po, } 
� 0o) 
and, for n > 1, 
T 
Multiply the 
Pt ---- 
nth equation by n and sum. We ob.tain 
] EPij01-- 1) t}n-1)+ 25 25Pij'}n-)+ EPij 
n T n T C 
2 Ptj'  + ]E P +  P 
T T O 
=  Po % + 1 
T 
as required. 
4.6] MARKOV CHAINS '231 
To prove that we require the minimal solution of (9) we 
consider 
As in the proof of a similar result in theorem 1 we easily estab- 
lish that if zi is any positive solution of (9) then v?)  zi and 
that if v?)  zi so is v}n+) < &. Consequently ?) < zi for 
all i. But v?) < v? +x), vi = lim v?) and the result is established. 
.--> c;o 
Structure of Markov chains 
In the previous section it was explained that there exist three 
basic'types of Markov Chain: in which all states are either 
(i) transient, (ii) null, (iii) ergodic. We saw that case (iii) could 
be distinguished by the existence of a stationary distribution. 
Theorem 3 of this section enables case (i) to be recognized and 
hence all three basic types can be separated. Other chains can 
be built up from these. Theorems 1 and 2 enable a chain with 
transient and persistent states to be studied by calculating the 
probabilities of for ever remaining in transient states and of 
passirg to persistent states' once it is in the persistent states the 
stationary distribution applies if the persistent states are ergodic. 
Note that in such a chain, if E is transient and Ej. persistent, 
lim (n) , 
n---> o 
since p. is the probability of reaching the close, d set containing 
Ej. and #? is the conditional Probability of being in E. given 
that the chain is in the closed set. 
Examples 
These results can be applied to the examples of the previous 
section. Examples (a) and (c) are completely solved. 
(b) Two absorbbg barriers. We saw that absorption in E0 or 
E2v was certain. Let p denote the probability, starting from Ei, 
of reaching the closed set containing the single state E0. Then 
equation (5)gives, for 0 < i < N, 
p = pp+ +qp_ (11) 
with P0 = 1, P2v --0. This equation is the same as equation 
4.5.13 for 0 < i < N but withp and q interchanged. The general 
solution is therefore 
p. = A(q/P)  + B 
232 sxocH,sric ,ROC.SS�S [4.6 
with boundary conditions P0 = 1, Pv = 0. Determination of 
A and B to satisfy these conditions gives easily 
This solution fails ifp = q. A special argument for this case, or 
allowing p/q to tend to 1 in (12), gives 
p, = (N-i)/N. (13) 
Naturally both (12) and (13) diminish as i increases: that is, the 
farther the chain starts from E0 the less likely it is to reach it. 
The probability of absorption in Ev is clearly l -Pi, or alterna- 
tively is the solution of (11) with P0 = 0, P2v = 1. 
Theorem 4 enables the expected number of transitions before 
absorption in either boundary to be found. Equations (9) give 
for0<i<N 
r i ----- pri+ 1 +qvi_ 1 q- 1 (14) 
with v 0 = N = 0. These equations differ from (1 l) only in the 
extra unit term on the right. The general solution of (14) is 
therefore the general solution Of (l l) plus a particular solution 
of (14). An example of the latter, not included in the former, is 
i/(q-p) so that the general solution of (14) is 
A(q/p)  + B + i/(q-p). 
The boundary conditions v 0 = rv = 0 determine A and B and 
N [(q/p)i-11} i 
p_q [(q/p)V_ +-- (15) 
q-p 
the final result is 
This fails if p =q when a limiting procedure or a fresh 
solution of the equations gives the result 
 = i(N- i). (16) 
These results are relevant to the game of chance interpretation 
of the random walk mentioned in � 2.5. If player A has an initial 
capital of i units and B has (N- i) units: and if the probability 
of A winning a single play is p, then the chance of B winning 
(that is, A's capital reducing to zero) is given by p (equations 
(12) or (13)) and the expected duration of the game is given by 
v (equations (15) or (16)). 
4.61 taARKOV CI,INS 233 
(d) One absorbing barrier. We saw in the last section that E0 
is absorbing and Ei (i >.>- 1) transient. But it remains to see 
whether absorption is certain or whether it can stay forever in 
transient states. The corollary to theorem 1 enables this to be 
decided. We have to consider the equations, for i > 0, 
(17) 
with r 0 = 0. These are (11) again, and have, using the condition 
rr 0 = 0, the general solution A [(q/p)i - 1 ]. They have a bounded 
non-zero solution iff q < p. Thus absorption is certain if q > p. 
If q < p then the probability of not being absorbed is the 
maximal solution of (17), bounded by 1, which is dearly seen 
to be 
rti = 1 - (q/p)i. (18) 
The probability of absorption is therefore 1 if q > p and (q/p) 
if q < p. In the former case the expected time to absorption 
can be found from theorem 4. The equations to be solved are, 
for i > 0, 
v = pv+ + qvi_ + 1 (19) 
with Vo = 0. This is (14) again, and has, using the condition 
v0 = 0, the general solution A [(q/p)i _ 1 ] + i/(q-p). The minimal 
positive solution of this has A = 0, since A < 0 would make v 
negative for sufficiently large i; consequently 
v = i/(q-p). (20) 
If p = q the expected time to absorption is infinite. 
(e) One impenetrable barrier. Ifp < q we found a stationary 
distribution. It remains to consider p > q, the only possibilities 
are that all states are null or all transient. This is settled using 
theorem 3. The proof of that theorem involves treating E0 as 
absorbing; that is, replacing it by case (d)just studied. The 
equations (8) are then (17) and admit of a bounded non-zero 
solution in the cases p > q only if p > q. Consequently if p > q 
all states are transient, if p = q all states are null. 
(f) Queueing theory. This is closely similar to (e). We leave 
it as an exercise for the reader to show that with p = 1 all states 
are null but with p > 1 they are transient. Thus if the traffic 
234 
intensity 
but will 
infinitely 
STOCHASTIC PROCESSES [4.6 
is one the queue will be certain to return to zero size 
do so with infinite mean recurrence time; that is, 
rarely. 
Forward and backward equations 
These examples exhibit the main uses of the theorems. It is 
worth noticing some differences in character between the equa- 
tions of this section and those of previous sections. Let us 
contrast, for example, equations 4.5.2 and (1). In the former we 
are considering 'now' after the nth transition and considering 
how it can have arisen from developments in the 'past', that is 
after the (n-1)st transition. We are, as we have done so often 
with the. other processes studied in this chapter, looking back at 
the development of the process. In (1), by contrast, we consider 
'now' in relation to the 'future', by relating x0 to xx: we see how 
it develops forward in time. Which way one has to look depends 
on what is wanted in the process. Both approaches lead to 
useful results. 
A further point to notice in connexion with the methods used 
in this section is that they all solve more than is normally asked 
for. For example, suppose, in the game of chance mentioned in 
connexion with example (b) above, we are interested in 
In order to find these we find also the probabilities and expecta- 
tions for other values of i. This technique basically consists in 
relating the value for one i with the values for other suffixes. 
Method of change of state 
The method used, in proving theorem 3, of changing a state 
into an absorbing state and thereby producing a closed set con- 
taining this one state is often useful. Consider, for example, 
a chain containing a single closed set of ergodic states. We know 
how long it will take on the average to return to a given state, 
namely the mean recurrence time of that state. A related 
quantity is how long it will take on the average to pass from E� 
to a different state Ej. We know it is certain to happen but how 
long will it take ? This is easily solved by making E s absorbing 
but otherwise leaving the chain unaltered. All states, except Es, 
will now be transient and the quantity required is the expected 
4.6] MARKOV CHAINS 235 
time to absorption. This is easily found by theorem 4, at the cost 
of also finding the time to pass from any E� to E.. If we rewrite 
#i as Jqi then we have, by this device, found #ij. More compli- 
cated problems can similarly be solved this way. For example, 
we may wish to know the probability, starting from E�, of 
reaching Ej before En (i, j, k all different). This is solved by 
making E and En absorbing and calculating (much as in 
example (b) above) the probability of absorption in E. This is 
clearly equal to the desired probability. 
Suggestions for further reading 
There is an extensive literature on queues. Much of the earlier 
work is given in the collected works of Erlang, edited by 
Brockmeyer et alii (1948). A good introduction is provided by 
Khintchine (1960) and Cox and Smith (1961). There is an excel- 
lent account of Markov chains in Feller (1957). An elementary 
introduction to finite Markov chains is provided by Kemeny 
and Snell (1960). More advanced books on this subject are by 
Chung (1960) and Dynkin (1960). An account of Renewal 
Theory is given by Cox (1962). 
A wider field of stochastic processes is covered in the books 
by Doob (1953) and Bartlett (1956). In the former the emphasis 
is on the mathematics, whilst the latter provides a treatment 
balanced between the mathematics and its applications. 
Exercises 
1. Construct some realizations of immigration-emigration processes 
using random number tables as in fig. 4.1.1. Do the same for a queueing 
process with Poisson arrivals and a r-distribution of index 2 for the 
service-time, plotting the number in the queue and the waiting times. 
2. The usual immigration-emigration process is modified so that a 
particle arriving and finding N particles in the region does not enter it but 
leaves and is 'lost'. Find the stationary distribution of the number of 
particles in the region. 
3. Show that in an immigration-emigration process the distribution of 
the number of particles in the region at time t which were not in it at time 
zero is Poisson with mean 
,(1 - e-"t)/C. 
4. In an immigration-emigration process in one dimension the region is 
an interval of unit length. The particles all enter at the left-hand end and 
236 STOCHASTIC PROCESSES 
leave at the right, travelling at constant speed. Find the distribution of 
speed of the particles and show that its mean is infinite. 
The process described above is observed at a random time and the speed 
of a randomly chosen particle is noted. Ignoring the possibility of the 
interval being empty (,k/t large) show that this particle has a distribution 
of speed v, equal to 
K21)-3 e-t/. 
Show that this has finite mean. Discuss the difference between this result 
and that in the first paragraph. 
5. A certain type of bacterium grows in a colony in such a way that the 
probability that any one individual gives birth to a new individual in any 
time interval of length & is &+ o(&) independent of the past history of 
the individual or of other individuals. Obtain a differential equation for 
the probability, p,(t), that there will be n individuals in the colony at 
time t, given that there was a single individual at t - O. Show that 
p,(t) = e-(1-e-) "- (n > 1). 
The colony grows for a time t in the way just explained. Growth then 
stops and any individual then has probability pt+o(&) of dying in an 
interval & independently of its past history or of the other individuals. 
Show that after a total time t+s (t spent growing, s spent decaying) the 
probability that the original individual has no descendants left is 
(e "- l)/ea+ e '8- 1). 
(Wales Dip.) 
6. In a simple birth process each individual has a constant chance 
2&+ o(&) of giving birth to a new individual in (t, t+ &), independently 
of the previous history of the individual. Events for different individuals 
are independent. At t = 0 there is one individual. 
Let T,, be the time at which the population size first reaches the value m, 
where m > 1 is a given integer. Prove that the density of Tm is 
,k(m - 1) (1 - e-)m-:e -. 
(Lond. M.Sc.) 
7. In a simple model for the growth of a bacterial population it is assumed 
that the probability of a bacterium dividing to give two new bacteria 
during the time interval (t, t+Jt) is 2t&+o(&), and the probability of 
more than one division during (t, t+ t) is o(&), these probabilities for 
different bacteria all being mutually independent. 
At each division of a normal bacterium there is a probability p that one 
of the two bacteria produced is a mutant and a probability (1-p) that 
both are normal, and that a division of a mutant bacterium must produce 
two mutants, the probabilities for different divisions being mutually 
independent. Obtain the 'forward' partial differential equation satisfied 
by the probability generating function of the joint distribution of Nx(t), 
the number of normal, and N:(t), the number of mutant, bacteria. Hence, 
,XERCIS.S 237 
or otherwise, determine (N(t)}, and show how expressions for 
C(N(!), N(t) and {N2(t)} may be found, given that N(0) = n, N(0) = 0. 
(Camb. Dip.) 
8. In a density-dependent population of unicellular organisms the number 
of individuals varies between 1 and N. If at time t there are n in the popula- 
tion the chance that one individual will die in a small interval of time 8t is 
?,(n- 1)fit, whereas the chance that one will divide into two similar indi- 
viduals is ,k(N-n)t. Obtain the equilibrium distribution of n and deduce 
that for N and t large 
in approximately normally distributed with zero mean and finite variance. 
(Lond. Dip.) 
9. Events occur in a Poisson process of rate A. With the ith event is 
associated a random variable X having density p e -" (x > 0). The random 
variable Y(t) is defined as the sum of the X over all events occurring in 
(,0, t); Y(t) is zero if no events have occurred by time t. Prove that 
p{Y(t) = 0} = e -t and that the density of Y(t) is, for non-zero y, 
1 {p,t "-'e_(,u+aOl {2(At�y)}, 
where I(u) is the first-order Bessel function of imaginary argument, 
I1(tt) = Z 
r=0 r!(r+ 1)!' 
The random variable T is defined as the time at which the process { Y(t)} 
first reaches or crosses a barrier at y = a. Obtain the density of T. 
(Lond. M.Sc.) 
10. Events occur randomly in time in a Poisson process with rate of 
occurrence A. The random variable X is independent of the Poisson 
process and has distribution function F(x). The number of events that 
occur in the time interval (0, X) is denoted by Y. Obtain the probability 
generating function of Y in terms of the moment generating function of ,Y. 
Suppose now that there are two independent Poisson processes. One is 
the process of events referred to above, and the other is a process of 
catastrophes occurring with rate of occurrence/. The random variable X 
is defined to be the time of the occurrence of the first catastrophe, so that Y 
is the number of events that occur before there is a catastrophe. Prove that 
/"� (Lond. M.Sc.) 
p(Y=r) = +A)+ . 
11. Carry through the analysis of �4.3 in the special case where each 
customer takes the same time, c- (to conform to earlier notation), to be 
served. 
238 STOCHASTIC PROCESSES 
12. Consider a simple queueing process with the modification that the 
customers arrive in groups of 2 but are served individually as before. (The 
groups now arrive at rate A.) Determine 
(i) the stationary distribution of queue size, and the conditions under 
which it exists: 
(ii) the distribution of queucing time, assuming that the customers are 
served in their group order, but at random within a group. 
13. You are in a queue where the successive service-times are independently 
and exponentially distributed. Show that the probability that you will have 
to wait for more than 3 times as long as the person in front of you is 1/4. 
14. In a simple queueing process, show that the probability generating 
function 
O(s, t) = Z p(t)s n 
satisfies the differential equation 
OO(s, t) _ s-1 
[(As - x) 5(s, t) + K�0(t)]. 
ot s 
Deduce that if the mean number of individuals in the queue is always 
unity, the entire probability distribution, p.,(t), is independent of time with 
a variance equal to 2. (Camb. Trip.) 
15. Consider the simple queueing system. Assuming the. traffic intensity to 
be less than 1 and the system to have been in operation for a sufficiently long 
time for equilibrium probabilities to hold, find the probability distribution 
of the time interval between a departure of a randomly selected customer 
and the immediately following departure of a customer. (Aberdeen Dip.) 
16. In a simple queueing process the probability that a customer joins the 
queue in (t, t+ 8 0 is An St, independent of the behaviour of the system prior 
to t, where n is the size of queue at t. Similarly the probability that a 
customer leaves is ten St. Show that an equilibrium distribution only 
exists if 
1 + 0 + AoAx + AoAA +... 
K! KzK  KiK2K a 
converges. Consider the special cases: 
(i) A, = A/(n+l), x,, = : (a long queue discourages new arrivals). 
Show that the stationary queue size distribution is now Poisson. 
(ii) A,,= A, c,= nx for n < m, cn= mK for n> m. (There are rn 
servers attending to the customers.) Obtain the stationary distribution of 
queue size. 
17. A queueing process has two stages of service. Customers arrive in 
a Poisson process at rate a and queue for service at the first stage. There 
is one server and the distribution of service-time is exponential with mean 
1/o'. A customer who has been served at the first stage passes immediately 
to the second stage where there is a single server and where the distribution 
of service-time is exponential with mean l/ira. The stochastic processes 
EXERCISES 239 
Nx(t), Na(t) are the numbers of customers in the first and second stages of 
the system at time t; Nx(t) is thus the number of customers queueing and 
being served in the first stage. 
Show that in statistical equilibrium Nx and Na are distributed in inde- 
pendent geometric distributions. Write down the condition for the 
existence of an equilibrium distribution, and explain the practical interpre- 
tation of the equilibrium distribution. (Lond. M.Sc.) 
18. In a certain queue, it takes a constant time T to serve any customer. 
,4, is the probability that m customers arrive in any period T, and P, is the 
probability that exactly m customers are in the queue in any period T. 
Show that 
P = APo + APx + A,-Pa + ... 
and deduce that, if a(x) = 
0 
f(x) = Y, 
o 
then f(x) = a(x) (1 - x) f(O) ' 
a(x) - x 
Show that the average number of customers waiting to be served at any 
time is 
E- 
1--� ' 
where 6 = a'(1) and / = a"(1). (Camb. Trip.) 
19. A bus travels along a road of length a. In the course of its journey 
the bus is subject to accidental delays; it will be supposed that the total 
delay at any stage of the journey is an integral number of minutes. The 
delays are subject to the law that in any small segment (x, x+/x) of the 
road there is a probability ,/Xx+ o(x) of the occurrence of a delay of 
1 minute, where , is a constant. Show that the total delay at the end of 
the journey has a probability distribution following a Poisson law with 
mean value ,a. 
A second bus starts on the same journey m minutes after the first one. 
Show that the probability q that the second bus arrives n minutes later 
than the first one is equal to the coefficient of - in the Laurent 
expansion of 
and deduce that 
27r n 
20. 
exp [3,a(s- 2 + s-X)], 
exp [- 23,a(1 - cos 0)] cos (n- m)0 dO. 
(Camb. Trip.) 
A stochastic process consisting of a series of trials can be in either of 
two states ,4 or B. If at trial n it is in state A and was last in state B at 
trial n-r then the probability that at trial (n+ 1) it will be in state B is 
A (r = 1, 2, ...) independent of all states previous to the (n-r)th trial. 
The same probability with A and B interchanged is/x. The process starts 
240 STOCHASTIC PROCESSES 
at the first trial in state ,4 with a fictitious zero trial in which it was in 
state B. Identify two recurrent events. Obtain a necessary and sufficient 
condition for (i) B to be certain to occur, and (ii) for ,4 to be certain to 
occur again after B has occurred. Under these conditions find the limiting 
probability that the process will be in state ,4. 
21. A series of trials is made in each of which an event A is observed to 
occur or not. The probability that it will occur at any trial is ps, where s is 
the number of trials since A last occurred (s - 1, 2, ...), and is independent 
of all events other than the last occurrence of ,4. 
(i) Ifps = (s+ 1) - show that once ,4 has occurred it is certain to occur 
again, but that the mean time between occurrences is infinite. 
(ii) Ifp, = 1 -s - show that the mean and variance of the time between 
occurrences are e and e(3-e) respectively. (Camb. Trip.) 
22. A stochastic process in continuous time is specified by the following 
transition probabilities between its three states in the small time interval 
(t, t + St), the remainder terms of o(t) being omitted for convenience and 
all being independent of the process prior to t: 
(i) in state 1 at t, equal probabilities 8t of passing to states 2 and 3; 
(ii) in state 2 at t, probability 8t of passing to state 1, probability 2tt 
of passing to state 3; 
(iii) in state 3 at t, probability 3 8t of passing to state 1, probability 
of passing to state 2. 
The recurrence time T of any state is defined as the time from leaving 
that state to first returning to it again. If' the distribution of T is defined 
by the density f(T)dT, and 
L(e/) = f e-Vf(T)dT, 
obtain L(�) for the recurrence time of state 1. If, alternatively, T is 
defined as including the time before leaving state 1 (given that it is occupied 
at t = 0), as well as the subsequent time before returning to it, what 
would L() be then ? (Lond. Dip.) 
23. The independent random variables X, X, ... take 
- 1, + 1, + 2, each with probability 1/3. Show that 
p, = (2- 1) m, 
where rn is a positive integer and p.., is the probability that 
Xx+ ... +X, = -m 
for some n. 
the values 
(Camb. Trip.) 
24. The life-time up to failure of electric light bulbs of a certain type is 
a non-negative random variable having probability density function f(x). 
The probability of a failure in (x, x + 8x) given that no failure has occurred 
up to x is A(x)x+ o(x). 
EXERCISES 
Express A(x) in terms off(x), and hence show that 
f(x) = A(x)exp{-,(u)du}. 
241 
(Lond. B.Sc.) 
25. In a renewal process events occur at times X, X + X2, Xt + X2 + Xa, ..., 
where {X} are a set of mutually independent identically distributed random 
variables, with density f(x). Let N be the number of renewals in (0, t) and 
let H(t) = (N0. Show that 
f*(s) 
H*(s) - 
s[1 -f*(s)]' 
where the asterisk denotes a Laplace transform, for example 
f*(s) = e-8f(t) dt. 
o 
Hence show that t /2-o '' 
H(O .... as 
/ 2/  
where/, and rr are the mean and standard deviation of the distribution fix). 
Compare the exact and asymptotic values of H(t) when 
f(x) = �e-+ e -2. (Lond. M.Sc.) 
26. A signalling apparatus can either be 'on' or 'off'. If it is 'off' at 
time t the probability that it will come 'on' in the interval (t, t+St) is 
,tSt+o(St). If it is 'on' at time t the probability that it will come 'off' in 
the interval (t, t + St) is St + o(St)). These probabilities are independent 
of the behaviour of the system prior to t. Obtain a differential equation 
for p(t), the probability that at time t, the signal is 'off'. If it is 'off' at 
time t = 0 show that 
p(t) = {A e-(a+, )' +/}/(A + 
and hence obtain lim p(t). 
Obtain this last limiting result by an ergodic argument. 
(Wales Maths.) 
27. The random variables X1, X2, Xa, ..., may each take only the 
values 0 or 1; their joint probability distribution is defined by the relations 
P(& = 1) = , 
P( X,m = X, [ X1 = xx, Xz = x:, ..., X,, = x,,) = 1 - 
for all (Xl, x:, ..., x,) and n = 1, 2, 3, .... The sequence of random vari- 
ables (Y,,} is defined by 
1 
r,,=-zx,. 
/'/ i=1 
Establish whether the property '{ Y,,} converges in probability to � as 
n -> c' holds in the following two cases: 
(i) if all . = �; 
(ii) if the infinite series Y.a converges. (Camb. Trip.) 
242 STOCHASTIC PROCESSES 
28. A loom stops from time to time and the number X of stops in unit 
running time may be assumed to have a,Poisson distribution of mean/. 
For each stop there is a probability 0 that a fault will be produced in the 
fabric being woven. Occurrences associated with different stops may be 
assumed independent. Let Y be the number of fabric faults so produced 
in unit running time. By first finding the conditional distribution of Y, 
given that X = x, or otherwise, prove that Y ha a Poisson distribution 
of mean 0/. Show also that the covariance of X and Y is 0/. 
(Lond. B.Sc.) 
29. Each trial is an occasion on which a piece of equipment is used. The 
event E is the equipment's failure and replacement by a new piece which is 
then used, necessarily without failure on that occasion. All pieces are 
taken randomly from a large stock. F, is the probability that a piece will 
last for at least n trials without failure (n = 1, 2, ...; Fz = 1). The 'age' of 
a piece in any trial is the number of trials (excluding the one being con- 
sidered) for which it has been used. State, without proof and in terms of 
{F}, the probability that, in a randomly selected trial, the piece will fail. 
Deduce that the probability that, in a randomly selected trial, the piece in 
use will have age s is Fs+ = gs, say. 
Show that the probability that, in a randomly selected trial, the piece then 
in use will last a further s trials before the trial in which it fails is also 
Show that, in these conditions, the expected number of further trials 
before it fails is 
where/ and ra are respectively the mean and variance of the age of 
a piece at failure. (Wales Dip.) 
30. In a sequence of trials E is an ergodic recurrent event. A trial a long 
time from the first is observed and s is the number of trials since E was 
last observed. (Thus s = 0 if E occurred at the observed trial, s = 1 if 
E did not occur at the observed trial but did occur at the immediately 
preceding one, and so on.) Show that s has density 
Find the mean and variance of s in terms of the moments of the density f. 
Similarly, s' is the number of trials until E is next observed. (Thus 
's' = 0 if E occurred at the observed trial, s' = 1 if E did not occur at the 
observed trial but did occur at the immediately succeeding one, and so on.) 
Find the density p of s. 
31. Consider a Markov process in discrete time, with states labelled by 
j = 0, 1, 2, ..., and with transition probabilities 
P.+x = Pi, p,o = qi = 1-pi, pin= 0 (k :!= O,j+ l). 
Consider the recurrent event E: occupation of the state j = 0. Determine 
conditions for E to fall into the various standard types. 
EXERCISES 243 
Under what conditions are all states of the process ergodic, and what 
is then the limiting distribution over states ? (Manchester Dip.) 
32. A game is played by three players, A, A., Aa, seated round a table: 
the winner being the first to get three heads in three independent tosses of 
an unbiased coin. A begins: if he gets one tail in his three tosses he has 
another go. If he gets two tails the play passes to the player on his left. If 
he gets three tails the play passes to the player on his right. When the play 
passes to A2 or Aa they have the same rules. By considering a Markov 
chain of six states: 
T.: ,4 is about to toss three coins (i = 1, 2, 3), 
E: At has won (i = 1, 2, 3), 
or otherwise, obtain the probability that the first player to toss wins. 
(Wales Dip.) 
33. A Markov chain of four states has transition matrix 
���0 
0��� ' 
0 0 � � 
Find the stationary distribution. If the chain is in the first state (corre- 
sponding to the first row) find the expected number of transitions before 
it is next in the fourth state. 
34. Use the method for finite Markov chains described in �4.5, based on 
characteristic vectors, to find the exact distribution at the sth trial for the 
Markov chain of the previous question, starting from a general initial 
distribution. In particular find the probability of being in the third state 
at the fifth trial, given that the chain was in the first state at the first trial 
(that is, after four transitions). 
35. A chess club of N members M, M., ..., M2v play a tournament in 
the following manner. M plays M2; the winner plays Ma; the winner of 
that game plays M and so on. The winner of the first game igainst Mv 
plays M, and so on. The winner of the tournament is the person who first 
defeats his fellow members in (N- 1) successive games. If all players are 
equally good and draws are ignored find the expected number of plays in 
a tournament. 
36. Set up a Markov chain formulation of the previous problem. If 
N = 4 and Ma has probability p (> �) of beating any of the other, players 
who are equally good, find the probability of M4 winning the tournament. 
37. The probability density of the lifetime of a piece of industrial equip- 
ment is f(x). The equipment is inspected at unit intervals and classified in 
one of the states E. E (i > 0) means it has been inspected i times and is 
still working. E0 means it has failed in the last interval, when it is replaced 
by a new piece. Show that the process on {E) is Markov and find the 
transition probabilities in terms off(x). 
244 STOCHASTIC PROCESSES 
38. A number, N, of points are placed around the perimeter of a circle. 
A particle at any one of these points has probability p of moving to the 
point to its right and probability 1 -p = q of moving to the point to its 
left, irrespective of its previous movements. Show there exists a limiting 
stationary distribution, and find it. 
A particle starts at a point A. It is said to have completed a 'tour' of the 
circle if the next time it reaches A it does so from the point to the other 
side of A from which it left A. Thus, if initially it inoved to the left, it will 
need to return to A through the point to the right in order to complete 
a tour. Find the probability that the first return to A will constitute a tour 
and find the average duration of a tour. 
39. A population of organisms consists initially of Nx male and N. female 
organisms. In time 8t any particular male is equally likely to mate with 
any particular female with probability A St+ o(8t), where ,k is independent 
of time. Each mating immediately produces one offspring which is equally 
likely to be male or female. Obtain a differential eqnation for the prob- 
ability generating function of the numbers nx, n.,. of males and females 
present after time t. 
Hence, or otherwise, show that for all time, 
(n- ns) = Nx- Ns, 2(nx- n) = {$(n + ns) - (Nx + N)). 
(Camb. Dip.) 
40. A Markov chain with three states has transition matrix 
q p 0] 
0 q p , 
p 0 q 
wherep+q= 1. Show that if0<p < 1 the chain is ergodie, with a 
limiting stationary distribution in which all states are equally probable. 
Prove that 
a2,n 
a!  a2, n , 
aa,n 
where aa,, + wa..n + waaa.,, = (q +pw)", 
w being a primitive cube root of unity. 
If the states are assigned values 1, 2, 3, show that the autocorrelation 
function of the limiting stationary process is 
a -- a 
Pn  al,n--2 2,n 2 3.n. 
(Camb. Dip.) 
41. Events occurring in time are observed not to be random but to be such 
that the occurrence of one event inhibits the occnrrencc of another event 
for a short period. It is therefore proposed to consider a model in which 
the probability that an event occurs in a short interval of te of length St, 
EXERCISES 245 
given that the last event occurred at a time t before the conLrnencement of 
the short interval, is 
A(1 - e -) & + o(&). 
This probability is independent of all previous occurrences other than the 
last. By finding the probability that no event occurs in an interval of 
length t after the occurrence of an event, or otherwise, show that if fl is 
large the events occur at a rate A-,k�/? approximately. (Camb. Dip.) 
42. The sequence of numbers 
Xl, X2, X3, ..., Xn, ... 
represents the values of the density in a sequence of batches of material of 
equal size produced in the indicated order. Each xn is independent of the 
others, and 
p{x,= 9} =p{x, = 11} =p, 
while p {x, = 10} = 1 - 2p. 
A batch is either disposed of immediately, or put into store. It is disposed 
of inmediately if its density is 10, or if it can be mixed with a batch 
already in store to give a mean density of 10; otherwise, it is put into store. 
Find an approximation, valid for large N, for the expected number of 
batches in store, and the variance of this number, after N batches have 
been produced. (Camb. Dip.) 
43. A simple model for population growth is to assume that each indi- 
vidual has a probability A&+ o(&) of producing another in an interval t 
of time independently of its previous history and other members of the 
population. Show that the logarithm of the mean number in the 
population increases linearly with time. 
Another model supposes that the individuals exist in two forms A and B. 
Those of type A cannot produce offspring but have a probability 
, 8t + o(8 0 of turning into type B, those of type B act as already described, 
producing always offspring of type A. Show that the logarithm of the mean 
of the total number of individuals still increases linearly with time, for 
long periods of growth, but that the rate is decreased by an amount 
,k2r + o(r), where r is the mean lifetime spent as type A. (Camb. Dip.) 
44. A slot machine works on inserting a penny. If the player wins, the 
penny is returned with an additional penny, otherwise the original penny 
is lost. The probability of winning is arranged to be � (independently of 
previous plays) unless the previous play has resulted in a win, in which case 
the probability is p < �. Show that if the cost of maintaining the machine 
to the owner averages c pence per play, then the owner must arrange that 
p < (1 - 3c)/2(1 - c), (c < �), in order to make a profit in the long run. 
(Camb. Dip.) 
45. In a radiation experiment, nuclear particles arrive randomly at a 
Geiger counter at rate A per unit time. Each particle produces in the 
recording circuit of the counter a pulse of current which is of magnitude 
246 STOCHASTIC PROCESSES [4.1 
g(u) (0 < u < oo) at a time u after the arrival of the particle, so that the 
total current 
x(t) = ftog(u)dN(t-u), 
where N(t) denotes the number of particles arriving during the interval 
(0, 0. By considering the cumulant generating functions of random vari- 
ables of the form g(u)IN(t-u+8)-N(t-u)], where 8 is a small positive 
quantity, or otherwise, show that the cumulant generating function of 
x(t), In (exp Ox(t)), tends to 
itf(eg(U'�-l)du when t-c. 
[It may be assumed that f [g(u)[du is finite and that 
g(u)O when u.] 
Show also that for large t, the process (x(t)) has autocorrelation function 
p(r) = g(u)g(u+ r)du g(u)du. (Camb. Dip.) 
o 
46. In a sple birth-and-death process there is for any one individual 
a constant probability X&+ o(&) of giving birth to a new invidual in 
the te interval (t, t+ &) and (independently of this) a constant prob- 
abiliW &+o(&) of dying in (t, t+&), the probabilities for different 
hviduals being mutually hdepepdent. Prove that the probability 
generating fction of N,, the population size at te t, given that 
No = n0, is 
G(z, t) =  p(N = r)z' [(1-z)-&-z)e-(-t] "� 
r=0 = h(1 z)-&-z)e--)q ' 
Hence, or otherwise, prove that g(N) = hoe (-) and that the prob- 
ability of the population ultimately becoming extinct is 1 (h  p) and 
> 
Prove that for h > p, 
(Ne = riD) = (N = r)/A) -", 
where D denotes ultate extinction of the population, and hence show 
that then g(Ne ] D) = no e(-)t. (Camb. Dip.) 
47. A process can be in either of two states A, B. Initially it is h state A, 
and changes of state take place at times 
Xx, Xx+ Yx, Xx + Yx + X, X + Yx + X: + Y, .... 
The random variables Xx, Y, Xa, Y, ..., representing successive lengths 
of te spent in a given state, are mutually Mdependent and 
p( < x) = G(x), p(Y  y) = H(y) (i= 1,2,...). 
Let 
= '<x , H)=p Yy (n= 1,2,...); 
Go(x) 1, and Ho)= 1 ff y0, Ho)=0 if y<0. 
EXERCISES 247 
Let fl(t) be the total time spent in the state B during the interval (0, 0. 
Show that 
p{fl(t) < x} = Z Ha(x) [Gn(t- x) - Gn+x(t- x)]. 
71,=0 
For G(x) = 1- e -as, H(y) = 1- e-t% obtain 
f0' 
p{fl(t)  x) = e -*-) l+{(t-x)} e- y- I[2{(t-x)y)lldy 
where Ix(z) = ro  (r ' (Camb. Dip.) 
48. {Xt} (t = 0, 1, 2 .... ) is a time-homogeneous Markov �ha whose 
states are the positive integers. The probabilities that X,+ = j and that 
Xt+ = j, Xt+,  j ff 1  n' < n, each conditional on Xt = i, are respec- 
tively g7 and A} (n = 1, 2, 3, ...). Show that 
{ 
+ Z z  () 1), 
n=l 
where F�) = Z z[ ), 
=1 
and hence that the state i is persistent if and only if the series 
diverges. Explain (without proof) how the mean recurrence time of a 
persistent state is related to the behaviour of pJ7 ) as n  m. 
For a chain with two states 1 and 2, 
pm= l-a, ,m = 1-b (a,b > 0). 
By obtaining F(z), or otherwise, detcrme the mean and variance of the 
distribution of the recurrence te of the state 1. (Camb. Dip.) 
49. A traffic light has a constant probability Adt of changing to green 
after being red or to red after being green in any infinitesimal time interval 
dr, so that a 'car 'arriving at a random instant has a probability of � of 
passing through without waiting and a probability element �/t exp (- Aw) dw 
of waiting a time w, where w > 0. Two cars approach the traffic light the 
second one arriving at a time interval a after the first. Find the joint 
distribution of their waiting:times, wx and w2, and hence the distribution 
of W. -- Wx. 
If the two cars travel always with the same speed between traffic lights 
and are following the same route, can you say anything about the distribu- 
tion of the time by which the second car is behind the first, after they have 
passed a large number of traffic lights operating independently with the 
same coefficient A ? (Camb. Dip.) 
50. The n states of a time-homogeneous Markov chain are represented by 
the integers 0, 1, 2, ..., n- 1. pj is the probability that the chain is in 
state j at trial k + 1, given that it was in state i at trial k. Derive a set of 
248 
STOCHASTIC PROCESSES 
n linear equations satisfied by x, the probability, starting from state j at 
the first trial, of reaching, after the first trial, the state 0 before the state 
n-! (j= 0, 1,...,n-l). 
A time-homogeneous Markov chain with two states has �00 = Po, 
Pn - Px. From a realization of this chain a new chain is constructed by 
considering non-overlapping pairs of integers, calling the pair 01, state 0; 
and the pair 10, state 1; the pairs 00, 11 being ignored. Prove that the new 
chain has poo = Pn = (1 +P0 +PO -. 
Show how, from any realization of this new chain, an independent 
sequence of the integers 0 and 1 may be derived. (Camb. Dip.) 
249 
BIBLIOGRAPHY 
ANDERSON, T.W. (1958). An bttroduction to Multitariate Statistical 
Analysis. New York: John Wiley and Sons Inc. 
BARTt. ET-r, M. S. (1956). An Introduction to Stochastic Processes. Cam- 
bridge University Press. 
BAYES, T. (1958). Essay towards solving a problem in the doctrine 
of chances. Biometrika, 45, 293-315. (Reproduction of 1763 
paper.) 
BRAITHWAITE, R. B. (1953). Scientific Explanation. Cambridge University 
Press. 
BROCKMEYER, E., HALSTROM, H. L. and JENSEN, A. (1948). The Life and 
Works of A.K. Erlang. Copenhagen Telephone Company. 
CARNAP, R. (1950). Logical Foundations of Probability. London: Rout- 
ledge and Kegan Paul Ltd. 
CHUNG, KAI LAX (1960). Markov Chains with Stationary Transition 
Probabilities. Berlin: Springer-Verlag. 
Cox, D. R. (1962). Renewal Theory. London: Methuen and Co. Ltd. 
Cox, D. R. and SMITH, W. L. (1961). Queues. London: Methuen and 
Co. Ltd. 
CRAMER, H. (1946). Mathematical Methods of Statistics. Princeton 
University Press. 
D^WD, F. N. and B^RTON, D. E. (1962). Combinatorial Chance. London: 
Charles Griffin and Co. Ltd. 
DooB, J. L. (1953). Stochastic Processes. New York: John Wiley and 
Sons Inc. 
DYNKIN, E. B. (1960). Theory of Markov Processes. Oxford: Pergamon 
Press. (Translation from the Russian.) 
FADDEEVA, V. N. (1959). Computational Methods of Linear Algebra. New 
York: Dover Publications Inc. (Translation from the Russian.) 
FELLER, W. (1957). An Introduction to Probability Theory and Its Applica- 
tions, Vol. 1. New York: John Wiley and Sons Inc. 
FINETrI, B. DE (1937). La pr6vision: ses lois logiques, ses sources sub- 
jectives. Annales de l'Institut Henri Poincard, 7, 1-68. 
FRAZER, R. A., DUNCAN, W. J. and COLLAR, A.R. (1938). Elementary 
Matrices. Cambridge University Press. 
GNEDENKO, B. V. (1962). The Theory of Probability. New York: Chelsea 
Publishing Co. 
GNEDENKO, B. V. and KOLMOGOROV, A. N. (1954). Limit Distributions for 
Sums of Independent Random Variables. Reading: Addison-Wesley 
Publishing Co. Inc. (Translation from the Russian.) 
GooD, I. J. (1950). Probability and the Weighing of Evidence. London: 
Charles Griffin and Co. Ltd. 
250 
BIBLIOGRAPHY 
HALMOS, P. R. (1950). Measure Theory. New York: D. van Nostrand 
Co. Inc. 
HARVARD COMPUTATION LABORATORY STAFF (1955). Tables of the Cumu- 
lative Binomial Probability Distribution. Cambridge: Harvard University 
Press. 
JEFFREX'S, H. (1961). Theory of Probability, 3rd edition. Oxford: Claren- 
don Press. 
KAC, M. (1959). Statistical Independence in Probability, Analysis and 
Number Theory. New York: John Wiley and Sons Inc. 
KEMENY, J. G. and SNELL, J. L. (1960). Finite Markov Chains. Princeton: 
D. van Nostrand Co. Inc. 
KENDALL, D. G. (1951). Some problems in the theory of queues. J. roy. 
statist. Soc. B, 13, 151-185. 
KENDALL, M. G. and MORAN, P. A. P. (1963). Geometrical Probability. 
London: Charles Griffin and Co. Ltd. 
KENDALL, M. G. and BABINGTON SMITH, B. (1954). Tables of Random 
Sampling Numbers. Cambridge University Press. 
KERmCH, J.E. (1946). An Experimental Introduction to the Theory of 
Probability. Copenhagen: Einar Munksgaard. 
KEYNES, J. M. (1921). A Treatise on Probability. London: MacMillan 
and Co. Ltd. 
KHrNTCI-nNE, A.Y. (1960). Mathematical Methods in the Theory of 
Queueing. London: Charles Griffin and Co. Ltd. (Translation from the 
Russian.) ' 
KOLMOGOROV, A.N. (1956). Foundations of the Theory of Probability. 
New York: Chelsea Publishing Co. (Translation of original 1933 
German edition.) 
LAPLACE, P.S. (1951). A Philosophical Essay on Probabilities. London: 
Constable and Co. Ltd. (Translation of 1819 French edition.) 
LiNDLE�, D.V. and MmL�R, J. C.P. (1961). Cambridge Elementary 
Statistical Tables. Cambridge University Press. 
Lo/vE, M. (1960). Probability Theory, 2nd edition. Princeton: D. van 
Nostrand Co. Inc. 
MACMAHON, P. A. (1916). Combinatory Analysis. Cambridge University 
Press. 
MUNROE, M.E. (1953). Introduction to Measure and Integration. Cam- 
bridge: Addison-Wesley Publishing Co. Inc. 
NATIONAL BUREAU OF STANDARDS (U.S.A.) (1953). Tables of Normal 
Probability Functions. Washington D.C. 
NEUMANN, J. YON and MOROENSTERN, O. (1947). Theory of Games and 
Economic Behaviour. Princeton University Press. 
PARZEN, E. (1962). Stochastic Processes. San Francisco: Holden-Day Inc. 
PITt, H. R. (1963). Integration, Measure and Probability. Edinburgh and 
London: Oliver and Boyd.' 
RAIFFA, H. and SCHLAXFER, R. (1961). Applied Statistical Decision Theory. 
B os ton: Harvard University Graduate School of Business Administration. 
BIBLIOGRAPHY 251 
RMSEY, F. P. (1931). The Foundations of Mathematics. London: Rout- 
ledge and Kegan Paul Ltd. 
R4D CORPOR^TON (1955). A Million Random Digits with 100,000 Normal 
Deviates. Glencoe (Illinois): Free Press. 
RErCHENBACt-I, HNS (1949). The Theory of Probability. Berkeley and 
Los Angeles: University of California Press. 
IN�, A. (1962). Wahrscheinlichkeitsrechnung. Berlin: Veb Deutscher 
Verlag der Wissenschaften. 
RIORDAN, J. (1958). An Introduction to CombinatorialAnalysis. New York: 
John Wiley and Sons Inc. 
Romo, H. G. (1953). 50-100 Binomial Tables. New York: John Wiley 
and Sons Inc. 
SAVAGE, L.J. (1954). The Foundations of Statistics. New York: John 
Wiley and Sons Inc. 
WmTWOP, TH, W.A. (1901). Choice and Chance. Cambridge: Deighton 
Bell and Co. 
WOLD, HE}tM^N (1954). Random Normal Deviates. Cambridge University 
Press. 
253 
SUBJECT INDEX 
absolute probability, 11 
absorbing state, 221-2, 229, 231-5 
absorption, mean time, 230, 232-5 
addition law, 6, 8-9, 11, 19, (see also 
generalized addition law) 
additive process, 82, 154 
analysis of variance, 124 
aperiodic event, 205 
arithmetic mean, 128-31,159 
autocorrelation, 116 
immigration-emigration process, 
185 
Poisson process, 116 
axionas, 7, 31, 37-8 
probability, 6-14, 34-6 
absolute probability, 10-11 
backward equations, 234 
barriers (see under simple random walk) 
Bayes's theorem, 20, 22--4, 31, 40-1 
continuous form, 118, 121 
Bernoulli sequence of trials, 16 
bets, 33-6, 56 
bias, 130, 132 
bimodal, 77 
binomial density, 52-3 
binomial distribution, 49-54, 79, 83,110 
inverse-sine transformation, 138-9 
generating functions, 105 
mean, 54 
normal limit, 86-90 
Poisson limit, 73-4 
variance, 78 
binomial distribution function, 53, 87- 
90 
binomial variable, 50 
Borel field, 11 
bivariate (see under nouns) 
busy period, 192, 201 
expected length, 192-3, 201 
expected number:of customers, 201 
Cauchy distribution, 159 
central limit theorem, 91, 143, 150, 
153-6, 212-13 
characteristic function, 92-4 
bivariate, 109, 118, 122 
limits, 152-6, 158 
of sums, 141,145-7 
characteristic roots (of a matrix), 27 
transition matrix, 225-6 
Chebychev's inequality, 75-6, 78-9, 84, 
89, 134, 151 
closed set of states, 217-18, 225, 228- 
31 
clustering, 68-9 
coefficient of variation, 79, 137 
combinations, 49 
combination of observations, 128-33, 
135-9 
conditional probability, 11 
conditioning event, 3, 5, 33, 51 
connected states, 217, 220, 229 
consistent behaviour, 36-8 
continuity (of a distribution function), 
60, 120 
continuity correction, 88 
converge in probability, 150, 156-7 
converge strongly, 151,157-8 
converge weakly, 150, 156-7 
convolution, 140, 145-6 
correlation, 109, 113-16, 118, 123-5, 
131,133-4 
covariance, 109, 113-16, 118, 123-5, 
127-8, 149 
craps, 46, 98 
critical odds, 34 
cumulant generating function, 93 
bivariate, 122 
limits, 152-6 
of sums, 141,145-7 
cumulants, 80, 93, 122 
De Moivre's theorem, 86-9 
decision theory, 37-8 
deduction, 1-3, 38-9 
degrees of belief, 29-42, 56, 121 
density (probability), 76, 80-1, 85, 
93-4, 119, 125-6, 141 
conditional (continuous), 118, 120-1 
conditional (discrete), 108, 110-13 
continuous (one variable), 58, 60-2 
continuous (bivariate), 117-19 
discrete (one variable), 50, 55 
discrete (bivariate), 107, 110 
of a function, 139-45 
of sums, 140, 145-7 
diffusion coefficient, 85 
254 SUBSECT INDEX 
diffusion equation, 84-5, 90, 154 
diffusion process, 85-6, 90, 154 
dispersion matrix, 109, 114, 118, 124, 
129, 149-50 
distribution, 76, 125-6 (see also den- 
sity) 
conditional (continuous), 118, 120-1 
conditional (discrete), 108, 110-13, 
116 
continuous (one variable), 58-62 
continuous (bivariate), 117-26 
discontinuities, 62 
discrete (one variable), 13, 49-57 
discrete (bivariate), 107-17 
marginal, 108, 110, 117 
mixed, 61, 119, 191 
multivariate, 125-6 
distribution function, 76, 120 (see also 
density) 
continuous (one variable), 58, 60-2 
continuous (bivariate), 117, 119-20 
discrete (one variable), 50, 53 
discrete (bivariate), 107 
limits, 150-6 
mixed, 61,119, 191 
drift (diffusion process), 90 
efficiency, 133  
elementary event, 6, 10 
equilibrium distribution, 178 
ergodic, 157, 186, 192, 200-1,211 
events, 206, 211 
states, 190, 216, 218-19, 223-5, 231 
Erlang distributions, 202-3 
event, 6, 10 
exclusive events, 6, 19 
exhaustive events, 6 
expectation, 34, 74, 76, 144, 157 
conditional (continuous), 118, 122 
conditional (discrete), 108, 112-13, 
116 
continuous (one variable), 59, 62 
continuous (bivariate), 118, 121-2 
discrete (one variable), 50-1, 55-7 
discrete (bivariate), 109, 118 
infinite values, 57, 206 
non-negative variables, 51, 57, 59, 
206 
of functions, 134-9 
of sums, 126-33 
experimental design, 131-3 
exponential distribution, 64, 66, 68-9, 
174-5, 179, 187, 197 (see also 
gamma distribution) 
queueing time, 189 
factorial function, 66, 74, 91 
fair bet, 34 
features of distributions, 74-82 
Fokker-Planck equation, 85 
forward equations, 234 
Fourier transform, 94, 146 
frequency limit, 3-6, 8-9, 16, 39, 80 
' strong convergence, 158 
weak convergence, 156 
frequency ratio, 3 
game, 55-6 
gamma (I'-) distribution, 64, 66, 74, 
137, 189 
coefficient of variation, 79, 137 
mean, 66 
moment generating function, 105, 
202 
normal limit, 154 
square of normal, 142-3 
sum of, 146 
variance, 78 
gamma function, 74 
Gaussian density, 85 
generalized addition law, 20-2, 26, 83, 
96, 180-1,197-8 
continuous case, 72, 118 
Markov chain, 215-16, 224 
generalized multiplication law, 20, 24-5 
generating functions, 91-7, 146, 199;- 
205 (see also special types) 
bivariate, 109, 122 
genetics, 2, 4, 5, 15, 25-9, 52, 226-7 
geometric distribution, 57, 69 
generating function, 203 
mean, 57 
queue size, 188, 203 
renewal theory, 209 
sum, 203 
grouping, 81 
Hardy's law, 26--7, 29 
heat equation, 85 
heteroscedastic, 113 
histograms, 80-2 
homogeneous linear function, 127 
homoscedastic, 113, 122 
hypergeometric distribution, 99 
hypotheses, 30-4 
immigration--emigration process, 174- 
87 
autocorrelation, 185 
cumulant generating function, 181 
joint distribution, 184-5 
SUBJECT. 
immigration cont. 
probability generating function, 177, 
181 
realizations, 183 
stationary, 178, 186-7 
imply (for events), 19 
inbreeding, 26-9, 226-7 
incomes, 81-2, 143 
independence, 14--18 
events, 14-19, 126 
hypotheses, 31 
random variables, 64, 111, 114, 140- 
1, 146-7: discrete, 108; con- 
tinuous, 118, 121; correlation, 
124; multivariate, 125-6 
index, binomial, 50 
gamma, 64, 74 
induction, 1-3, 38-9 
information, 47 
interquartile range, 77 
inverse-sine transformation, 138-9 
inversion formula, 94 
Jacobinn, 140, 142 
joint (see under nouns) 
kurtosis, 106 
Laplace transform, 94, 146 
Laplacian density, 85 
law of large numbers, 5, 78 
strong, 151, 157-8, 192, 200-1 
weak, 150, 156-7 
likelihood, 30, 38-9 
limit theorems, 150-60 
linear functions, 126-34, 169 
location, 76-7, 81-2 
logarithmic transformation, 136-7 
logarithms, 63 
log-normal distribution, 143 
lower triangular matrix, 148 
Markov chain, 215-35 
finite, 215, 220, 225-7 
irreducible, 229 
Markov process, 25, 28, 185, 215, 227 
Maxwell-Boltzmann distribution, 101 
mean, 74, 76, 80-2 (see also expecta- 
tion) 
continuous, 59 
discrete, 50 
of functions, 134-9 
of sums, 126-33 
spatial, 157 
temporal, 157 
INDEX 255 
mean deviation, 77 
measure, 12 
mechanics, 13, 56-7, 60-2, 78, 122, 128 
median, 76-7, 82, 159 
mixed bets, 34-6 
mode, 77, 82 
moments, 93-4, 134 
about origin, 79, 92 
about mean, 80, 92 
absolute, 79-80 
moment generating function, 92-3 (see 
also generating functions) 
bivariate, 109, 118, 124 
conditional, 125 
multinomial distribution, 110 
multiplication law, 14, 19 (see also 
generalized multiplication law) 
multivariate (see under nouns) 
negative binomial distribution, 
166 
non-Markov chain, 223 
normal density, 85 
normal distribution, 85-91 
bivariate, 114, 122-5, 147, 
generating functions, 125; 
ments,-125 
central limit theorem, 150, 153 
cumulants, 95 
generating functions, 95 
logarithm (see log-normal) 
mean, 85-6 
moments, 95 
multivariate, 147-50, 160, 185 
random samples, 145, 159 
square, 142-3 
sums, 146-7 
variance, 85 
normal distribution function, 86-91 
normal random variable, 86 
standardized, 86 
null, events, 206, 210 
states, 190, 216-20, 223-4, 231 
163, 
185: 
mo- 
odds, 11, 34-6 
orthogonal, 133 
parameter, binomial, 50 
bivariate normal, 124 
exponential, 64 
gamma, 66 
geometric, 57 
multivariate normal, 150 
normal, 86 
Poisson, 65 
256 
period, 205, 209, 216-17, 220, 226 
persistent, events, 204-5 
states, 216-18, 231 
personal probability, 37 
play (of a game), 55-6 
Poisson density, 69-70 
Poisson distribution, 65, 69-74 
binomial limit, 73-4, 158 
bivariate, 184-5 
cumulants, 95 
distribution function, 69-71 
generating functions, 94--5, 97 
immigration-emigration process, 
178 
mean, 65 
moments, 95 
normal limit, 154, 185 
square-root transformation, 138 
sum, 145-6 
variance, 78 
Poisson process, 63-74, 121, 146, 157, 
175, 179, 187, 193, 198 
autocorrelation, 116 
generating function, 95-7 
joint distribution, 115-16 
rate, 72 
populations, 17-18 
posterior probability, 30 
prior probability, 30 
probability, 1, 32, 39 (see also density) 
axioms, 6-14, 34-6 
empirical basis, 3-6 
mass, 13, 56-7 
measure, 12 
probability generating function, 91-4, 
96-7, 114, 116-17 
bivariate, 109, 114-18 
conditional, 116-17 
independent random variables, 114-- 
15 
products of random variables, 143 
proportion (and probability), 18, 24 
propositions, 30 
purely random process, 63 
purely random stationary process, 
63 
quartiles, 77 
queue discipline, 187 
queue size, 187 
distribution, 188, 193-5, 203 
mean, 188, 191,195, 201 
probability generating function, 195, 
203 
queueing, 67-8, 187-203 
SUBJECT INDEX 
queueing process, general service 
time, 193-203, 211,223, 233-4 
queueing time, 189, 202 
distribution, 189, 191, 196, 201 
mean, 191,196, 201 
moment generating function, 196, 
203 
random error, 130, 155 
random mating, 26 
random normal deviates, 145, 159 
random process, 67 
random sample, 17-18, 26, 51, 111, 
129-31 
construction of, 144-5 
with replacement, 17 
without replacement, 17 
random sampling numbers, 144-5, 
159 
random trials, 16, 110 
with constant probability, 16, 41, 49, 
57, 69, 80, 207: limit, 156 
random variable, continuous (one 
variable), 58-62 
continuous (bivariate), 117-20 
discrete (one variable), 50, 54-5 
discrete (bivariate), 107-10 
functions of, 135-47 
honest, 61 
products of, 143 
sums of, 126-34, 140, 143-7, 150-9 
random walk, 82, 87, 91,154 (see also 
simple random walk) 
range, 77 
rate (of occurrence of incidents), 66, 
72 
rational behaviour, 36-8 
recessive genes, 28-9 
records, 210 
recurrence time, 212-13 
mean, 206, 216, 218, 225 
recurrent event, 204, 207, 211,216 
delayed, 213, 217 
regression, 108, 112-14, 118, 122 
linear, 112, 114, 116, 122-5, 148-50, 
181: coefficient, 113, 116, 122-5 
quadratic, 113 
renewal theory, 203-14 
industrial, 208-9, 213 
renewal theorem, 206, 218 
residual variance, 124 
rounding errors, 155 
sample paths, 183 
sample realizations, 183, 186, 192 
SUBJECT 
sample space, 6-8, 10, 24, 32, 54, 107, 
109, 186 
sampling inspection, 51-2, 87 
serveifs free time, 188, 191, 195, 200 
service, 187, 200, 201 
time, 187, 189, 193: mean, 190, 200- 
1; moment generating function, 
195 
set, 6 
simple queueing process, 187-93 
simple random walk, 82-90 
many dimensions, 210 
Markov chain, 220: absorbing bar- 
riers, 220-2, 231-3; impenetrable 
barriers, 221-3, 232-3 
normal limit, 85 
return to origin, 209-10 
simulation, 42 
skewness, 106 
slack period, 191,200-1 
spread, 77-9 
square-root transformation, 137-8 
standard deviation, 75-9, 129-33 
stationary distribution, 178, 182-4, 
186, 187, 190 
Markov chains, 218-25 
stationary process, 63, 68, 186 
staffstie, 81 
statistics, 1, 38, 41 
step, 215 
Stieltje's integration, 62 
stochastic, 16 
stochastic process, 67, 82, 115, 215, 
224 
stochastically independent, 16 
subjective probability, 4.0 
strong convergence, 151, 157-8 
success ratio, 3, 9, 16, 80 
limit, 156, 158 
INDEX 257 
success runs, 211 
sums of random variables, 126-34, 140, 
143-7, 150-9 
systematic error, 130, 132 
tail (of a distribution), 69 
temporally homogeneous, 186, 215, 
224 
traffic intensity, 190, 200 
transient, events, 204-5, 210 
states, 190, 216, 220, 224, 227-31, 
233 
transition, 215, 235 
matrix, 215, 221,226 
probability, 215 
trial, 3 
trinomial distribution, 110, 111, 113, 
115 
twins, 21-2 
unbiased, 130 
uncorrelated, 114, 124, 127-9, 133 
uniform distribution, 12, 144, 155 
unimodal, 77 
utility, 37-8 
variance, 75, 77-8, 80 
of functions, 134-9 
of sums, 126-34 
variance-covariance matrix, 109 
vectors, 129, 133 
Venn diagram, 7-8 
waiting-time, 191 
distribution, 61,191,196, 201 
mean, 191,196, 201 
moment generating function, 196 
-algebra, 11 
258 
INDEX OF NOTATIONS 
A (sample space), 6 
AB, 6 
B(n p), 50 
'if(-, .), 109 
9(.), 75 
_2(.), 75 
(.), 51, 59 
d'(.), 75 
(' I'), lO8 
E(A), 64 
f(.), 58 
(.), 58 
f, 204 
O(q), 57 
'lim', 3-6 
ln, 63 
matrix notation, 27, 149 
n!, 74 
N(p, rr'), 86 
o(.), 175 
O(.), 134 
P, 215 
p(A), 10, 59 
p(AIB), 6 
p?), 215 
Pij (transition matrix), 215 
p!.>, 216 
plim, 156 
P(p), 65 
p,. 215 
p. 50 
Pt, 50 
Pt., 107 
Prs, 107 
5s, 107 
p(rls), 108 
(.), 79 
128 
flo, 147, 148 
6 
r(n), 74 
r(n, ), 66 
(service time), 187 
r, 93 
K(z), 93 
(arrival rate), 187 
(recurrence time), 206 
(mean), 59 
/x (Markov chains), 216 
p, 80 
p, 79 
(Markov chains), 230 
v, 80 
v, 80 
% 227 
n(x), 91 
INDEX OF NOTATIONS 259 
n(x, y), o9 
n(y10, 116 
(traffic intensity), 190 
p(., .), o9 
228 
(x), 86 
� (z), (m.g.f.), 92 
,(x), 86 
F(t), 92 
F(t, u), 109 
tr, 75 
rr, 75 
E A,i, 6 
~, 55, 126 
j'ax fo, 9 
